[
    {
        "source": "mattermost",
        "post_id": "wuohdejkptdjpysug57hke9awy",
        "create_at": 1681977277781,
        "user_id": "dbxj1b39spd85k8thjcngnt8gc",
        "message": "Hi, I am trying to run locally a simulation of a single MB pp collision with a very simple script (that you can find at the link), but the process is hanging indefinitely. I have the same problem both on ubuntu and on macOS, in both cases with a fresh new installation of O2, O2Physics, O2DPG, QualityControl (from scratch). All the relevant logs and files (including the script) can be found here: https://cernbox.cern.ch/s/Ags9Krw4wgK9pSe. Have you any suggestion about what could be wrong? This is just a test, because also for a bit more complex simulations I have the same problem. Thanks! ",
        "question": "What could be causing the simulation to hang indefinitely when running a single MB pp collision locally on both Ubuntu and macOS?"
    },
    {
        "source": "mattermost",
        "post_id": "gsgge5jwr3rabcc45gs4z5495c",
        "create_at": 1681980323615,
        "user_id": "cb3ujfswxpd6tm5fj9z53byray",
        "message": "I have a similar problem \nI tried to kill and reinitialize the token \nBut the hanging, should it not have a timeout? \nI will try to get more information here ",
        "question": "Should the token killing and reinitialization process have a timeout?"
    },
    {
        "source": "mattermost",
        "post_id": "3u5ccz4cu3dqxxgnyzmpo7qg8w",
        "create_at": 1681983523108,
        "user_id": "dbxj1b39spd85k8thjcngnt8gc",
        "message": "Now for some reason that I do not understand, on macOS it does not hang anymore, but it dies after `tpcclustermerge`:\n```\nRuntime error: Not able to make progress: Nothing scheduled although non-zero candidate set\n\n**** Pipeline done with failures (global_runtime : 98.316s) *****\n```\nAll exit codes in logs (https://cernbox.cern.ch/s/ZRh3An7RsT3vsri) are 0.\nAny suggestions?\nI also got this problem before the hanging appeared\nTrying to understand how to get the stacktrace from the bash script (in which a python script is executed) fon linux",
        "question": "Why does the simulation die after `tpcclustermerge` on macOS with the error \"Not able to make progress: Nothing scheduled although non-zero candidate set\"?"
    },
    {
        "source": "mattermost",
        "post_id": "5ngre511rtd68gwyg4zpf4ayeh",
        "create_at": 1683034334869,
        "user_id": "xchyiqc69pdou8actqq9gwqfde",
        "message": "Dear all,\n\nI have one small question. I am still digesting the MC Run 3 framework itself at the same time as implementing the PWG-EM dielectron MCs.\n\nI understood that in MC simulations like:\nhttps://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGDQ/runCharmToMuons_fwd_pp.sh\nOr similarly https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGEM/runHFToDielectrons_pp.sh\nOr even https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGDQ/runPromptJpsi_midy_pp.sh\n\nwe are injecting signal (and sometimes triggering at the same time) in a pp minimum bias pp collisions. Each collision has then a signal in it. Is it correct ?\n\nIn the presentation of David during the tutorial (here: https://indico.cern.ch/event/1267433/contributions/5379755/attachments/2635472/4559337/DDChinellato-Tutorial-HandsOn-04.pdf) there was on slide 5 the PYTHIA Gap-triggered concept. It is not clear to me how you do this PYTHIA Gap-triggered concept with the script https://github.com/AliceO2Group/O2DPG/blob/master/MC/bin/o2dpg_sim_workflow.py. Is it be via the --embeddPattern option ??\n\n\n",
        "question": "Is it correct that in these MC simulations, we are injecting signal in each pp collision, and how does the PYTHIA Gap-triggered concept fit into the script o2dpg_sim_workflow.py?"
    },
    {
        "source": "mattermost",
        "post_id": "mymi8hpzw783ddwp78o5b49e7r",
        "create_at": 1683034678976,
        "user_id": "xchyiqc69pdou8actqq9gwqfde",
        "message": "Is there an example somehow of gap-triggering with external generator ?",
        "question": "Is there an example of gap-triggering with an external generator?"
    },
    {
        "source": "mattermost",
        "post_id": "qrusif74ttrmzm1of4jtwgg5no",
        "create_at": 1683039696947,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@rbailhac @ddobrigk : Gap triggering is possible in O2DPG MC workflows (in principle). This works by using a specific embedding pattern (https://github.com/AliceO2Group/O2DPG/blob/master/MC/bin/o2dpg_sim_workflow.py#L73). By default this is set to '@0:e1' ... which means inject signals on-top of every background (index==0) each time. If you take an embedding pattern of `r0:e5` you would replace every 5-th background event with a signal event. @fgrosa has some experience with this. In principle it should work. You may need to be a bit careful to select the right amount of background and signal events with the `-ns -nb` arguments. I will try add this to the documentation. Please report back how it goes.\nThis assumes usage of background + signal embedding in digitization. I am sure gap-triggering can also be done inside a custom generator.",
        "question": "Can gap triggering be done using the embedding pattern in O2DPG MC workflows, and how does it work?"
    },
    {
        "source": "mattermost",
        "post_id": "kuhbau3j83nd9nuxeybhwwgb9c",
        "create_at": 1683049346422,
        "user_id": "cb3ujfswxpd6tm5fj9z53byray",
        "message": "@swenzel I remember you told me that the on-the-fly simulations (i.e. not saving anything to disk) were used already by DQ or EM - is that correct? Could you perhaps give me a pointer to an example use case? Thanks!",
        "question": "Did you tell me that on-the-fly simulations (i.e., not saving anything to disk) were used by DQ or EM? Could you provide an example use case?"
    },
    {
        "source": "mattermost",
        "post_id": "14kko5h6u7bf9mm7gm3n8zishc",
        "create_at": 1683128423632,
        "user_id": "cb3ujfswxpd6tm5fj9z53byray",
        "message": "Hi @rbailhac thanks! I will take a look! This does not save the kine files to disk, right? Or does it? \n(the option I am interested in is not to save and provide mc particles straight to analysis in active memory) ",
        "question": "Does the option exist to not save kine files to disk and provide MC particles straight to analysis in active memory?"
    },
    {
        "source": "mattermost",
        "post_id": "fgbowhnq87rjpyh4m99hyeczaa",
        "create_at": 1683904279818,
        "user_id": "xchyiqc69pdou8actqq9gwqfde",
        "message": "Hi @all, I am not sure it is the right channel for this question (do not hesitate to send me somewhere else) but I have the following question. For the case of background + signal embedding in digitization, are both the background and signal kept ? We had in Run 2 signal filtering to spare disk place. How is it in Run 3 ? (Sorry if I missed the info somewhere)",
        "question": "For the case of background + signal embedding in digitization, are both the background and signal kept? How is the handling compared to Run 2 where signal filtering was done to save disk space?"
    },
    {
        "source": "mattermost",
        "post_id": "a5g8gt8c8t8nfp7s9xa5a6gtaw",
        "create_at": 1684164429013,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@rbailhac : I am not precisely sure what you mean: Do you mean information within an AOD or do you mean other files? I believe by default the MC productions only keep AOD files unless someone asks specifically to keep more. Within an AOD,  both background + signal MC info should be there. We do not filter the background part on signal properties.",
        "question": "Do you mean information within an AOD or do you mean other files? We do not filter the background part on signal properties within an AOD."
    },
    {
        "source": "mattermost",
        "post_id": "gmznt3wpepg4xdjcychpso8awh",
        "create_at": 1684164518033,
        "user_id": "xchyiqc69pdou8actqq9gwqfde",
        "message": "Hi @swenzel , I think you answered to my question with the \"Within an AOD, both background + signal MC info should be there\".  If I am not wrong in Run 2, we had production where only the info from signal in the event was kept in the AOD event. Thanks.",
        "question": "Did you mean that both background and signal MC info are included in the AOD for Run 2, or was it only the signal info that was kept in the AOD event?"
    },
    {
        "source": "mattermost",
        "post_id": "8itozyrmkpdd7qrnczbisrx4ye",
        "create_at": 1684842102021,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@ihrivnac : I have the impression that the TOFMAX cut is not working correctly with Geant4. When I do, say, `o2-sim -n 1 --seed 1 -g pythia8hi --configKeyValues \"G4.physicsmode=3;SimCutParams.lowneut=true;GlobalSimProcs.TOFMAX=1.4\" -o foo -j 8` ... I would expect that all tracks be stopped after 1.4s of propagation, but this does not seem to be the case. Geant4_VMC seems set the value in the TG4Limits object (fMaxTime is 1.4E09 nanoseconds?) correctly but I still see hits being created much after that with the low energy neutrons switched on. Would you be able to take a look or to suggest what I may be doing wrong?",
        "question": "Is the TOFMAX cut working correctly with Geant4 in the ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "o6yb6apfbp8rixu7oz4sg1pkic",
        "create_at": 1688471245721,
        "user_id": "8gj5de5ehjgmpkrab47ts3saoe",
        "message": "Dear all,\n\nI was wondering, is it possible to establish a volume where photon conversions (to e+e-) are turned off?\nThe FCT has 9 layers, but for my analysis it would be convenient if I could turn off photon interactions in the first layer.\nAll the other interactions should still happen.\n\nIt would also be convenient to know whether the reverse is possible:\nHave all photons convert to e+e- if they reach a layer\n\nIs there a way to do this?",
        "question": "Is it possible to turn off photon conversions to e+e- for a specific layer in the ALICE O2 simulations while keeping other interactions intact?"
    },
    {
        "source": "mattermost",
        "post_id": "otsr9g9ahtyubj7jrpco8qzojy",
        "create_at": 1688719070630,
        "user_id": "e57uyaq14t8o3pnco81wyi9q4e",
        "message": "We have not G4 biasing interfaced in VMC, there are only classes supporting mixing physics lists; but they do not allow hooking user code. So I cannot give a simple recipe how to do the last. We have already one user request for adding more general support for  biasing in geant4_vmc since last year, but I did not yet get to it.",
        "question": "Can you provide a recipe for interfacing G4 biasing in VMC, or are there any updates on adding more general support for biasing in geant4_vmc?"
    },
    {
        "source": "mattermost",
        "post_id": "rcgszh191frqjkjew7oupfsywc",
        "create_at": 1692957103245,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Hello,\nI am new to the ALICE group and I am trying to generate MFT simulations using pythia generator.\nI followed some instructions and I have the o2-sim reconstructed tracks and clusters.\nMy question is that how can I convert the o2-sim files to AO2D ?\nThanks. ",
        "question": "How can I convert the o2-sim files to AO2D?"
    },
    {
        "source": "mattermost",
        "post_id": "r6yo346km38s9ynzb7oobrkrzh",
        "create_at": 1698707673673,
        "user_id": "xhct7puz47gs7k8psm81wubtir",
        "message": "Dear experts,\nI'm a beginner with O2 simulations and I'm trying to run a simple Hard QCD all on simulation with O2 with\n```o2-sim -n 10 -g pythia8 --configKeyValues \"GeneratorPythia8.config=path_to/pythia8.cfg\" \\ --noGeant```\nWhat I receive in my terminal after executing the command is:\n```[INFO] This is o2-sim version 1.2.0 (a3142359b)\n[INFO] Built by ALIBUILD:1.14.5-jammy, ALIDIST-REV:3551039d457f9ee792f63473bab3cd9f2054838f on OS:Linux-6.2.0-35-generic\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-80157 type pub\n[INFO] Running with 8 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 8 WORKERS\nSpawning particle server on PID 80160; Redirect output to o2sim_serverlog\nSpawning sim worker 0 on PID 80187; Redirect output to o2sim_workerlog0\nSpawning hit merger on PID 80188; Redirect output to o2sim_mergerlog```\nBut after this I don't see anything else, no matter how much time I wait. Does anybody know what could be the problem?",
        "question": "What could be the reason for not seeing any output after spawning the sim worker and hit merger in the O2 simulation command?"
    },
    {
        "source": "mattermost",
        "post_id": "bq36k7c3jfdimg1ixfbpc8puiw",
        "create_at": 1698727511582,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Dear Christian,\ndo you have an alien token?\nIn particular, did you follow https://alice-doc.github.io/alice-analysis-tutorial/start/cert.html and in particular https://alice-doc.github.io/alice-analysis-tutorial/start/cert.html#convert-your-certificate-for-using-the-grid-tools ?\nIf so, before running the simulation, you need a token.\nAfter entering your O2 environment, you need to run \n```bash\nalien-token-init\n```\nLet me know how it goes",
        "question": "Do I need an alien token to run ALICE O2 simulations, and if so, how do I obtain it?"
    },
    {
        "source": "mattermost",
        "post_id": "9mpu6crp37dduxt7qwahxzswaw",
        "create_at": 1700125360817,
        "user_id": "apnw78jtq7n33f84s5rzh68rra",
        "message": "https://cernbox.cern.ch/s/DKeIWJhYB4ZmUzh Hi, while I tried install O2Physics, the  installation error appear at  FairRoot : Log file attached (FairRoot is being built (use --debug for full output): failed)",
        "question": "While trying to install O2Physics, I encountered an installation error during the FairRoot build. What could be the issue?"
    },
    {
        "source": "mattermost",
        "post_id": "7nrim6ih57f13c3g379wnky8ma",
        "create_at": 1702394163976,
        "user_id": "tchrdk7jtibcbbempsxh5bg8uc",
        "message": "Hello,\n\nIt seems I have problems accessing certain objects in CCDB when running `o2-sim` locally. E.g. `o2-sim -n 0 -m FT0 FV0 FDD` hangs with\n\n```\n[17:10:39][INFO] Init CcdApi with UserAgentID: andreas-dell-1702393838-pfiIQp, Host: http://alice-ccdb.cern.ch/\nDN >>> C=ch/O=AliEn2/CN=Users/CN=mmolande/OU=mmolande\nISSUER >>> C=ch/O=AliEn2/CN=AliEn CA\nBEGIN >>> 2023-12-12 12:58:14\nEXPIRE >>> 2024-01-12 14:58:14\nInfo in <TJAlienConnectionManager>: Opening connection to JCentral. Please wait\nInfo in <TJAlienConnectionManager>: Opening connection to 128.142.249.76\nInfo in <TJAlienConnectionManager>: Successfully connected to 128.142.249.76\nInfo in <TJAlienFile::Open>: Accessing file /alice/data/CCDB/FT0/Calib/Align/00/37459/3f67485b-e310-11ec-9e90-2a010e0a0b16 in SE <ALICE::CCIN2P3::SE>\n[17:10:43][INFO] ccdb reads http://alice-ccdb.cern.ch/FT0/Calib/Align/1640991600000/3f67485b-e310-11ec-9e90-2a010e0a0b16 for 1702393838109 (retrieve, agent_id: andreas-dell-1702393838-pfiIQp), \nInfo in <TJAlienFile::Open>: Accessing file /alice/data/CCDB/FV0/Calib/Align/15/55175/38865750-e310-11ec-9e90-2a010e0a0b16 in SE <ALICE::CCIN2P3::SE>\n[17:10:44][INFO] ccdb reads http://alice-ccdb.cern.ch/FV0/Calib/Align/1640991600000/38865750-e310-11ec-9e90-2a010e0a0b16 for 1702393838109 (retrieve, agent_id: andreas-dell-1702393838-pfiIQp), \nInfo in <TJAlienFile::Open>: Accessing file /alice/data/CCDB/FDD/Calib/Align/14/04848/f9c530b8-bc3e-11ec-b66d-2a010e0a0b16 in SE <ALICE::FZK::SE>\n```\n\nSometimes, when I have patience to wait long enough (~15 mins) it times out and tries another location for the FDD object, finds it, and continues. But most often I'm not patient. The object it looks for exists: http://alice-ccdb.cern.ch/browse/FDD/Calib/Align. When excluding FDD, there are no problems. Token is valid, and on lxplus it works fine.\n\nGrateful for tips and ideas!\n\n(cc @upadhyay )",
        "question": "Why does `o2-sim` hang when accessing certain CCDB objects, specifically FDD, and how can this issue be resolved?"
    },
    {
        "source": "mattermost",
        "post_id": "musb65k8jirt9f8g4kw7jaqg9o",
        "create_at": 1705673611046,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi, the exercise I am trying to do is to perform some private simulations of exclusive UPC events on my laptop. I am following the guides presented in the last o2 Tutorial 3.0 and the relevant link `https://github.com/AliceO2Group/AliceO2/tree/dev/run/SimExamples/HepMC_STARlight`. This is then followed by using the DPG commands. By launching the final `${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt digi -j 6 --stdout-on-failure` I understand that the issue seems to come from `qedsim_1`. In particular, I see that library `libTEPEMGEN` does not exist. I have then tracked down the thread on ALICE talks `https://alice-talk.web.cern.ch/t/qedloader-c-not-working-on-alidock/581/3` when it appears to be a similar issue... In fact when I open a ROOT session:\n```c++\ngSystem->Load(\"libTEPEMGEN.so\")\n.class TGenEpEmv1\nauto genBg = new TGenEpEmv1()\ngenBg->Init()\n```\nThe output is:\n```c++\nError in <TMacOSXSystem::FindDynamicLibrary>: libTEPEMGEN.so does not exist in /Users/simoneragoni/aliceO2/sw/osx_arm64/STARlight/r313-c-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/O2Physics/master-local3/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/VecGeom/v1.2.6-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/KFParticle/v1.1-5-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/MCStepLogger/v0.6.0-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/O2/EMCAL-539-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/RapidJSON/v1.1.0-alice2-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/ONNXRuntime/v1.12.1-alice1-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/flatbuffers/v1.12.0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/libjalienO2/0.1.4-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/fastjet/v3.4.1_1.052-alice2-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/cgal/4.12.2-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/JAliEn-ROOT/0.7.4-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/DebugGUI/v0.8.0-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/libuv/v1.40.0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/GLFW/3.3.2-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Common-O2/v1.6.2-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Configuration/v2.6.3-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Ppconsul/v0.2.3-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Monitoring/v3.17.5-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/libInfoLogger/v2.5.3-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/curl/7.70.0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/HepMC3/3.2.5-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Vc/1.4.1-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/FairRoot/v18.4.9-alice2-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/FairMQ/v1.8.4-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/ZeroMQ/v4.3.5-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/FairLogger/v1.11.1-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/fmt/10.1.1-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/pythia/v8304-alice1-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/lhapdf/v6.5.2-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/GEANT3/v4-2-local2/lib64:/Users/simoneragoni/aliceO2/sw/osx_arm64/GEANT4_VMC/v6-1-p8-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/vgm/v5-0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/VMC/v2-0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/ROOT/v6-28-04-alice3-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/TBB/v2021.5.0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/XRootD/v5.6.0-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/AliEn-Runtime/v2-19-le-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/FFTW3/v3.3.9-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/lzma/v5.2.3-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/Python-modules/1.0-local2/share/python-modules/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/arrow/v14.0.1-alice1-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/xsimd/8.1.0-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/boost/v1.83.0-alice1-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/utf8proc/v2.6.1-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/protobuf/v21.9-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/GEANT4/v11.0.4-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/xercesc/Xerces-C_3_2_4-local1/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/pythia6/428-alice2-local2/lib::.:/Users/simoneragoni/aliceO2/sw/osx_arm64/O2/EMCAL-539-local2/lib:/Users/simoneragoni/aliceO2/sw/osx_arm64/ROOT/v6-28-04-alice3-local1/lib:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:\n```\nWould you have any suggestions? Or a way to disable running this process? Thanks!",
        "question": "Would you have any suggestions to resolve the issue with the `libTEPEMGEN.so` library or a way to disable running the `qedsim_1` process?"
    },
    {
        "source": "mattermost",
        "post_id": "fwoz1z8jo3gjbji6uhdyqgswmw",
        "create_at": 1705914594107,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Many thanks Sandro and Benedikt! It might be that I had somehow an outdated version of AEGIS. I solved this current issue by doing `aliBuild build AEGIS  --defaults o2`. Thanks a lot for the help! (Hopefully I won't have many additional issues on this exercise in the near future)\nSorry to ping everyone again. Please let me know should this be addressed to the DPG instead or other groups. I am trying to use the command for the workflow runner I am using the specific o2dpg conditions described here: `https://twiki.cern.ch/twiki/bin/viewauth/ALICE/O2DPGMCSamplingSchema`. In particular, I am using `field=-5`, `run=310000`. I see that the process crashes with the tpc digitisation:\n```\n[INFO] ## Processes completed. Run summary:\n[INFO] ### Devices started: 11\n[INFO]  - Device internal-dpl-clock: pid 4280 (exit 0)\n[INFO]  - Device SimReader: pid 4281 (exit 0)\n[INFO]  - Device internal-dpl-ccdb-backend: pid 4282 (exit 0)\n[ERROR]  - Device TPCDigitizer_1: pid 4283 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[ERROR]  - Device TPCDigitizer_2: pid 4284 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[ERROR]  - Device TPCDigitizer_3: pid 4285 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[ERROR]  - Device TPCDigitizer_4: pid 4286 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[ERROR]  - Device TPCDigitizer_5: pid 4287 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[ERROR]  - Device TPCDigitizer_0: pid 4288 (exit 1)\n[INFO]    - First error: [13:27:56][FATAL] Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\n[INFO]    - Last error: Backtrace complete.\n[INFO]  - Device GRPUpdater: pid 4289 (exit 0)\n[INFO]  - Device internal-dpl-injected-dummy-sink: pid 4290 (exit 0)\n[INFO] Dumping used configuration in dpl-config.json\n[ERROR] SEVERE: Device TPCDigitizer_1 (4283) had at least one message above severity 5: Got nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and timestamp 1550600800000\nTASK-EXIT-CODE: 1\n <---- END OF LOGFILE  tf1/tpcdigi_1.log  -----\n```\nWould you be able to provide any suggestion on how to solve it? I see also there is an incongruence with the computed timestamp and with the timestamp that I should have obtained with the DPG formula: `1546300800 + 430 * ([run] - 300000)`. The timestamp I have is `1550600800000` while the timestamp I should have obtained is `1550600800` so three additional zeroes somehow...",
        "question": "What is the solution to the TPCDigitizer crashes due to nullptr from CCDB for path TPC/Calib/IDC_PadStatusMap_A and how to correct the timestamp discrepancy?"
    },
    {
        "source": "mattermost",
        "post_id": "9db4mmxepjgpzrf1x7gkqmc7gy",
        "create_at": 1706094749843,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Hello, I am getting the following error while accessing MCEventHeader branch in the o2sim_Kine.root:\n\nError in <TTree::SetBranchAddress>: Unable to determine the type given for the address for \"MCEventHeader.\". This is probably due to a missing dictionary, the original data class for this branch is o2::dataformats::MCEventHeader\n\nOnce before this error was fixed by correcting the order of header files in the code. But now the order is fine and this is still happening. What could be the reason?",
        "question": "What could be the reason for the error in determining the type for the \"MCEventHeader\" branch in the TTree, even though the order of header files is correct?"
    },
    {
        "source": "mattermost",
        "post_id": "jkk35djc538o9j4u11db6qzcmr",
        "create_at": 1706269890567,
        "user_id": "tchrdk7jtibcbbempsxh5bg8uc",
        "message": "Hello,\n\nHow should one turn off delta ray production when simulating with Geant4? Is it in the detector specific `simcuts.dat` file? Asking because I recall that this did not have an effect with Geant4 like a year ago, + I think it was said that these settings were to be moved somewhere else or something like that  :thinking_face: \n\nMany thanks!\n\ncc @upadhyay ",
        "question": "How should one turn off delta ray production when simulating with Geant4, and is it specified in the detector specific `simcuts.dat` file?"
    },
    {
        "source": "mattermost",
        "post_id": "juu4tif6xibpzbz1ngh5uwbhqr",
        "create_at": 1706270994468,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@mmolande : Do you mean globally or on specific detector levels?\n@mmolande : Do you mean globally or on specific detector levels?",
        "question": "Do you mean globally or on specific detector levels?"
    },
    {
        "source": "mattermost",
        "post_id": "mrs5af9kd38gdmx473y3xbkhfy",
        "create_at": 1706271187222,
        "user_id": "tchrdk7jtibcbbempsxh5bg8uc",
        "message": "Doesn't matter for this test, we run only FV0, so either global or detector level (but in either case so that it's not overridden by the other level)\nDoesn't matter for this test, we run only FV0, so either global or detector level (but in either case so that it's not overridden by the other level)",
        "question": "What level should we run the simulation at for this test, given that we only run FV0?"
    },
    {
        "source": "mattermost",
        "post_id": "51ptbfjxhf8gmdpw1p17rtojba",
        "create_at": 1706281228680,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Reading in the sim docs, https://aliceo2group.github.io/simulation/docs/transport/geometry.html?highlight=cuts, I believe the following approach should work (pinging @bvolkel as expert):\nReading in the sim docs, https://aliceo2group.github.io/simulation/docs/transport/geometry.html?highlight=cuts, I believe the following approach should work (pinging @bvolkel as expert):\na) extract a json file with all processes and cut values: (adjust geometry to your needs)\na) extract a json file with all processes and cut values: (adjust geometry to your needs)\n```\no2-sim-serial -n 0 -m FT0 PIPE -o bar --configKeyValues \"MaterialManagerParam.outputFile=o2_medium_params.json\"\n```\n```\no2-sim-serial -n 0 -m FT0 PIPE -o bar --configKeyValues \"MaterialManagerParam.outputFile=o2_medium_params.json\"\n```\nb) modify json with your choice of processes or cuts\nb) modify json with your choice of processes or cuts\n```\nreplace all \"DRAY\" : 1\nby \"DRAY\" : 0\n```\n```\nreplace all \"DRAY\" : 1\nby \"DRAY\" : 0\n```\nc) run simulation with this custom file\nc) run simulation with this custom file\n```\no2-sim --configKeyValues \"MaterialManagerParam.inputFile=o2_medium_params.json\" ...\n```\n```\no2-sim --configKeyValues \"MaterialManagerParam.inputFile=o2_medium_params.json\" ...\n```\nAs far as I understood, the new Geant4 version should honour these settings.\nAs far as I understood, the new Geant4 version should honour these settings.",
        "question": "What is the approach to modify the cut values in the simulation and run a custom simulation with these changes?"
    },
    {
        "source": "mattermost",
        "post_id": "gbmq17q61pgydmagme5mjg6pzc",
        "create_at": 1706693843730,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@mmolande : Did you make progress on the process disabling? If the process can't be disabled ... maybe setting the associated cut value to extremely high might be another idea. Eventually, we should discuss this need with @ihrivnac and see what can be done in Geant4_VMC.",
        "question": "Did you make progress on the process disabling? If the process can't be disabled, maybe setting the associated cut value to extremely high might be another idea. Eventually, we should discuss this need with @ihrivnac and see what can be done in Geant4_VMC."
    },
    {
        "source": "mattermost",
        "post_id": "3nknoktqtbrdurmyxuusm3586h",
        "create_at": 1706696870576,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Thanks @ihrivnac .\nSo you are saying, changing the process globally is fine, right? I always understood there was a problem with that. Or was that only with local settings per medium?\nIf the global setting **IS RECOGNISED**, then yes, @mmolande @upadhyay , you could try to change the default `DRAY` setting, in case you haven't done that yet",
        "question": "Is changing the `DRAY` setting globally recognized, or is it only an issue with local settings per medium?"
    },
    {
        "source": "mattermost",
        "post_id": "jscgtgg6zfn1fby371zgo7mk1w",
        "create_at": 1706703781704,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "@swenzel @bvolkel @mmolande \nSo, I tried this solution. But it does not work. I still see a majority of delta rays in the simulation. I will try the one by @ihrivnac ,i.e. gMC->SetProcess()\n@swenzel @bvolkel @mmolande \nSo, I tried this solution. But it does not work. I still see a majority of delta rays in the simulation. I will try the one by @ihrivnac ,i.e. gMC->SetProcess()",
        "question": "Why are there still a majority of delta rays in the simulation despite trying a solution?"
    },
    {
        "source": "mattermost",
        "post_id": "qbnmspua7jfyfdkbks6bm79iwa",
        "create_at": 1707291953012,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Hello everyone,\n\nFollowing up on the discussion from last Wednesday's meeting and the related thread in JIRA, I want to initiate a conversation about our needs for MC performance generators for code validation.\n\nAddressing the \"realistic use case,\" I'm sharing  a fragment from  JIRA post ([O2-4612](https://its.cern.ch/jira/browse/O2-4612?focusedId=5753074&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-5753074)):\n\nQuote: \"Thank you for providing the setup via the pull request. Matthias and I conducted a small-scale production at GSI of approximately 100 jobs and obtained our initial performance plot. However, for detailed performance parameterization and comparison with MC data, we realize the need for significantly larger statisticsâ€”approximately a 100-1000 fold increase, especially for conducting occupancy scans and analyzing high pt particles.\n\nDuring last Wednesday's meeting, I suggested using a performance generator similar to what I developed for Run2, which was also utilized in test grid production for software validation. This included a cocktail with the addition of flat q/pt jets and flat pdgCode of interest. This method seems more suitable for our current requirements, as it allows us to use minimal resources efficiently. In Run2, we typically used about 50-100 jobs, equivalent to a production scale 100-1000 times larger than MB production.\"\n\nThis highlights the necessity for a tailored approach to MC generation that can support our specific analytical needs with an efficient use of computational resources. I believe revisiting the concept of performance generators, akin to those used in Run2, could provide the flexibility and precision required for our current validation efforts.\n\nI look forward to your feedback and suggestions on this matter.\n\nBest regards,\n\nMarian\nHello @swenzel, @bvolkel, @morsch, and @hristov. As mentioned in the JIRA ticket quoted above ([O2-4612](https://its.cern.ch/jira/browse/O2-4612?focusedId=5753074&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-5753074)), we urgently need to conduct MC production to test the consequences of certain tracking modifications. As stated earlier, running minimum bias (MB) simulations is not feasible for us; we require a performance generator. **For the time being, any setup with enhanced jet samples would suffice. Could we arrange for such a setup in the short term, enabling us to perform a parameter scan at GSI? I assume you have something like that.**",
        "question": "Could we arrange for a setup with enhanced jet samples in the short term to enable a parameter scan at GSI?"
    },
    {
        "source": "mattermost",
        "post_id": "oa9debjnabn4mrxdsiexa8x5mc",
        "create_at": 1707321914741,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Hello @gconesab, @swenzel @bvolkel  and all.\n\nThank you for recipe. I tried the setting after the SC meeting, but I got some failures in grpcreation.\nhttps://gitlab.cern.ch/alice-tpc-offline/alice-tpc-notes/-/blob/95806a27cd95c772b9974fbf1ec09b8034c810e1/JIRA/O2-4612/mcTest.sh#L69-114\n\nI assume I used the same setting as your, but it was failing therefore I had to add rate, in addition I had to switch tpctimes to enabble skimming\n```\n  # create workflow\n  ${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM ${CONFIG_ENERGY} -col pp -gen pythia8 -proc \"jets\" \\\n                                              -ptHatMin ${PTHATMIN} -ptHatMax ${PTHATMAX}            \\\n                                              -tf ${NTIMEFRAMES} -ns ${NSIGEVENTS} -e ${SIMENGINE}   \\\n                                              -j ${NWORKERS} -mod \"--skipModules ZDC\"                \\\n                                              -weightPow ${WEIGHTPOW} \\\n                                              -interactionRate 500000\n  # run workflow\n  ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json   -tt tpctimes\n```\n\n\n*Job output:\n```\nOpen Pt-hat range set\nNamespace(run=300000, productionTag='unknown', timestamp=-1, conditionDB='http://alice-ccdb.cern.ch', condition_not_after=3385078236000, orbitsPerTF=128, anchor_config='', dump_config='user_config.json', ns='5', gen='pythia8', proc='jets', trigger='', ini='', confKey='', interactionRate='500000', bcPatternFile='', meanVertexPerRunTxtFile='', eCM='13000.0', eA=-1, eB=-1, col='pp', field='ccdb', with_qed=False, ptHatMin='5.0', ptHatMax='300.0', weightPow='6.0', embedding=False, embeddPattern='@0:e1', nb=20, genBkg='', procBkg='heavy_ion', iniBkg='${O2DPG_ROOT}/MC/config/common/ini/basic.ini', confKeyBkg='', colBkg='PbPb', e='TGeant4', tf='1', production_offset=0, j=8, mod='--skipModules ZDC', with_ZDC=False, seed=None, o='workflow.json', noIPC=None, upload_bkg_to=None, use_bkg_from=None, early_tf_cleanup=False, pregenCollContext=False, no_combine_smaller_digi=False, no_combine_dpl_devices=False, no_mc_labels=False, no_tpc_digitchunking=False, with_strangeness_tracking=False, combine_tpc_clusterization=False, first_orbit=0, sor=-1, run_anchored=False, alternative_reco_software='', dpl_child_driver='', include_qc=False, include_local_qc=False, include_analysis=False, mft_reco_full=False, mft_assessment_full=False, fwdmatching_assessment_full=False, fwdmatching_4_param=False, fwdmatching_cut_4_param=False, fwdmatching_save_trainingdata=False)\n** Using generic config **\nINFO: Written additional config key parameters to JSON user_config.json\nDiamond is\nUsing initialisation seed:  None\nALICEO2_CCDB_LOCALCACHE not set; setting to default /lustre/alice/users/miranov/NOTESData/alice-tpc-notes/JIRA/O2-4612/prodJet/dir0/ccdb\nTimeframe 1 seed:  202040861\n=== There are 0 warnings ===\n=== There are 0 errors ===\n===> The workflow looks sane\nWorkflow saved at workflow.json\nLaunching task: o2-grp-simgrp-tool createGRPs --timestamp 1546300800000 --run 300000 --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf 128 --field ccdb --readoutDets all --print  &> grpcreate.log &\nLaunching task: [ \"${O2DPG_ENABLE_TPC_DISTORTIONS}\" ] || { ${O2_ROOT}/bin/o2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch -p TPC/Calib/CorrectionMapRef --timestamp 1 --created-not-after 3385078236000 -d ${ALICEO2_CCDB_LOCALCACHE} ; ${O2_ROOT}/bin/o2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch -p TPC/Calib/CorrectionMap --timestamp 1 --created-not-after 3385078236000 -d ${ALICEO2_CCDB_LOCALCACHE} ; } &> tpc_spacecharge_downloader.log &\nLaunching task: ${O2DPG_ROOT}/MC/config/common/pythia8/utils/mkpy8cfg.py --output=pythia8.cfg --seed=202040861 --idA=2212 --idB=2212 --eCM=13000.0 --eA=-1.0 --eB=-1.0 --process=jets --ptHatMin=5.0 --ptHatMax=300.0 --weightPow=6.0 &> gensgnconf_1.log &\ncommand o2-grp-simgrp-tool createGRPs --timestamp 1546300800000 --run 300000 --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf 128 --field ccdb --readoutDets all --print  had nonzero exit code 134\nStop on failure  True\nsetting up ROOT system\ngrpcreate failed ... checking retry\n```",
        "question": "What settings did you use and why did you encounter failures in grpcreation?"
    },
    {
        "source": "mattermost",
        "post_id": "uu8fbceftjdipbfssb8brp31ec",
        "create_at": 1707321943419,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "what does `grpcreate.log` say?",
        "question": "what does `grpcreate.log` say?"
    },
    {
        "source": "mattermost",
        "post_id": "5o6ijkibqibqfgn4ripedezoso",
        "create_at": 1707322189097,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Thanks. I will try to change http_server. Indeed we had similar problems before. I will update soon.\n\n```\n[INFO] file grp_grpecs.root copied/published to \"/lustre/alice/users/miranov/NOTESData/alice-tpc-notes/JIRA/O2-4612/prodJet/dir0/ccdb/GLO/Config/GRPECS/snapshot.root\"\n[INFO]  --- creating magfield GRP -----\n[INFO] Downloading mag field directly from CCDB\n[INFO] Fetching GLO/Config/GRPMagField from CCDB\nError in <TJAlienFile::Open>: No JAliEn Grid connection available!\n[ERROR] Failed to open file alien:///alice/data/CCDB/GLO/Config/GRPMagField/06/62924/01d633ab-efdf-11ec-841e-2a010e0a0b16?filetype=raw\n[ERROR] Unable to find object GLO/Config/GRPMagField/1546300800000, Aborting\n[FATAL] Downloading mag field failed\nFor later analysis we write a core dump to core_dump_47651\n./grpcreate.log_tmp.sh: line 4: 47651 Aborted                 o2-grp-simgrp-tool createGRPs --timestamp 1546300800000 --run 300000 --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf 128 --field ccdb --readoutDets all --print\nTASK-EXIT-CODE: 134\n```",
        "question": "What is the error and how can it be resolved when downloading the magnetic field file from CCDB in the ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "yz4nsmsjqirsi85qmgaymtsbha",
        "create_at": 1707323699590,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Indeed, the issue was related to the http_proxy at GSI/ Problem which I resolved 10 minutes ago\n\n* alien.py was working.\n* ( TGrid::Connect(\"alien\") was failing\n\nI have resolved the issue, and the MC has been running for a while now.  No crash so far, but not results yet.\n I will provide an update if there are any problems or questions. I do have a question already. We are interested in testing not only reconstruction skimming but also time series analysis.\n\nFor the time series analysis, we need to simulate \"time-Orbits\". Is this easily configurable? It can be addressed later, but if it's straightforward, I might attempt to run that part as well.\n\n* Pilot jobs finished - resuls looks \"reasonable\" - I submit first production\nIn case I want to make rate scan - what is the optimal way  to simulate occuancy from 0 to 50 kHz PbPb, using switches which we have?\nHello @bvolkel, @gconesab, @swenzel, and @Jens,\n\nThe first production with the default settings has been completed, and as I previously explained, using approximately 100 jobs each running for 2 hours on our server, I have gathered sufficient statistics for differential performance parameterization. As mentioned before, we aim to conduct an occupancy scan, emulating the Interaction Rate (IR) from 500 kHz to 5 MHz.\n\nCould you advise on the preferred method for implementing this with the Jet setup? I am currently running the following configuration:\n\n```bash\n\n  # create workflow\n  ${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM ${CONFIG_ENERGY} -col pp -gen pythia8 -proc \"jets\" \\\n                                              -ptHatMin ${PTHATMIN} -ptHatMax ${PTHATMAX}            \\\n                                              -tf ${NTIMEFRAMES} -ns ${NSIGEVENTS} -e ${SIMENGINE}   \\\n                                              -j ${NWORKERS} -mod \"--skipModules ZDC\"                \\\n                                              -weightPow ${WEIGHTPOW} \\\n                                              -interactionRate 500000\n```\nI understand that the combination of **ns, tf, and interaction rate** parameters should enable me to achieve the desired rate and target statistics. However, I am unsure how to accurately submit rates for a uniform rate distribution from 100 kHz to 3 MHz while aiming for an integral of 10^6 events. Could you clarify how exactly these three parameters are interpreted? I can envision different interpretations.\n\nThank you for your guidance.\nIn the initial test, I observed a relatively narrow multiplicity distribution. Below, I've plotted the DCA resolution ()y for high-momentum tracks (>5 GeV) as a function of TPC occupancy (x axis)- number of tracks. Now, we need to constrain it within the following occupancy ranges such that we will have the same coverage in the data and in the MC.\n\n",
        "question": "What is the optimal way to simulate occupancy from 0 to 50 kHz PbPb using the Jet setup in ALICE O2 simulations, and how should the parameters `ns`, `tf`, and `interaction rate` be configured to achieve this?"
    },
    {
        "source": "mattermost",
        "post_id": "zi788bp4ybya5pm5ogucfcp69y",
        "create_at": 1707378304011,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Hi @mivanov. The number of events **doable/fitable** per timeframe is of course dependent on the interaction rate. If the interaction rate is small, you may not fit 2000 pp events in a timeframe. In this case, we have 2 useful mechanisms: (a) add `--pregenCollContext` to the command line of o2dpg_sim_workflow.py. (b) inspect the file '0_0_0_<N>.stat' created after AOD creation and interpret N as the number of events actually simulated. You can then setup a self-consistent system to always achieve the same total number of events. Alternatively, simply calculate the mean number of events per timeframe in advance using interaction rate and length of timeframe (for unanchored MC = 128 orbits). And scale the number of jobs accordingly. I would always put the option `--pregenCollContext`. The number given by `-ns` then signifies just an upper limit of events per timeframe.",
        "question": "What are the mechanisms to ensure a consistent number of events per timeframe when the interaction rate is low in ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "sremafead7rhbmdkrwjx9krfxc",
        "create_at": 1707382952293,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Hello @swenzel, @bvolkel and @gconesab \n\nThank you, everyone.\n\nI have three questions before I proceed further with interaction rate scan at GSI:\n\n- **Relation Between the Number of Collisions, Interaction Rate, and the Length of Time Frame:** It seems to be overdetermined. Providing the interaction rate, fixing the time frame to 128 orbits, and selecting the number of time frames, the number of collisions per time frame is determined. If we provide all the information:\n   - Number of collisions\n   - Interaction rate\n   - The length of time frame (expected to be fixed)\n   \n   Which number will be prioritized?\n\n- **Output from Production Missing AOD Files:** In the output from the production, all reconstruction was extracted, including or except for skimmed data, but not the AOD file. It seems I am missing something in the script. I didn't spot it in the first submission as I didn't use them, but now we would like to run standard AO2D analysis on top of that data. I assume should be simple swith.\n\n- **For Gustavo - Jet Generation:** How are the jets generated in each collision? We will need a significant fraction of minimum bias (MB) collisions and a fraction of collisions with jets, e.g., 70:30% or 80:20%, to have most of the data with \"realistic\" properties otherwise the \"vertexing and efficiency will  overoptimistic - have very weel defined vertex properties.\n\nFor point 1, I would like to delve into more details: What happens if we provide all the information listed? How is the system reconciled, and which parameters take precedence?\n\nYour guidance and clarification on these matters would be greatly appreciated.\n\n",
        "question": "- **Relation Between the Number of Collisions, Interaction Rate, and the Length of Time Frame:** What happens if we provide all the information (number of collisions, interaction rate, and the length of time frame)? How is the system reconciled, and which parameters take precedence?"
    },
    {
        "source": "mattermost",
        "post_id": "4fyztmx4n3b43kdbr1yttqcycw",
        "create_at": 1707386676012,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Hello @swenzel and @gconesab \n\n1. **Interaction Rate and Collision Integral:** If it's true that the simplest way to conduct a rate scan is by submitting jobs with incrementally increasing interaction rates while keeping the integral number of collisions constant, do I still need to specify the `ns` flag, or will its value be automatically assigned?\n\n2. **Workflow Submission Clarification:** I'm unsure if I've fully understood the submission process. Is it necessary to execute the workflow twice as shown in the following snippet?\n\n    ```bash\n      # create workflow\n      ${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM ${CONFIG_ENERGY} -col pp -gen pythia8 -proc \"jets\" \\\n                                                  -ptHatMin ${PTHATMIN} -ptHatMax ${PTHATMAX}            \\\n                                                  -tf ${NTIMEFRAMES} -ns ${NSIGEVENTS} -e ${SIMENGINE}   \\\n                                                  -j ${NWORKERS} -mod \"--skipModules ZDC\"                \\\n                                                  -weightPow ${WEIGHTPOW} \\\n                                                  -interactionRate 500000\n      # run workflow\n      ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt tpctimes\n      ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt aod\n    ```\n\n3. **Jet Trigger Configuration for Realistic Physical Background:** As mentioned earlier, I aim to replicate the Run1/2 performance generator setup, which allowed specifying a random fraction for signal enhancement. If the current generator setup doesn't yield a realistic physical background and tends to overestimate occupancy and multiplicity, as seen in my occupancy estimations from skimmed data, I'd prefer to adjust this via a configuration parameter if possible. Otherwise, I'll proceed with the current setup and make necessary rate corrections.\n\nYour advice on these matters would be greatly appreciated.\n\n\n",
        "question": "1. Do I still need to specify the `ns` flag when incrementally increasing interaction rates while keeping the integral number of collisions constant?\n2. Is it necessary to execute the workflow twice as shown in the snippet?\n3. How can I adjust the jet trigger configuration to yield a more realistic physical background?"
    },
    {
        "source": "mattermost",
        "post_id": "j75744xrtino7c3ahq4dwewjpw",
        "create_at": 1707399938662,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Dear @gconesab \n\nI see you post was deleted. \n\nTo start a new simulation, I wonder if it is possible to use the standard jet generator and include MB events ( minimum bias) to achieve a realistic multiplicity distribution. Currently, the occupancy is roughly estimated to be three times higher than what is observed in MB data, and furthermore, the vertexing performance is significantly better for jet events. This discrepancy is crucial as vertex monitoring and DCA monitoring are important observables in our performance parameterisation, which we are obtaining as part of the MC/Data test.\n\nIs there a function to set the fraction of signal collisions relative to MB events, or should I continue with the current setup, taking Sandro's recent advice into account?",
        "question": "Is there a function to set the fraction of signal collisions relative to MB events, or should I continue with the current setup?"
    },
    {
        "source": "mattermost",
        "post_id": "ggo9q1z39fnfu8k9x8yy5ybebe",
        "create_at": 1707400368016,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Thank you @gconesab, indeed I did not spot it.\n\n@swenzel and @bvolkel , can you comment also on point 3 \n\n",
        "question": "Can @swenzel and @bvolkel comment on point 3?"
    },
    {
        "source": "mattermost",
        "post_id": "ptweg9mg9p8wicoon1ubhi1afr",
        "create_at": 1707400921436,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "I can't. Generator experts from PWGs would be a more suitable source of information.",
        "question": "What is the best source of information for running ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "udtrm3ebctdq3qq5g96rsm1uya",
        "create_at": 1707401221089,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Who should I contact? @morsch ?",
        "question": "Who should I contact? @morsch?"
    },
    {
        "source": "mattermost",
        "post_id": "sbst8fdc6inwxrtyk8uihgotxo",
        "create_at": 1707401718765,
        "user_id": "ztcwo5f54pdz9jbxbyf55aakrc",
        "message": "I do not think  that in the PWGJE this kind of configuration has been even considered. I think other PWG have something like that (without jets but injecting particles),  I have no idea how to do it.",
        "question": "How can I configure the simulation to inject particles without using jets, similar to what might be available in other PWGs?"
    },
    {
        "source": "mattermost",
        "post_id": "oz6xwcycftyn5rbcszdd4xy1xo",
        "create_at": 1707402019762,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "For any kind of signal injection, I could also imagine that PWGLF might have some expertise",
        "question": "Could PWGLF have expertise for any kind of signal injection?"
    },
    {
        "source": "mattermost",
        "post_id": "admes4ucnjr5bp6zwft5djxk5e",
        "create_at": 1707404169232,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": "Is there a method to share my code on GitHub, allowing you to provide comments, especially if the configuration is complex? We are currently using a private tpc-gitlab repository.",
        "question": "Is there a method to share my code on GitHub for you to provide comments, especially if the configuration is complex, when we are currently using a private tpc-gitlab repository?"
    },
    {
        "source": "mattermost",
        "post_id": "ftxup58kyibotddypnfcg4os7y",
        "create_at": 1707404539971,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "For your point 3, do I understand correctly that you want jet less events injected in between jet events?\nI believe that is similar to HF was doing with the gap trigger technique: https://github.com/AliceO2Group/O2DPG/blob/master/MC/config/PWGHF/external/generator/generator_pythia8_gaptriggered_hf.C\nMaybe there's a way to check for wether the event had a jet in pythia like HF looks for wether the event has a HF particle in it\nIt's different to how the jet mc is currently setup though. We only ask pythia add a bias with the PhaseSpace:bias2SelectionPow variable \nSo if you use the gap trigger technique with this current setup I don't think your jetless events would be MB",
        "question": "Do I understand correctly that you want jet-less events injected in between jet events?"
    },
    {
        "source": "mattermost",
        "post_id": "87miqtqhopbeffbfniiz8785kr",
        "create_at": 1707406582202,
        "user_id": "i9jam9rsxby85yhhne63397zxw",
        "message": ">>> So if you use the gap trigger technique with this current setup I don't think your jetless events would be MB\n\nOK. For a moment I will run what is avaiable now.\n\nIn the performance generators used for Run2 productions, I managed to add particles to the cocktail described by  user defined probabilities. I just look how i implemented it using AliPythia and Pythia 6 ().  This approach, if adopted as a general option, could have wide-ranging applicability.\n\nWe need a performance generator that can accurately simulate the background and introduce signals randomly, according to parameterizations defined by detector and reconstruction specialists. I am not sure if the method you've described achieves this goal. \n\nFor Run2, our cocktail included paramtereizble  admixture of:\n\n* Proability to inser signal\n* Flat qpt\n* Flat pdg code, as configured in an array\n* Kinematic distribution\n\nThis strategy allowed for a more dynamic and realistic simulation of particle events, tailored to the specific needs of our analyses. \nDo we have in O2 something with this functionality?\n\n\n\n\n\n",
        "question": "Do we have in O2 something with the functionality to introduce signals randomly according to parameterizations defined by detector and reconstruction specialists?"
    },
    {
        "source": "mattermost",
        "post_id": "8tbhae65m7yejp7pyxuuhjchca",
        "create_at": 1708102880427,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "Hi, I am having an issue when dumping the ```o2_dpg_workflow_runner.py``` output to file by adding the option ```--produce-script my_script.sh``` . The error I get is:\n```Traceback (most recent call last):\n  File \"/home/fmazzasc/alice/sw/ubuntu2004_x86-64/O2DPG/master-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1734, in <module>\n    exit (executor.execute())\n  File \"/home/fmazzasc/alice/sw/ubuntu2004_x86-64/O2DPG/master-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1600, in execute\n    self.produce_script(args.produce_script)\n  File \"/home/fmazzasc/alice/sw/ubuntu2004_x86-64/O2DPG/master-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1491, in produce_script\n    for e in self.globalenv:\nAttributeError: 'WorkflowExecutor' object has no attribute 'globalenv```\n\nI did few checks and it seems that the error is caused by this PR: https://github.com/AliceO2Group/O2DPG/commit/ec4acee8f0d38616b6fa45809661213c9b938acc\nReverting the commit avoided the crash. \n@swenzel , @bvolkel  could you have a look?",
        "question": "What is the issue when using the `--produce-script` option with `o2_dpg_workflow_runner.py`, and is this related to a specific commit?"
    },
    {
        "source": "mattermost",
        "post_id": "f45g78mezjfcbe7jr9yhp66f6h",
        "create_at": 1708429351477,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "Hi, I am following the instructions given at the tutorial for launching few jobs on the grid for testing purpose (https://indico.cern.ch/event/1368037/contributions/5801215/attachments/2796791/4878921/MC_Tutorials.pdf)\nThe simulations always fail before starting and the jobs go into ```EE```   status.\nI am attaching the stdout, the error I get is:\n```BASH_FUNC_failhook()=() {  notify_mattermost \"${ALIEN_PROC_ID}: **Failure** in stage $2\";\n cp alien_log_${ALIEN_PROC_ID:-0}.txt logtmp_${ALIEN_PROC_ID:-0}_failure.txt;```\n\nIs there anything I am missing?",
        "question": "What could be the reason for the simulations failing before starting and going into `EE` status?"
    },
    {
        "source": "mattermost",
        "post_id": "bse5t1ju9trkbfthk6quqnjoic",
        "create_at": 1708433261660,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "\n```${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM 13600 -col pp -gen pythia8 -proc cdiff -tf 1 -ns 200 -e TGeant4 -interactionRate 500000```\n```${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt aod --cpu-limit 8 --produce-script myscript.sh```\n\nThen, to submit the job I do:\n```${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script myscript.sh --jobname mytest --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240210-1\" --wait --f\netch-output```",
        "question": "What are the commands and steps to run ALICE O2 simulations using the provided scripts and submit the job to a grid system?"
    },
    {
        "source": "mattermost",
        "post_id": "j6bwqr3yg7ya7qfwmptqg573pa",
        "create_at": 1708445818542,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi, I am trying to run Pythia to be able to perform some targeted EMCAL studies. I am using the following commands:\n```\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM 13600  -col pp -gen pythia8 -proc cdiff -tf 1 -ns 1000 -j 10 -interactionRate 769  -run 529006\n${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt emcreco_1 --cpu-limit 8\n```\nBut at the moment I am not even able to run it either with the following output `Apparently some of the chosen target tasks are not in the workflow`. Would you be able to advise on how to proceed? Thanks a lot",
        "question": "Why am I getting the error \"Apparently some of the chosen target tasks are not in the workflow\" when trying to run the simulations, and how can I proceed?"
    },
    {
        "source": "mattermost",
        "post_id": "h3amc7zxq7rgfrbwucr6d3k4ee",
        "create_at": 1708529216363,
        "user_id": "wiackyom7pnmdeuq9cjxg7ya1e",
        "message": "Dear all,\nI have a question about the ```fromBackgroundEvent``` flag in the ```McParticles``` table. This flag intended to be used to check if the particle actually belongs to the selected collision or is wrongly associated to it, right? If yes, how is the correct usage of it? Because is was running some tests, where I selected protons and the flag is true for all protons that I selected (at least in the files I used for testing, which are from the datasets 23k2c_pass4 (anchored to pp of 2022) and 21k6_pp)",
        "question": "What is the correct usage of the ```fromBackgroundEvent``` flag in the ```McParticles``` table, and why is it true for all selected protons in my tests using datasets 23k2c_pass4 and 21k6_pp?"
    },
    {
        "source": "mattermost",
        "post_id": "4mjbz9k6pjf39bmkxtgqng3aco",
        "create_at": 1708953866498,
        "user_id": "bbty4qgeoidddjxb9ewfrob3ec",
        "message": "Hello experts,\nThere was a problem installing AEGIS during O2sim installation\nI've attached the logs\nIt seems that the nlohmann/json library is causing the problem.\nIf anyone knows a solution, please let me know.\n",
        "question": "What is the solution to the problem with the nlohmann/json library during the O2sim installation?"
    },
    {
        "source": "mattermost",
        "post_id": "x1kd5zgkqbn79r77hn3ncozq5r",
        "create_at": 1709034304603,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI'm trying to run a simulation workflow on the grid\nUnfortunately, I have an error when trying to submit the job\nBelow is the log. How can I solve this?\n```\n[O2sim/latest] ~/alice/MyWorkDir/MCtests/testHF_5evts %> ${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script ~/alice/O2DPG/MC/run/PWGGAJE/run_jets_HF_ccbar.sh --jobname testAIMERIC --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240226-1\" --wait --fetch-output\nUsername: alandou\n  Full name: Aimeric Robin Landou\n  Roles: alandou\n  Email: aimeric.landou@cern.ch\n  Subject: /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=alandou/CN=836451/CN=Aimeric Landou\nYour job's working directory will be /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nSet the job name by running /Users/landou/alice/sw/osx_arm64/O2DPG/master-local3/GRID/utils/grid_submit.sh <scriptname> <jobname>\nFound OutputSpec to be *.log@disk=1,*.root@disk=2\nFound ErrorOutputSpec to be \nFound Container Image to be \nFound PackagesSpec to be VO_ALICE@O2sim::v20240226-1\nLocal working directory is /Users/landou/alice/sw/osx_arm64/O2DPG/master-local3/GRID/utils\nPreparing job \"testAIMERIC-20240227-114318\"\nSubmitting job \"testAIMERIC-20240227-114318\" from /Users/landou/alice/sw/osx_arm64/O2DPG/master-local3/GRID/utils\nJob submission failed: error log follows\nWelcome to the ALICE GRID\nsupport mail: adrian.sevcenco@cern.ch\n\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory: /alice/cern.ch/user/l/landou/selfjobs\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory: /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory: /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318/output\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >Input/output error : Failed to remove [/alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318/testAIMERIC-20240227-114318.sh]\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory (or non-existing parents): /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory (or non-existing parents): /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >No such file or directory : Could not create directory (or non-existing parents): /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >Remote I/O error : Not able to get the file /alice/cern.ch/user/l/landou/selfjobs/testAIMERIC-20240227-114318/testAIMERIC-20240227-114318.jdl\nAliEn[alandou]:/alice/cern.ch/user/a/alandou/ >Exit\n```",
        "question": "How can I solve the error when submitting a simulation job on the grid, specifically the \"No such file or directory\" and \"Remote I/O error\" issues?"
    },
    {
        "source": "mattermost",
        "post_id": "ahzqcm6us3g6mng5apwkjj6w8w",
        "create_at": 1709043958301,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, I'm testing a simulation workflow on lxplus (to be tested on grid) using a modified version of $O2DPG_ROOT/MC/run/PWGGAJE/run_jets.sh. When testing using O2sim/v20240220-1 or later I get an error, I attach the terminal output along with the modified script and the log file of the task that it is failing on (restdigi_1) . Any ideas on how to solve this would be much appreciated.\n\nNote that earlier O2sim versions seem to run OK 'locally', but aren't able to produce a script to run on the grid with the option '--produce-script my_script.sh', with an error that I understood from a recent message on this channel was fixed on Feb 19th.\nHi all, I'm testing a simulation workflow on lxplus (to be tested on grid) using a modified version of $O2DPG_ROOT/MC/run/PWGGAJE/run_jets.sh. When testing using O2sim/v20240220-1 or later I get an error, I attach the terminal output along with the modified script and the log file of the task that it is failing on (restdigi_1) . Any ideas on how to solve this would be much appreciated.\n\nNote that earlier O2sim versions seem to run OK 'locally', but aren't able to produce a script to run on the grid with the option '--produce-script my_script.sh', with an error that I understood from a recent message on this channel was fixed on Feb 19th.",
        "question": "What is the error I encounter when using O2sim/v20240220-1 or later, and how can I solve it?"
    },
    {
        "source": "mattermost",
        "post_id": "5sncwsn5qpf69dz9ps4ygbdkjc",
        "create_at": 1709051384173,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Please report the exact lxplus server and whether the error is reproducible. (I suspect it could be a platform / software incompatibility issue between the lxplus OS and the binaries on cvmfs ... or some dirty environment). Please note that on the GRID we use an additional containerization layer which is not present on lxplus, ... and the 2 are not 1-1 the same.\nPlease report the exact lxplus server and whether the error is reproducible. (I suspect it could be a platform / software incompatibility issue between the lxplus OS and the binaries on cvmfs ... or some dirty environment). Please note that on the GRID we use an additional containerization layer which is not present on lxplus, ... and the 2 are not 1-1 the same.",
        "question": "Please report the exact lxplus server and whether the error is reproducible."
    },
    {
        "source": "mattermost",
        "post_id": "bxxzk9a197rkdgjwctg61biymy",
        "create_at": 1709051995479,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "I am having another issue. I tried adapting the above `run_jets.sh` script for an anchored production (see attached `run_jets_anchored.sh` file). It seems to run without any error message, however I only have 1 dataframe and 5 collisions in the resulting AO2D instead of the 20 and 100 I asked for;\nAm I supposed to do some cleaning after I run a task on the grid? or will they be overwritten whenever I run another production on the grid",
        "question": "Am I supposed to do some cleaning after I run a task on the grid, or will they be overwritten whenever I run another production on the grid?"
    },
    {
        "source": "mattermost",
        "post_id": "3gn9r9ouq7rifd1h44razffoor",
        "create_at": 1709055970778,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi Sandro, I was logged into lxplus928 if this is what you mean. I discussed with Aimeric privately and I am now able to successfully run the jobs to the grid instead, though would still like to understand the issue with running directly on lxplus (unless its not recommended for the reasons you mention?)\nHi Sandro, I was logged into lxplus928 if this is what you mean. I discussed with Aimeric privately and I am now able to successfully run the jobs to the grid instead, though would still like to understand the issue with running directly on lxplus (unless its not recommended for the reasons you mention?)",
        "question": "Would it not be recommended to run jobs directly on lxplus for ALICE O2 simulations, and if so, why?"
    },
    {
        "source": "mattermost",
        "post_id": "6axn5rsxz3nkzrhprca9jkmpth",
        "create_at": 1709108776160,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Let me take a look!\nTwo questions @alandou :\n1. where does `${WEIGHTPOW}` come from?\n1. could you send me the log `async_pass_log.log` in case you have it available?",
        "question": "1. Where does `${WEIGHTPOW}` come from?\n2. Could you send me the log `async_pass_log.log` if it is available?"
    },
    {
        "source": "mattermost",
        "post_id": "rour61aqffyoxbhyx6brrubrdy",
        "create_at": 1709112389014,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Sure, but it does not seem to be defined in the shell script shared by @alandou \nThis is why I asked.",
        "question": "What is the variable or configuration that is not defined in the shell script shared by @alandou?"
    },
    {
        "source": "mattermost",
        "post_id": "m7kfjaf1f3rpuxtqprnryr5ije",
        "create_at": 1709114226791,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "And if you have the `timestampsampling_<runnumber>.log` that would also be helpful",
        "question": "What is the helpfulness of having the `timestampsampling_<runnumber>.log` file?"
    },
    {
        "source": "mattermost",
        "post_id": "etsf9d4g67ncjy7h7n88u4d3hy",
        "create_at": 1709545881368,
        "user_id": "ena3w9mrkpfb5mpz7n1ms4g6oc",
        "message": "Dear experts, I would like to add files and scripts to simulate bb -> mumu with natural decays to the O2DPG/MC/PWGDQ. This includes modifications to GeneratorBeautyToMu_EvtGenFwdY(). Could you have a look at my Pull Request and approve it if it is acceptable?\n[AliceO2Group/O2DPG#1504](https://github.com/AliceO2Group/O2DPG/pull/1504)",
        "question": "Could you review and approve my Pull Request to add files and scripts for simulating bb -> mumu with natural decays, including modifications to GeneratorBeautyToMu_EvtGenFwdY()?"
    },
    {
        "source": "mattermost",
        "post_id": "w7t7a6z44fn8bn7edke4ozfcge",
        "create_at": 1709551432193,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI tried running a workflow on the grid; it failed however I don't understand what the error is.\nHere is the link to the stdout log : https://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3031344161\nThe script I used is as follow:\n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_jets_HF_ccbar.sh --jobname hfJetsCCBAR10k --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240226-1\" --wait --fetch-output --asuser alandou\n```",
        "question": "What is the error in the workflow run on the grid, and how can I interpret the error from the provided stdout log?"
    },
    {
        "source": "mattermost",
        "post_id": "ehyh6k6g4jgwdxu1giwgf39jkr",
        "create_at": 1709552234148,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "I see the return code was 137. It was killed.\nFrom the process' trace I see\n```\nMar 03 17:43:41 [trace ]: Killing the job (it was running for longer than its TTL)\nMar 03 17:43:44 [trace ]: JobWrapper: SIGTERM received. Killing payload and proceeding to upload.\nMar 03 17:43:58 [proc ]: Execution completed. Time spent:\nMar 03 17:43:58 [trace ]: Payload killed. Executable exit code was 137 \n```\nNote that it ran almost for 24h and wasn't even finished with the AODs, only the 12th TF was finished; everything after would have still need to run",
        "question": "What caused the job to be killed and what was the exit code?"
    },
    {
        "source": "mattermost",
        "post_id": "eistjudw9jyy3yucwmja69hfaw",
        "create_at": 1709650896343,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "I could try to play with this\nI am not sure whether that is the only issue though, because while that failed test above was trying to run 10 events with a single time frame, I had managed a few days ago to run successfully a 10TF 100evts/TF job of the same sim script within 2575 seconds (/alice/cern.ch/user/a/alandou/selfjobs/testAIMERIC3-20240228-131858) ; the only thing I changed is the nubmer of TF and events\n",
        "question": "What is the difference in performance between running a 10 events with a single time frame and running a 100 events per time frame job?"
    },
    {
        "source": "mattermost",
        "post_id": "51aogz3g8prutg7pxg5ir77djo",
        "create_at": 1709651574289,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Is it same script and therein same run number in both cases?\nOr did you change the run number at some point?\nBecause the interaction rate can make a big difference and is orders of magnitude apart for pp and PbPb.\n\nDepending also on what you generate. Is it pp?",
        "question": "Is it the same script and run number in both cases, or did you change the run number at some point? Depending on what you generate, is it pp?"
    },
    {
        "source": "mattermost",
        "post_id": "sjaz4hubnif79kqx4m1mamrd8w",
        "create_at": 1709655803450,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Ah, I thought you were still running something via the anchorMC.sh script.\nI understood that you did that before.\n\nOn which machine are you running? Do you have 32 cores available?",
        "question": "On which machine are you running? Do you have 32 cores available?"
    },
    {
        "source": "mattermost",
        "post_id": "7n4abgbqfp8u8c78ttjmfna8ec",
        "create_at": 1709713157491,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "I would appreciate if Pythia8 experts could take a look in this bug report: [O2-4699](https://its.cern.ch/jira/browse/O2-4699)",
        "question": "Can Pythia8 experts review the bug report O2-4699?"
    },
    {
        "source": "mattermost",
        "post_id": "tw8gojknhtfj8r4bgubqir65dw",
        "create_at": 1709911083230,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI am continuing to try running a simulation with anchoring. We have already generated a first production without anchoring a few months ago, without issue ([run_jets.sh](https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGGAJE/run_jets.sh)). I am trying to adapt it to work with anchoring (see attached run_jets_anchored.sh script).\nI am running said anchored script on the grid with the following command, but cannot get any AO2D:\n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_jets_anchored.sh --jobname testJetAnchoredLHC22f_20Evts --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240305-1\" --wait --fetch-output --asuser alandou\n```\nLooking at the logs (https://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3035185901), I see that there seems to be a problem with gensgnconf (signal configuration?), though I am not sure why the anchoring causes this nor what is happening at this gensgnconf step:\n- in `pipeline_action_xxxx.log` files: `INFO Stoping pipeline due to failure in stages with PID [1801, 1903]`, with tasks 1801 and 1903 being `gensgnconf_1`and `gensgnconf_2`\n- in `logtmp_xxxxxx.txt` files, I get a `[ERROR] run with echo in pipe` line with a long json like suite of settings for a workflow resulting from the command `    \"command\": \"cvmfsLongPathName/o2-create-aligned-geometry-workflow --configKeyValues HBFUtils.startTime=1657457522166 --condition-remap=file:///workdir/ccdb=ITS/Calib/Align -b\"` followed by `gensgnconf_1 failed ... checking retry` (or gensgnconf_2) lines\n\nWhat is this gensgnconf step?\nAny ideas about what is the issue or how I could solve it?",
        "question": "What is the gensgnconf step and what could be causing the issue during the simulation with anchoring?"
    },
    {
        "source": "mattermost",
        "post_id": "bktt46cxqjduiytt1kekrrhn8w",
        "create_at": 1709911932490,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "There seems to be a problem with some paths. Give me a minute\nWhat seemed to have failed is this line: https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/ANCHOR/anchorMC.sh#L224\n\nTo check, ran \n```bash\no2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch/ -p \"ITS/Calib/Align\" -d ccdb --timestamp 1\n```\nand it works just fine. This also seemed to have worked fine in your case since I see\n```\nQuerying host http://alice-ccdb.cern.ch/ for path(s) ITS/Calib/Align ... and timestamp 1\nInfo in <TJAlienConnectionManager>: Successfully connected to JBox\nInfo in <TJAlienFile::Open>: Accessing file /alice/data/CCDB/ITS/Calib/Align/09/16940/f7db4c84-bc3e-11ec-b66d-2a010e0a0b16 in SE <ALICE::CCIN2P3::SE>\n[INFO] ccdb reads http://alice-ccdb.cern.ch/ITS/Calib/Align/1/f7db4c84-bc3e-11ec-b66d-2a010e0a0b16 for 1 (retrieve, agent_id: wn0258.m45.ihep.su-1709910683-Hj7tf9-2963436952),\n```\n\nHowever, somehow the snapshot doesn't seem to be created in your case whereas I have `ccdb/ITS/Calib/Align/snapshot.root`\n\nNote, that afterwards, it just continues to run so the second problem of `gensgnconf_1` might not be genuine.\n\nIn general, have you tried to run that locally on your computer @alandou ? Like 1 TF and a few events, just to x-check?",
        "question": "What seems to be the issue with the path in the line https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/ANCHOR/anchorMC.sh#L224, and why doesn't a snapshot get created in your case while it does in mine?"
    },
    {
        "source": "mattermost",
        "post_id": "8ukridkcrigtipm1mxs8gnpsny",
        "create_at": 1709915137420,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "I had not; can I simply run the same run_jets_anchored.sh script? I tried but it doesn't work\n```\n[O2sim/latest] ~/alice/O2DPG/MC/run/PWGGAJE %> sh run_jets_anchored.sh \n \nSubstituting ALIEN_JDL_LPMPRODUCTIONTAG=LHC22f999 with ALIEN_JDL_LPMANCHORPRODUCTION=LHC22f for simulating reco pass...\n[INFO alien_setenv_extra.sh] setenv_extra.sh was found in the current working directory, use it.\n[INFO alien_async_pass.sh] Setting up DPGRECO to ./async_pass.sh\nsed: 1: \"setenv_extra.sh\": bad flag in substitute command: 'x'\nsed: 1: \"async_pass.sh\": command a expects \\ followed by text\nRECO finished with 6\n```\nin async_pass_log.log:\n```\nsetenv_extra.sh: line 314: syntax error in conditional expression: unexpected token `('\nsetenv_extra.sh: line 314: syntax error near `@(L'\nsetenv_extra.sh: line 314: `  elif [[ $PERIOD == @(LHC22c|LHC22d|LHC22e|JUN|LHC22f) ]]; then'\n```",
        "question": "Can I simply run the `run_jets_anchored.sh` script to simulate reco pass, and what does the error mean?"
    },
    {
        "source": "mattermost",
        "post_id": "9ryqdiq85ffzipioytpnwdkk4h",
        "create_at": 1710169192465,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "I tried the same command on lxplus (with O2sim/v20240309-1):\nI'm still getting similar messages in `pipeline_action_xxxx.log`and `logtmp_xxxxxx.txt` files:\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3037277262\n\nthe command:\n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_jets_anchored.sh --jobname testJetAnchoredLHC22f_20Evts_test2 --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240305-1\" --wait --fetch-output --asuser alandou\n```",
        "question": "What are the messages in `pipeline_action_xxxx.log` and `logtmp_xxxxxx.txt` files that you are still seeing after running the command on lxplus?"
    },
    {
        "source": "mattermost",
        "post_id": "oypgmykio3nx3nbguszef3m1ao",
        "create_at": 1710506648386,
        "user_id": "m4433ecqp38ptq7r8bgcbwa3rh",
        "message": "Dear experts , i try  to test a MC simulation on Grid following the tutorial with the commandInput/output error : Failed to remove [/alice/cern.ch/user/b/bastid/selfjobs/test-20240315-122305/test-20240315-122305.sh]\n --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"V0_ALICE@O2sim:v20240305-1\" --wait --fetch-output\nI have the following error message \" Input/output error : Failed to remove [/alice/cern.ch/user/b/bastid/selfjobs/test-20240315-122305/test-20240315-122305.sh]\" . I also did the test in local with Input/output error : Failed to remove [/alice/cern.ch/user/b/bastid/selfjobs/test-20240315-122305/test-20240315-122305.sh] --local  and i can the get AO2D.root.  I attach also the log file and also the script. Thank you for your help\n\n",
        "question": "What is the cause of the \"Input/output error : Failed to remove [/alice/cern.ch/user/b/bastid/selfjobs/test-20240315-122305/test-20240315-122305.sh]\" error when running the MC simulation on Grid?"
    },
    {
        "source": "mattermost",
        "post_id": "ygu5ud3rpjfxfmumqk1686ndhc",
        "create_at": 1711101897629,
        "user_id": "m4433ecqp38ptq7r8bgcbwa3rh",
        "message": "Meanwhile, i also submitted the script on GRID  by logging on lxplus and it works  well. Now i wanted to run an anchored MC production  but it fails.  I think that this is due to the ALIEN_JDL_ANCHOR_SIM_OPTIONS  that i need  after the .ini file ( i.e. genBkg, procBkg, collBkg, embedding, nb and see the attached script) but i don't know how to solve it. When running it on lxplus with sh runBeautyToMUONS_fw_pp-anchor-test.sh  i got the following error: Traceback (most recent call last):\n  File \"/cvmfs/alice.cern.ch/el9-x86_64/Packages/O2DPG/daily-20240320-0100-1/UTILS/parse-async-WorkflowConfig.py\", line 296, in <module>\n    postadjust_ConfigValues(flat_config)\n  File \"/cvmfs/alice.cern.ch/el9-x86_64/Packages/O2DPG/daily-20240320-0100-1/UTILS/parse-async-WorkflowConfig.py\", line 285, in postadjust_ConfigValues\n    for key in gpuglobal:\nTypeError: 'NoneType' object is not iterable\nProblem in anchor config creation. Exiting.\nAny idea how to solve this problem? Thanks a lot.",
        "question": "How can I resolve the TypeError: 'NoneType' object is not iterable error when trying to run an anchored MC production with ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "fzf4hp517t8mpx57tx6mmngnph",
        "create_at": 1711102515841,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "That trace is unfortunately not showing the real issue. It means that something went wrong before.\n\nThere should be other files like\n* `timestampsampling_<runnumber>.log`\n* `async_pass_log.log`\nwhich could give further insight in what is going wrong.\nCould you point me to your directory on alien where that was supposed to be run? Then I can try to find the files myself and have a look.",
        "question": "Could you point me to your directory on alien where the simulations were supposed to be run so I can find and examine the `timestampsampling_<runnumber>.log` and `async_pass_log.log` files?"
    },
    {
        "source": "mattermost",
        "post_id": "pgkoj3st9inrumtqzjnz91sska",
        "create_at": 1711122882763,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi, following kind instructions from the tutor of the PWG-dedicated simulation tutorials, Alberto Caliva, I was able to submit MC production test jobs to the GRID. Please note that I am trying to give as input a HepMC file which has a physical location  that is specified in the submission script. The job ID is `3045059057` and the resulting output folder is `/alice/cern.ch/user/s/siragoni/selfjobs/testCoherentRho-20240322-144250`. The HepMC file is passed as: \n```\nexport ALIEN_JDL_ANCHOR_SIM_OPTIONS=\"-gen hepmc -confKey GeneratorFileOrCmd.fileNames=alien:///alice/cern.ch/user/s/siragoni/MC_run3/starlight.hepmc\"\n```\nFinally after tinkering with it for two days, an AOD.root file is produced, but only the BC structures are filled. It feels like no MC event is injected in the simulation at all, and quite in fact both generated and reconstructed information are totally empty. Would you have any advice? I don't see any `sgn*.log` unfortunately, so I cannot check myself. I would also like to see if at least the HepMC file was really fed.... Thanks for any help!",
        "question": "What could be the reason for the AOD.root file being produced with only BC structures filled and no MC events injected in the simulation?"
    },
    {
        "source": "mattermost",
        "post_id": "fa3fokwh4jbcfce1o1wknfnzpy",
        "create_at": 1711360115572,
        "user_id": "3a5ytz8r33fcme33fb8gbicr6e",
        "message": "Hi all, I'm performing some estimations for a MC request following the instructions provided in Alberto's tutorial (https://indico.cern.ch/event/1384034/contributions/5818034/attachments/2806921/4898185/MC_Tutorials.pdf) and I have a doubt. In slide 30, the computation for the expected running time is shown and I would like to do the same starting from the running time on the GRID of some test productions (https://alimonitor.cern.ch/job_details.jsp?jt_field1=23l2). Hence the question, is the running time reported on monalisa already accounting for the fact that MC run on 8-core slots or is it just the wall time (and I have to multiply by 8 as suggested in the tutorial)?",
        "question": "Is the running time reported on monalisa already accounting for the fact that MC runs on 8-core slots or is it just the wall time (and I have to multiply by 8 as suggested in the tutorial)?"
    },
    {
        "source": "mattermost",
        "post_id": "j9pm6pmfwbfqzndhbzf7kykr9a",
        "create_at": 1711442606850,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks a lot for the reply! I have studied a bit how to do it, since I was not too sure how to handle it... An example of how I have handled it (unsuccessfully) is shown here: `/alice/cern.ch/user/s/siragoni/selfjobs/testCoherentRho-20240325-142905`, which I will refer to as `localdir` below. First of all, since the processing script `alien_jobscript.sh` is handled in `localdir`, at runtime and before I run this last script I copy the HepMC file in `localdir`, so that both the script and the HepMC file are at the same level, as in:\n```\n# ----------- EXECUTE ACTUAL JOB  ------------------------------------ \n# source the actual job script from the work dir\nalien.py cp -f file:starlight.hepmc ${MY_JOBWORKDIR}/\n\nchmod +x ./alien_jobscript.sh\n./alien_jobscript.sh\n``` \nThen, I thought that in the script the generator should be referred to as:\n```\nexport ALIEN_JDL_ANCHOR_SIM_OPTIONS=\"-gen hepmc -confKey GeneratorFileOrCmd.fileNames=starlight.hepmc\"\n``` \nUnfortunately, this is not working, I see in fact that in the job directory `localdir/001` :\n```\nWill iterate 0 input files\nProcessing will be on the following list of files:\n\n\nprocessing run 536757, from period LHC23f with pp collisions and mode\nNo runInput_536757.tgz, let's hope we don't need it\nChecking current directory content\ntotal 228\n-rwx------  1 alicesgm edguser 24079 Mar 25 17:29 testCoherentRho-20240325-142905.sh\n-rwx------  1 alicesgm edguser  1654 Mar 25 17:29 alien_jobscript.sh\n-rw-------  1 alicesgm edguser   419 Mar 26 10:29 logging.properties\n-rw-------  1 alicesgm edguser   814 Mar 26 10:29 access_log\n-rw-------  1 alicesgm edguser  1675 Mar 26 10:29 jobtoken9271661257240137965.pem\n-rw-------  1 alicesgm edguser  1415 Mar 26 10:29 jobtoken69888348148384008.pem\ndrwx------  2 alicesgm edguser  4096 Mar 26 10:29 .apptainer\ndrwxr-xr-x 20 alicesgm edguser   620 Mar 26 10:29 ..\n-rw-------  1 alicesgm edguser   358 Mar 26 10:29 stderr\n-rw-------  1 alicesgm edguser  6456 Mar 26 10:29 alien_cpuinfo.log\n-rw-------  1 alicesgm edguser  1282 Mar 26 10:29 alien_meminfo.log\n-rw-------  1 alicesgm edguser  1081 Mar 26 10:29 this_jdl.jdl\n-rwx------  1 alicesgm edguser  2533 Mar 26 10:29 analyse_CPU.py\ndrwx------  4 alicesgm edguser  4096 Mar 26 10:29 tmp\n-rw-------  1 alicesgm edguser 34109 Mar 26 10:29 stdout\n-rw-------  1 alicesgm edguser 33923 Mar 26 10:29 alien_log_3046337092.txt\n-rwx------  1 alicesgm edguser 34270 Mar 26 10:29 setenv_extra.sh\n-rwx------  1 alicesgm edguser 36174 Mar 26 10:29 async_pass.sh\n-rw-------  1 alicesgm edguser     0 Mar 26 10:29 list.list\ndrwx------  4 alicesgm edguser  4096 Mar 26 10:29 .\n-rw-------  1 alicesgm edguser   237 Mar 26 10:29 async_pass_log.log\n```\nSo it sees all the files, apart from the most important HepMC file, which should be also the reason why it is finding 0 input files... Also pinging @alcaliva , sorry for that!",
        "question": "Why is the simulation not finding the HepMC file and instead reporting 0 input files?"
    },
    {
        "source": "mattermost",
        "post_id": "5h9rcgkmbirjfph6krmshm8i5r",
        "create_at": 1711442772187,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "Dear all, I tried to test a MC configuration following the instructions by @alcaliva (specifically slide 33 in [this presentation]([https://indico.cern.ch/event/1384034/contributions/5818034/attachments/2806921/4898185/MC\\_Tutorials.pdf](https://indico.cern.ch/event/1384034/contributions/5818034/attachments/2806921/4898185/MC_Tutorials.pdf)) using the `ALIEN_JDL_LPMANCHORPASSNAME=apass4`, and I get the following error: `./alien_jobscript.sh: line 21: /cvmfs/alice.cern.ch/el7-x86_64/Packages/O2DPG/async-2022-apass4-pp-mc.1-1/MC/run/ANCHOR/anchorMC.sh: No such file or directory` (full log [here](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/f/fgrosa/selfjobs/test_Dstar2-20240325-151345/001/logtmp_3046342612.txt)).\nAm I doing something wrong? [Here](https://cernbox.cern.ch/s/0n2INzXLTnNYVk9) you can find the script I used. Many thanks in advance!\n\nThis is the command line I used to run the test:\n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_pp_D2H_ccbar_and_bbbar_Mode2_ptHardBins_embrepl3_anchor.sh --jobname test_Dstar2 --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::async-2022-apass4-pp-mc-20240311.1-1\" --wait --fetch-output\n```",
        "question": "Am I doing something wrong when running the ALICE O2 simulations as described in the slide 33 of the given presentation, which results in the `No such file or directory` error?"
    },
    {
        "source": "mattermost",
        "post_id": "irxcce5ddin4zmm84u4ofo7wfh",
        "create_at": 1711444295179,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Hej,\nof course, you used the tag on purpose but that seems to not have `anchorMC.sh`\nSome porting needs to be done here.\nI assume you need specifically that tag.\nHowever, in the meantime, could you try with a more recent tag, je.g. the last daily, to see if it works in general?\n\nThen, we need to discuss when the new tags are produced and what we will need to port.\nCould you try within your job script to `alien.py cp` your file to the current directory?\n",
        "question": "Could you try with a more recent tag, e.g., the last daily, to see if it works in general?"
    },
    {
        "source": "mattermost",
        "post_id": "tyhghwc7b7dqi8zsbktbsk7b7o",
        "create_at": 1711444812876,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks Benedikt! Just to clarify, you mean something like:\n```\nLOCALDIR=$pwd\nalien.py cp file:alice/user/s/siragoni/selfjobs/.../starlight.hepmc ${LOCALDIR}/\n``` \n?",
        "question": "Are you suggesting a command like `alien.py cp file:alice/user/s/siragoni/selfjobs/.../starlight.hepmc ${LOCALDIR}/` to copy a file to the local directory?"
    },
    {
        "source": "mattermost",
        "post_id": "ph4znhnqt3gsjkypzxx4s816sw",
        "create_at": 1711445252735,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "How did you do it before? Did you simply upload the file or copied it on the GRID inside your parent dir?",
        "question": "How did you upload or copy the file for ALICE O2 simulations before?"
    },
    {
        "source": "mattermost",
        "post_id": "pyeykpir33fjxkwscgey9f5b5y",
        "create_at": 1711448116261,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "Hi @bvolkel, thanks! Indeed I would need to test the tag for the `apass4` anchoring for the 2022 pp sample (I am also unsure that the one that I used is the correct one).\n\nFollowing what @fcatalan told me, I am now testing with the `O2PDPSuite::async-async-20240115.4.trd-slc7-alidist-O2PDPSuite-daily-20231208-0100-1` tag (which should be for `apass6` though) and it seems to work",
        "question": "Are you testing the correct tag for `apass4` anchoring for the 2022 pp sample?"
    },
    {
        "source": "mattermost",
        "post_id": "jwkouk1rdffozccffqq48b9y6h",
        "create_at": 1711448704799,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "Hi @bvolkel we have some analyses that will use the `apass4`, since we have much more statistics - a factor 10 more - (not all the analyses of course), that's why we would need a MC anchored to it",
        "question": "What MC should we use to anchor our analyses that will use the `apass4` dataset, given it has much more statistics?"
    },
    {
        "source": "mattermost",
        "post_id": "y5cr9u1rnjr78nzz74mgedb4wh",
        "create_at": 1711455531470,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks a lot Sandro! I have done exactly what you have said. Unfortunately, it fails with the same output (and empty AO2D):\n```\nWill iterate 0 input files\nProcessing will be on the following list of files:\n\n\nprocessing run 536757, from period LHC23f with pp collisions and mode\nNo runInput_536757.tgz, let's hope we don't need it\nChecking current directory content\ntotal 276\n-rwx------  1 alicesgm001 alicesgm 24079 Mar 26 11:29 testCoherentRho-20240326-102713.sh\n-rwx------  1 alicesgm001 alicesgm  1734 Mar 26 11:29 alien_jobscript.sh\n-rw-------  1 alicesgm001 alicesgm   419 Mar 26 11:29 logging.properties\n-rw-------  1 alicesgm001 alicesgm   817 Mar 26 11:29 access_log\n-rw-------  1 alicesgm001 alicesgm  1679 Mar 26 11:29 jobtoken7570561923626811135.pem\n-rw-------  1 alicesgm001 alicesgm  1415 Mar 26 11:29 jobtoken4359682809343690963.pem\ndrwx------  2 alicesgm001 alicesgm  4096 Mar 26 11:30 .apptainer\ndrwxr-xr-x 21 alicesgm001 alicesgm   640 Mar 26 11:30 ..\n-rw-------  1 alicesgm001 alicesgm   358 Mar 26 11:30 stderr\n-rw-------  1 alicesgm001 alicesgm 56770 Mar 26 11:30 alien_cpuinfo.log\n-rw-------  1 alicesgm001 alicesgm  1313 Mar 26 11:30 alien_meminfo.log\n-rw-------  1 alicesgm001 alicesgm  1081 Mar 26 11:30 this_jdl.jdl\n-rwx------  1 alicesgm001 alicesgm  2533 Mar 26 11:30 analyse_CPU.py\ndrwx------  4 alicesgm001 alicesgm  4096 Mar 26 11:30 tmp\n-rw-------  1 alicesgm001 alicesgm 34209 Mar 26 11:30 stdout\n-rw-------  1 alicesgm001 alicesgm 34023 Mar 26 11:30 alien_log_3046772217.txt\n-rwx------  1 alicesgm001 alicesgm 34270 Mar 26 11:30 setenv_extra.sh\n-rwx------  1 alicesgm001 alicesgm 36174 Mar 26 11:30 async_pass.sh\n-rw-------  1 alicesgm001 alicesgm     0 Mar 26 11:30 list.list\ndrwx------  4 alicesgm001 alicesgm  4096 Mar 26 11:30 .\n-rw-------  1 alicesgm001 alicesgm   237 Mar 26 11:30 async_pass_log.log\nTime used so far, before setenv_extra = 0 s\ngrep: wn.xml: No such file or directory\n``` \nPlease note that this is crucial for the progress of the Run 3 measurements of the entire UPC group, since we cannot use standard generators such as Pythia, and can only rely on e.g. STARlight and Superchic, so with HepMC files...",
        "question": "Why are the ALICE O2 simulations failing and producing an empty AO2D output?"
    },
    {
        "source": "mattermost",
        "post_id": "wd39rymnp3n6bk56rpbsqi6tjo",
        "create_at": 1711457777154,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks a lot for the availability! I am attaching my script. The `starlight.hepmc`file is already loaded to alien. The command to run it that I use is the following: \n``` \n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_anchored_prod2.sh --jobname testCoherentRho --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240303-1\" --wait --fetch-output\n``` ",
        "question": "What is the command used to run the simulation script, and are there any specific details about the file loading or simulation setup?"
    },
    {
        "source": "mattermost",
        "post_id": "7ntwz51nx7rhzdf9hp1edug5ih",
        "create_at": 1711473251422,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks a lot @swenzel for checking! Sorry for that, but I went to check the output that you mentioned, i.e. `/alice/cern.ch/user/a/aliperf/selfjobs/testCoherentRho-20240326-151011/001/AO2D.root`. If you open a TBrowser interface, you will see that the only plots that are actually filled are those relevant to the filling scheme, such as BC plots. All the others, quite notably the one related to the injection of the hepMC data, such as those contained in `o2mcparticle_001` are empty! I think this means that the hepMC file is not read at all...",
        "question": "Why are the plots related to the injection of hepMC data empty, indicating that the hepMC file might not be read during the simulation?"
    },
    {
        "source": "mattermost",
        "post_id": "s76were4tifn8pjpgty5e8cooe",
        "create_at": 1711474924528,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks, yes, that's the one that is in the script you have processed now, but I think it still doesn't go in the simulation, that's why the plots in your job are empty (same as when I submit it myself)",
        "question": "Why are the plots in the simulation job empty?"
    },
    {
        "source": "mattermost",
        "post_id": "c1nnqwiupbbn8r39ewobur93rh",
        "create_at": 1711477979623,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks!! I must have missed that. I will check and let you know how it goes. Just to clarify, you mean that all the plots for the generation of the MC are filled, and not only the ones relevant to BC?\nI am asking because in the job you have submitted at 3:10pm they are empty",
        "question": "Do all the plots for the MC generation get filled, or only the ones relevant to BC?"
    },
    {
        "source": "mattermost",
        "post_id": "jiwypkkhfpdizf4j1hx97rhnao",
        "create_at": 1711545732417,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "Hi @bvolkel, I still bother about the tests I was doing yesterday. I noticed that in the [anchorMC](https://github.com/AliceO2Group/O2DPG/blob/81d06a88790a8a021179d66e00139ef5bffcfc7a/MC/run/ANCHOR/anchorMC.sh) script there is no possibility to pass the number of background events, hence no possibility of using the embedding. Is there a particular reason for that, or it's simply to be implemented? Many thanks!",
        "question": "Is there a reason why the number of background events cannot be passed in the [anchorMC](https://github.com/AliceO2Group/O2DPG/blob/81d06a88790a8a021179d66e00139ef5bffcfc7a/MC/run/ANCHOR/anchorMC.sh) script, which prevents the use of embedding?"
    },
    {
        "source": "mattermost",
        "post_id": "wi9a859hwtb1xrcs1pm61keapr",
        "create_at": 1711546850009,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "I am not 100% certain now however, if that will work with production tags (aka. if the PRs to support this have been ported).\nWith daily it will work.\nNote that quite a few developments have been made during the last weeks and we need to take a few things into account when goiing for the next async. SW tags",
        "question": "Will the changes work with production tags?"
    },
    {
        "source": "mattermost",
        "post_id": "naegidi557nyubmqaxum6i3wir",
        "create_at": 1711646427673,
        "user_id": "m4433ecqp38ptq7r8bgcbwa3rh",
        "message": "Hi @bvolkel et al,   I am also preparing anchored MC simulations with embedding. i did several tests several but none of them were successfull. I still don't manage to get AO2D produced.  Here are few examples of output at /cern.ch/user/b/bastid/selfjobs/testembed-v4-20240328-151636 or /alice/cern.ch/user/b/bastid/selfjobs/testa-20240326-180114). Thanks  ",
        "question": "What is the issue with producing AO2D in my anchored MC simulations with embedding?"
    },
    {
        "source": "mattermost",
        "post_id": "bt31tzgur7f93jqfu6j8y3bfua",
        "create_at": 1712570550829,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Log files in your folder indicate:\n```\nTraceback (most recent call last):\n  File \"/cvmfs/alice.cern.ch/el7-x86_64/Packages/O2DPG/async-20240115.3.trd-1/MC/bin/o2dpg_sim_workflow_anchored.py\", line 436, in <module>\n    sys.exit(main())\n  File \"/cvmfs/alice.cern.ch/el7-x86_64/Packages/O2DPG/async-20240115.3.trd-1/MC/bin/o2dpg_sim_workflow_anchored.py\", line 337, in main\n    assert(args.split_id <= args.prod_split)\nAssertionError\n```\nso most likely wrong splitID in comparison to PRODSPLIT.\n@fgrosa : Since you inquired about anchoringMC in combination with embedding: I think the setup may yet work as expected or should be validated carefully. `anchorMC` is generically using the feature where collision contexts are generated before the transport part. But as far as I remember, embedding is not yet really sensitive to this. There is ticket [O2-3622](https://its.cern.ch/jira/browse/O2-3622) which is supposed to follow this up. We will bump it in priority and fix it asap. (In principle the number of background events should be the maximum of all signal_events / timeframe *and* we need to make sure to use the right vertex ... which is part of the collision contexts).\nHowever, embedding workflows should work nicely when --pregenCollContext is not used (which should be fine for all productions with higher interaction rate).",
        "question": "What does the error indicate and how should the setup be validated?"
    },
    {
        "source": "mattermost",
        "post_id": "ia9kfntuojf4jpcd1x914uxzyh",
        "create_at": 1712579883830,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "I'll test again and let you know, thanks!\nHi @swenzel, I tested, but it still does not work:\nIn [this](https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Ff%2Ffgrosa%2Fselfjobs%2Ftest_anchor_apass4_smalltest_sandro-20240408-150914#/alice/cern.ch/user/f/fgrosa/selfjobs/test_anchor_apass4_smalltest_sandro-20240408-150914) test I removed `--pregenCollContext` from the arguments and I used `10` background events and `10` signal events per TF, but still the memory increases a lot (it did not exceed 70 GB, but it is now at 40 GB) and it is stuck since 1h. I will follow up in the JIRA that you opened, if there are further tests that I can perform let me know!",
        "question": "What should I do to resolve the issue with memory increase and simulation getting stuck?"
    },
    {
        "source": "mattermost",
        "post_id": "gt8hgsooojrgmg9dfzyixb84co",
        "create_at": 1712851831494,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi everyone, sorry for the unusual request. I have just noticed that when launching simulations on GRID, not all the output is saved. I would like to have a look at for example `o2trac_its.root ` to get additional insights on the pT of the track at the end of the ITS. The command I issue is usually of the type:\n``` \n${O2DPG\\_ROOT}/GRID/utils/grid\\_submit.sh --script [run\\_anchored\\_prod3.sh](http://run_anchored_prod3.sh/) --jobname testCoherentRho --outputspec \"\\*.log@disk=1\",\"\\*.root@disk=2\" --packagespec \"VO\\_ALICE@O2sim::v20240303-1\" --wait --fetch-output\n``` \nShould it be modified to get that kind of file? Thanks a lot in advance",
        "question": "Should the command be modified to save the `o2trac_its.root` file when launching simulations on GRID?"
    },
    {
        "source": "mattermost",
        "post_id": "gyxqqo6pzjbixbqzzigkp15shw",
        "create_at": 1712853927404,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Hej Simone,\nCould you specify if there are ROOT files other than `AO2D.root` saved?\nMeaning are some `tf*/*.root` files also saved?\nI am not an expert with this notation, but maybe\n```\n\"*.log@disk=1\",\"*.root,tf*/o2trac_its.root@disk=2\"\n```\ncould do the job?",
        "question": "Are any ROOT files other than `AO2D.root` saved, such as `tf*/*.root` files?"
    },
    {
        "source": "mattermost",
        "post_id": "31qfx3t3spnb3pr6ipzujm95gw",
        "create_at": 1713178931489,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Hi @siragoni (and other PWG experts). You mention documentation specific for your PAG. Can you share a link to it? I think it be useful to cross-link or mention these documentations in our central documentation or in the header of this mattermost channel.",
        "question": "Can you share a link to the documentation specific for your PAG? It would be useful to cross-link or mention these documents in our central documentation or in the header of this Mattermost channel."
    },
    {
        "source": "mattermost",
        "post_id": "g3gecknnsjyftehkxye3tzreja",
        "create_at": 1713184086513,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "Dear @siragoni , @swenzel , \nToday I tried to execute MC following tutorial of Alberto and recent manual of Simone. Unsuccessfully. Last job PID is 3057063797. The HepMC file is coming from Superchic4.2. I tried locally to do Geant4 transport and it works. Output is present and I can open and read files (file is readable and is correct). When moving to GRID running I encountered problems. I tried to get workflow (via o2dpg_sim_workflow.py script) and configuration script (via o2_dpg_workflow_runner.py script) - ok. After getting them I manually edited my_script.sh where I added a line: alien.py cp /alice/cern.ch/user/a/amatyja/selfjobs/bg_eePbPb5360_10000ev.hepmc file:./  and modified the path to have ${PWD}. I also copied the file to GRID to the mentioned location. The execution on the GRID returns error. Since I am not experience in Run3 running I ask you for some help to diagnose the problem.",
        "question": "Why am I encountering errors when trying to run MC simulations on the GRID after successfully running them locally?"
    },
    {
        "source": "mattermost",
        "post_id": "iyac88iw7ibk3g8wa4xas7xdoc",
        "create_at": 1713184615659,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi adam, I can't see the script anywhere... In principle your submission script should appear in the job base directory as `alien_jobscript.sh`, but I see something funny there. Look for example at the structure of \n``` \n/alice/cern.ch/user/s/siragoni/selfjobs/testPhi-20240412-073457\n``` \nHow are you launching the job? Can you post the full command?",
        "question": "How are you launching the job and can you post the full command?"
    },
    {
        "source": "mattermost",
        "post_id": "nwgp6bbzc7ystygcbuojdc8wuh",
        "create_at": 1713185149402,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "command: ${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script my_script.sh --jobname testAdam --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240303-1\" --wait --fetch-output",
        "question": "What is the command used to submit the ALICE O2 simulation job, and what are the key output specifications and package specifications?"
    },
    {
        "source": "mattermost",
        "post_id": "pzqcfax4kprbunn7kx66fcqudc",
        "create_at": 1713248078109,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi Adam, it is weird. I see all the outputs and AO2D files in your directory\nHi @swenzel and @bvolkel , I was wondering if it was possible to have STARlight either inside a `o2sim` package, or as a separate package available on GRID, so that it can be loaded with `--packagespec` for the `grid_submit.sh` script. STARlight can already be built with aliBuild, e.g. `aliBuild build STARlight --defaults o2`. The reason for this is that if so I could for example do a generation on the fly of STARlight events, convert them to hepMC on the fly afterwards, and feed them to the workflow. So this would become the closest we can get to having a \"native\" generator, Ã  la Pythia.... This would help when generating millions of events, or with issues such as having to manually compute how many events to skip in a HepMC file. Tagging also @pbuhler to hear thoughts. I have looked on `https://alimonitor.cern.ch/packages` but I can't find it anywhere...",
        "question": "Is it possible to integrate STARlight either inside the `o2sim` package or as a separate package available on GRID, so that it can be loaded with `--packagespec` for the `grid_submit.sh` script?"
    },
    {
        "source": "mattermost",
        "post_id": "w56kxnctupb67nzif8sagbadkc",
        "create_at": 1713252402266,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "Hi @siragoni , the last try works. I changed O2sim version and asked for all the root files to be left tf*/*.root.\nDear @siragoni , @swenzel , @pbuhler ,\nFrom the documentation of anchored production (example script) I see that some variables are set manually. Here comes questions:\n1. For example PRODSPLIT=153. Due to a different time duration of each runs, should we calculate how many timeframes are in the the run and adjust the product of \"number of splits\" x \"number of prodsplits\" x \"number of timeframes\"? Or are there any recomendations on it? \n2. NSIGEVENTS is a number of signal events per Timeframe (TF). If I have HepMC file with 10000 events and I require NSIGEVENTS=20000, how TFs are filled? Will be there 10000 events filled twice per TF? If I have 10 TFs, so each TF will have the same content of signal? I also understand that any collision without signal event is fed with other process (any MB process), am I correct?",
        "question": "1. Should PRODSPLIT be adjusted based on the number of timeframes in the run, and are there any recommendations for setting it?\n2. How are TFs filled if NSIGEVENTS exceeds the number of events in the HepMC file, and will each TF have the same content of signal events?"
    },
    {
        "source": "mattermost",
        "post_id": "44odbphwptyr5jwexs5479absr",
        "create_at": 1713515286006,
        "user_id": "349mzxje5pbz9fes49wk6cz9xc",
        "message": "Dear Experts,\nI would like to use Pythia for UPC simulations. (STARlight is not an option for now.) On their official website, they have an [example file](https://pythia.org/latest-manual/examples/main70.html) that I was able to run locally and also produce HepMC3 files with it. I have tried to run locally the `o2dpg_sim_workflow.py` and the `workflow.json` but after `o2dpg_workflow_runner.py` doesn't produce the AOD files. With simply `o2-sim -g hepmc --configKeyValues \"HepMC.fileName=test.hepmc\"` the simulation files, Kinetree and Hits are produced so I think the Pythia generated HepMC file is okay. How can I specify the options for `o2dpg_sim_workflow.py`?\nMay be it would be easier or more straightforward to derive the Pythia example like it is done [here](https://github.com/AliceO2Group/O2DPG/blob/master/MC/config/PWGLF/pythia8/generator_pythia8_longlived.C)?\n\nThanks",
        "question": "How can I specify the options for `o2dpg_sim_workflow.py` when running Pythia for UPC simulations in ALICE O2?"
    },
    {
        "source": "mattermost",
        "post_id": "ft69q4g68j8z5x39ftyhbhsssh",
        "create_at": 1713517969243,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "There is an example on how to use config key values here: https://aliceo2group.github.io/simulation/docs/o2dpgworkflow/#workflow-creation\nThe example line is\n```bash\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -gen pythia8 -eCM <emc energy  [GeV]> -confKey \"GeneratorPythia8.config=<path/to/config>\"\n```\nBut you can adjust it to your required HepMC confKey string.\n\nDoes that help?",
        "question": "Does the provided example help in adjusting the HepMC confKey string for running ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "ks8qhhpc87naxy316xk9uc9ukr",
        "create_at": 1713519064014,
        "user_id": "349mzxje5pbz9fes49wk6cz9xc",
        "message": "Thanks for the link but I think - I might be wrong - it is not just a matter of configs, because to implement UPC reaction, the developers defined a new class for the photon flux. That's why I thought it is necessary to derive a new generator, so to say, based on the existing Pythia.\n\nAs for the HepMC, I have tried to use the followin:\n```\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM ${ECM} -gen hepmc -tf 1 -ns 5 -e ${SIMENGINE} -j ${NWORKERS} -interactionRate 50000 -confKey \"GeneratorFileOrCmd.fileNames=${PWD}/test.hepmc\"\n```\nthat produced the attached `workflow.json`. When I tried to run\n```\n${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt aod\n```\nI got the following\n```\nResources of task tpcreco_1 are exceeding the boundaries.\nCPU: 3.0 (estimate) vs. 8 (boundary)\nMEM: 16000.0 (estimated) vs. 14273.7046875 (boundary).\n```\n",
        "question": "Why am I getting resource exceeding boundaries errors when trying to run the O2DPG workflow with HepMC input?"
    },
    {
        "source": "mattermost",
        "post_id": "szitun8o7pybtxatzryf636axa",
        "create_at": 1713536841202,
        "user_id": "k1gztq43yfgbber61k3pd736kw",
        "message": "Dear experts, I was trying to submit a simulation on the grid with the following command:\n\n``` ${O2DPG_ROOT}/O2DPG/GRID/utils/grid_submit.sh --script  anchorMC_cc.sh --jobname test_anchorMC_charm1 --outputspec \"*.log@disk1\",\"*.root@disk=2\" --packagespec \"O2PDPSuite::async-async-20240115.6.trd-slc7-alidist-O2PDPSuite-daily-20231208-0100-1\",\"VO_ALICE@jq::v1.6-3\" ```\n\nThe jobs seem to run correctly but an error occurs at the saving stage:\n```[trace ]: ERROR! Unable to handle job: alien.shell.commands.JAliEnCommandException ```\n(https://alimonitor.cern.ch/jobs/trace.jsp?pid=3061276304)\n\nDo you know how can it be fixed? Thanks in advance for your help!",
        "question": "Do you know how to fix the error `alien.shell.commands.JAliEnCommandException` that occurs during the saving stage of the simulation?"
    },
    {
        "source": "mattermost",
        "post_id": "mnqh4rguabftzq9en7n1jkre4r",
        "create_at": 1713537469587,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Maybe what you are trying to save is too fragmented.\nTry \n```bash\n--outputspec \"logs.zip:*.log@disk1\",\"root_files.zip:*.root@disk=2\"\n```\nNote, that in addition, it might ask for **all** ROOT files with `*.root`.\nDo you need hits, kinematics, tracks etc etc?\nOtherwise, you should specify \n```bash\n--outputspec \"logs.zip:*.log@disk1\",\"AO2D.root@disk=2\"\n```\nin case you are only interested in the final AOD",
        "question": "What should the output specification be for saving logs and ROOT files in ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "k31xg69td7rqint33sa367k81e",
        "create_at": 1713960062035,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, we're testing an anchored jet simulation setup for PWGJE, and find that we have a depletion of reconstructed tracks (and thus jets) when running some QA on the output AO2Ds. The generator level looks to work fine, which indicates there is an issue with reconstruction. I attach the scripts used to run these tests. I also attach some figures comparing the anchored production with an unanchored production (LHC23d4) which has consistent PYTHIA configuration. We have tested different anchoring periods of 2022 data (pass2 and pass6) and loosening track and event selection but find the same issue. If anyone has any ideas of what could be the problem it would be very helpful! Let me know if you need more information, thanks in advance",
        "question": "What could be the reason for the depletion of reconstructed tracks and jets in the anchored jet simulation setup, given that the generator level looks fine and different anchoring periods and selection criteria do not resolve the issue?"
    },
    {
        "source": "mattermost",
        "post_id": "yogayybjbfbr58rrhoaxdhgb9y",
        "create_at": 1713962314081,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Hej @jnorman \nWhen you say \"generator level\", are you talking about the kinematics file or really only primaries from Pythia8?",
        "question": "When you say \"generator level\", are you talking about the kinematics file or really only primaries from Pythia8?"
    },
    {
        "source": "mattermost",
        "post_id": "ni7zxqwxri8kfcwmcfwzyfzbrh",
        "create_at": 1713964509564,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "I mean the particle-level information that is used by the jet QA task. We haven't done any studies comparing the kinematics file but the fact that we get consistent particle-level jet spectra with a previous production I think indicates that the PYTHIA simulation is running and saving as expected",
        "question": "What is the particle-level information used by the jet QA task, and have any studies been done comparing the kinematics file?"
    },
    {
        "source": "mattermost",
        "post_id": "y4nng73sifn99rzdh6zf74xxgr",
        "create_at": 1714130228204,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Ah, so I guess you mean what you take from the mcParticles table in the AOD.\nThey are effectively MC kinematics.\nFor your \"Pythia jets\" I assume you are only taking primaries from the mcParticles, right?",
        "question": "Are the \"Pythia jets\" in the AOD constructed using only primary particles from the mcParticles table?"
    },
    {
        "source": "mattermost",
        "post_id": "qz9kf3q8gpbe5nq5x88suihrqc",
        "create_at": 1714662728169,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi everyone, sorry again for the bother. I am here again to ask for some help, this time not with STARlight at least. What I am currently doing is to generate `Jpsi->ee` events with pythia background, so that the event triggers FIT, and the electrons from the decay of the Jpsi trigger EMCAL instead. The exercise that I need to do to finish validating the trigger framework for EMCAL in MC is the following: basically saturating the production with Jpsi s, so that there are a few times where two consecutive Jpsi s are within 13 BCs (the tail in the trigger response in EMCAL is 13 BCs). The reason behind it is that this procedure might validate the implementation of the signal pile up in the trigger logic of the simulation... For now I am simulating the event with:\n```c++ \nNSIGEVENTS=${NEVENTS}\nNBKGEVENTS=${NEVENTS}\nNWORKERS=${NWORKERS:-8}\nNTIMEFRAMES=${NTIMEFRAMES:-1}\n\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM 13600 -gen external -j 10 -ns ${NSIGEVENTS} -tf ${NTIMEFRAMES} -e TGeant4 -mod \"--skipModules ZDC\" \\\n\t-confKey \"GeneratorExternal.fileName=${O2DPG_ROOT}/MC/config/PWGDQ/external/generator/GeneratorParamPromptJpsiToElectronEvtGen_pp13TeV.C;GeneratorExternal.funcName=GeneratorParamPromptJpsiToElectronEvtGen_pp13TeV()\"  \\\n       \t-genBkg pythia8 -procBkg inel -colBkg pp --embedding -nb ${NBKGEVENTS} -interactionRate 498226  -run 537959\n```  \nMay I ask if there is a way of doing that with this command? Maybe simply asking for a lot more signal events than background events (more than what the filling scheme can handle)?",
        "question": "May I ask if there is a way of doing that with this command? Maybe simply asking for a lot more signal events than background events (more than what the filling scheme can handle)?"
    },
    {
        "source": "mattermost",
        "post_id": "5iywmhbk7fnnmn8cxy8tp4ohur",
        "create_at": 1714737267352,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Hi @bvolkel \ndo you have any idea what is going on with the track reconstruction in our simulation?",
        "question": "What is going on with the track reconstruction in the simulation?"
    },
    {
        "source": "mattermost",
        "post_id": "ps7c36417tfu9j1ahafkexidqc",
        "create_at": 1714740982441,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Hello everyone, I'm just getting started running MC simulations but I managed to run a small simulation on the grid.\nHowever, the statistics in the output is very small. How can I increase the number of events being simulated?\nSo far I have used these commands:\n**creating a workflow**\n```\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -eCM 13600 -col pp -gen pythia8 -proc cdiff -tf 1 -ns 20000 -e TGeant4 -interactionRate 500000\n```\n**produce script to run workflow**\n```\n${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt aod --cpu-limit 8 --produce-script my_script.sh\n```\n**submit jobs on GRID**\n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script ${O2DPG_ROOT}/MC/run/PWGEM/runHFGapToDielectrons_pp.sh --jobname eeHFGap --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240502-1\" --wait --fetch-output\n```\nthe corresponding running script is the following: https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGEM/runHFGapToDielectrons_pp.sh\n\nAny help is welcome. Thank you. ",
        "question": "How can I increase the number of events being simulated in my ALICE O2 MC simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "ucjjpyfr778pfqut6rfej3xs1w",
        "create_at": 1715074302250,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Thank you very much I do understand it better now.\nI try to run an anchored MC now and therefore created a workflow.\nWhen I then try to run: `${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --cpu-limit 32`\nIt returns: \n```\ncommand ${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;Diamond.width[2]=6;\" -g external -o genevents --timestamp 1664858227486 --seed 191158313 -n 20 had nonzero exit code 1\n\nsgngen_1 failed ... checking retry\n```\n\nI tried to do a `--try-run` but here I get the error:\n```\nStop on failure  True\nsetting up ROOT system\n<class 'AttributeError'> o2_dpg_workflow_runner.py 1673\nTraceback (most recent call last):\n  File \"/data/feisenhut/alice/sw/slc8_x86-64/O2DPG/a764f86ba8-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1673, in execute\n    self.try_job_from_candidates(candidates, finished)\n  File \"/data/feisenhut/alice/sw/slc8_x86-64/O2DPG/a764f86ba8-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1149, in try_job_from_candidates\n    self.resource_manager.book(tid, p.nice())\nAttributeError: 'Popen' object has no attribute 'nice'\nCleaning up\n 2 : would do sgngen_1\n```\nIs there a problem with `p.nice()`, for the Popen constructor? \n\nThank you very much I do understand it better now.\nI try to run an anchored MC now and therefore created a workflow.\nWhen I then try to run: `${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --cpu-limit 32`\nIt returns: \n```\ncommand ${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;Diamond.width[2]=6;\" -g external -o genevents --timestamp 1664858227486 --seed 191158313 -n 20 had nonzero exit code 1\n\nsgngen_1 failed ... checking retry\n```\n\nI tried to do a `--try-run` but here I get the error:\n```\nStop on failure  True\nsetting up ROOT system\n<class 'AttributeError'> o2_dpg_workflow_runner.py 1673\nTraceback (most recent call last):\n  File \"/data/feisenhut/alice/sw/slc8_x86-64/O2DPG/a764f86ba8-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1673, in execute\n    self.try_job_from_candidates(candidates, finished)\n  File \"/data/feisenhut/alice/sw/slc8_x86-64/O2DPG/a764f86ba8-local1/MC/bin/o2_dpg_workflow_runner.py\", line 1149, in try_job_from_candidates\n    self.resource_manager.book(tid, p.nice())\nAttributeError: 'Popen' object has no attribute 'nice'\nCleaning up\n 2 : would do sgngen_1\n```\nIs there a problem with `p.nice()`, for the Popen constructor? \n",
        "question": "Is there a problem with `p.nice()`, for the Popen constructor?"
    },
    {
        "source": "mattermost",
        "post_id": "4cuxe6dxpibpmy7caj81q7xbqr",
        "create_at": 1715074742695,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "In your case the event generation fails. Could you look in `tf1/sgngen_1.log` or `tf1/genevents_serverlog` `tf1/genevents_workerlog0` to see what is the problem? .... For what concerns the `p.nice()` error ... this appears to be some strange Python error that we should follow up. Have seen it before but didn't spend time on it since it only happens for the `--try-run` option which is not critical.\nIn your case the event generation fails. Could you look in `tf1/sgngen_1.log` or `tf1/genevents_serverlog` `tf1/genevents_workerlog0` to see what is the problem? .... For what concerns the `p.nice()` error ... this appears to be some strange Python error that we should follow up. Have seen it before but didn't spend time on it since it only happens for the `--try-run` option which is not critical.",
        "question": "What should I check in the logs to identify why the event generation fails, and what does the `p.nice()` error indicate?"
    },
    {
        "source": "mattermost",
        "post_id": "unshtnudyfn7djcwcdpz9468eo",
        "create_at": 1715078898991,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "The log from `sgngen_1.log` is:\n```\nRunning: TIME=\"#walltime %e\\n#systime %S\\n#usertime %U\\n#maxmem %M\\n#CPU %P\" /usr/bin/time --output=sgngen_1.log_time ./sgngen_1.log_tmp.sh\n[INFO] This is o2-sim version 1.2.0 (cbcb288fe56)\n[INFO] Built by ALIBUILD:1.16.1, ALIDIST-REV:5cca9fc7bb9988464d56f8ed396c4518c464c991 on OS:Linux-4.18.0-552.el8.x86_64\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-3961330 type pub\n[INFO] Init CcdApi with UserAgentID: pcikf5-1715074455-aRo9mZ, Host: http://alice-ccdb.cern.ch/(cache snapshots to dir=/data/feisenhut/Run3/data/MCproduction/anchored_runscript/ccdb, prefer if available)\n[INFO] CCDB Time-machine constrained detected. Setting condition-not-after constrained to timestamp 3385078236000\n[INFO] Running with 1 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 1 WORKERS\nSpawning particle server on PID 3961685; Redirect output to genevents_serverlog\nSpawning sim worker 0 on PID 3962186; Redirect output to genevents_workerlog0\nSpawning hit merger on PID 3962187; Redirect output to genevents_mergerlog\n[INFO] Process 3962186 EXITED WITH CODE 1 SIGNALED 0 SIGNAL 0\n[INFO] Problem detected (or child received termination signal) ... shutting down whole system \n[INFO] TERMINATING 3961685\n[INFO] TERMINATING 3962186\n[INFO] TERMINATING 3962187\n[ERROR] SHUTTING DOWN DUE TO SIGNALED EXIT IN COMPONENT 3962186\n[INFO] Merger process 3962187 returned\n[INFO] Simulation process took 64.5391 s\nTASK-EXIT-CODE: 1\n```\n\nThe only errors that I found then in the `genevents_serverlog` is:\n```\nError in <TROOT::LoadMacro>: macro  not found in path .:/data/feisenhut/alice/sw/slc8_x86-64/ROOT/v6-30-01-alice4-8/macros\n[11:34:17][FATAL] Cannot find \n```\nI checked that. The directory is present.\n\nand in `genevents_workerlog0`:\n```\n[11:35:18][ERROR] No configuration received within 60000ms\n\n[11:35:19][ERROR] Could not initialize simulation\n```\nThe log from `sgngen_1.log` is:\n```\nRunning: TIME=\"#walltime %e\\n#systime %S\\n#usertime %U\\n#maxmem %M\\n#CPU %P\" /usr/bin/time --output=sgngen_1.log_time ./sgngen_1.log_tmp.sh\n[INFO] This is o2-sim version 1.2.0 (cbcb288fe56)\n[INFO] Built by ALIBUILD:1.16.1, ALIDIST-REV:5cca9fc7bb9988464d56f8ed396c4518c464c991 on OS:Linux-4.18.0-552.el8.x86_64\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-3961330 type pub\n[INFO] Init CcdApi with UserAgentID: pcikf5-1715074455-aRo9mZ, Host: http://alice-ccdb.cern.ch/(cache snapshots to dir=/data/feisenhut/Run3/data/MCproduction/anchored_runscript/ccdb, prefer if available)\n[INFO] CCDB Time-machine constrained detected. Setting condition-not-after constrained to timestamp 3385078236000\n[INFO] Running with 1 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 1 WORKERS\nSpawning particle server on PID 3961685; Redirect output to genevents_serverlog\nSpawning sim worker 0 on PID 3962186; Redirect output to genevents_workerlog0\nSpawning hit merger on PID 3962187; Redirect output to genevents_mergerlog\n[INFO] Process 3962186 EXITED WITH CODE 1 SIGNALED 0 SIGNAL 0\n[INFO] Problem detected (or child received termination signal) ... shutting down whole system \n[INFO] TERMINATING 3961685\n[INFO] TERMINATING 3962186\n[INFO] TERMINATING 3962187\n[ERROR] SHUTTING DOWN DUE TO SIGNALED EXIT IN COMPONENT 3962186\n[INFO] Merger process 3962187 returned\n[INFO] Simulation process took 64.5391 s\nTASK-EXIT-CODE: 1\n```\n\nThe only errors that I found then in the `genevents_serverlog` is:\n```\nError in <TROOT::LoadMacro>: macro  not found in path .:/data/feisenhut/alice/sw/slc8_x86-64/ROOT/v6-30-01-alice4-8/macros\n[11:34:17][FATAL] Cannot find \n```\nI checked that. The directory is present.\n\nand in `genevents_workerlog0`:\n```\n[11:35:18][ERROR] No configuration received within 60000ms\n\n[11:35:19][ERROR] Could not initialize simulation\n```",
        "question": "What are the errors in the logs that caused the simulation to fail?"
    },
    {
        "source": "mattermost",
        "post_id": "wxhza4buofyf7c3e1ctiyeduce",
        "create_at": 1715079187149,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "What is your external generator in\n```\n${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;Diamond.width[2]=6;\" -g external -o genevents --timestamp 1664858227486 --seed 191158313 -n 20\n```\n?\nI would expect  some `ini` file I guess\nWhat is your external generator in\n```\n${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;Diamond.width[2]=6;\" -g external -o genevents --timestamp 1664858227486 --seed 191158313 -n 20\n```\n?\nI would expect  some `ini` file I guess",
        "question": "What is your external generator in the provided simulation command?"
    },
    {
        "source": "mattermost",
        "post_id": "yt7u6komfpnp3dn1rwjo9hd8wh",
        "create_at": 1715102965860,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "Hi, I am trying to simulate a Pb--Pb event on the grid using this generator + the ```grid_submit``` command(https://github.com/AliceO2Group/O2DPG/blob/master/MC/config/PWGLF/ini/GeneratorLFHypertritonPbPbGap.ini)\n\nThe simulation goes into error execution due to the ```no space left on device``` error, see for example the stdout below\nIs there any workaround to avoid this issue? \n",
        "question": "Is there any workaround to avoid the \"no space left on device\" error when simulating a Pb--Pb event on the grid?"
    },
    {
        "source": "mattermost",
        "post_id": "5ctbkj7kst8dbmh3i8ea3xg4ga",
        "create_at": 1715153106135,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Can you please give additional details such as how many timeframes / events? Do you have a job id ? \nThe log indicates indicates a problem during cp of files to GRID storage. This is more a question to the central services - Alien team, I believe.   In any case, this particular copy has lately been taken out from the tool. So if you use the latest grid_submit version from O2DPG, the problem might go away.",
        "question": "Can you provide details on the number of timeframes/events and the job ID? Additionally, a problem was found during the file copy to GRID storage; has this issue been resolved in the latest grid_submit version from O2DPG?"
    },
    {
        "source": "mattermost",
        "post_id": "9m5q5xhfttfg3nx8he5pe4th6r",
        "create_at": 1715171558195,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "I would have a follow up question.\nI have managed now to run the anchored script on the grid and produce an AO2D.root file.\n\nBefore we would like to request a whole anchored MC production, we would like to study the effect of gap triggering on a test anchored MC. Therefore we would like to calculate a single electron efficiency.\nWith the script I'm currently using (see attached) the statistics is to low.\n\nCould you help me figuring out how I can modify the TimeFrame, ProdSplit and Split parameters to have sufficient statistics in the end while choosing reasonable values?\n\nWhen running the `${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow_anchored.py` script, there is an information about the space for the number of maximum timeframes.  Would this be suitable to use? \n```\nThis run has space for 601430.0220639554 timeframes\nEach job can do 3930.9151768885977 maximally at a prod split of 153\nWith each job doing 1 timeframes, this corresponds to a filling rate of 0.00025439368569421056\nWe can do this amount of cycle iterations to achieve 100%: 3930.9151768885977\nDetermined start-of-run to be:  1664858227373\nDetermined end-of-run to be:  1664865073059\nDetermined timestamp to be :  1664862656927\nDetermined offset to be :  389160\n```\nI would have a follow up question.\nI have managed now to run the anchored script on the grid and produce an AO2D.root file.\n\nBefore we would like to request a whole anchored MC production, we would like to study the effect of gap triggering on a test anchored MC. Therefore we would like to calculate a single electron efficiency.\nWith the script I'm currently using (see attached) the statistics is to low.\n\nCould you help me figuring out how I can modify the TimeFrame, ProdSplit and Split parameters to have sufficient statistics in the end while choosing reasonable values?\n\nWhen running the `${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow_anchored.py` script, there is an information about the space for the number of maximum timeframes.  Would this be suitable to use? \n```\nThis run has space for 601430.0220639554 timeframes\nEach job can do 3930.9151768885977 maximally at a prod split of 153\nWith each job doing 1 timeframes, this corresponds to a filling rate of 0.00025439368569421056\nWe can do this amount of cycle iterations to achieve 100%: 3930.9151768885977\nDetermined start-of-run to be:  1664858227373\nDetermined end-of-run to be:  1664865073059\nDetermined timestamp to be :  1664862656927\nDetermined offset to be :  389160\n```",
        "question": "How can I modify the TimeFrame, ProdSplit, and Split parameters to achieve sufficient statistics while choosing reasonable values when running the `${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow_anchored.py` script?"
    },
    {
        "source": "mattermost",
        "post_id": "edeskycmxi8h5qrijj1zuhtyto",
        "create_at": 1715180000284,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "In the output there should also be a `.stat` file, in whose file name the number of effectively simulated events is contained; something like `0_0_0_<nevents>.stat`\nWould that help?\nThen you know what comes out per split and a certain number of TFs therein.\nIn the output there should also be a `.stat` file, in whose file name the number of effectively simulated events is contained; something like `0_0_0_<nevents>.stat`\nWould that help?\nThen you know what comes out per split and a certain number of TFs therein.",
        "question": "What information is contained in the `.stat` file regarding the number of effectively simulated events?"
    },
    {
        "source": "mattermost",
        "post_id": "tbgkpmmnt3nyjkab1opoczbnnc",
        "create_at": 1715184350180,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI'm looking at the LHC24b1 simulation anchored to LHC22o pp\nI want to run the exact [anchorMC.sh script that has been used for it](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/a/aliprod/LHC24b1/anchorMC.sh), but I'm having trouble finding which of the O2DPG tag it corresponds to. It is different from the few MC/run/ANCHOR/anchorMC.sh versions I checked (initial commit, and few of the later ones). The [stdout](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/sim/2024/LHC24b1/0/528531/995/stdout) for the LHC24b1 simulation mentions `/cvmfs/alice.cern.ch/el7-x86_64/Packages/O2DPG/async-20240115.3.trd-1/MC/run/ANCHOR/anchorMC.sh` but at that point in time there's no MC/run/ANCHOR/anchorMC.sh file\nWhat --packagespec option should I give to use the same anchorMC.sh as that LHC24b1 sim?\nDear experts,\nI'm looking at the LHC24b1 simulation anchored to LHC22o pp\nI want to run the exact [anchorMC.sh script that has been used for it](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/a/aliprod/LHC24b1/anchorMC.sh), but I'm having trouble finding which of the O2DPG tag it corresponds to. It is different from the few MC/run/ANCHOR/anchorMC.sh versions I checked (initial commit, and few of the later ones). The [stdout](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/sim/2024/LHC24b1/0/528531/995/stdout) for the LHC24b1 simulation mentions `/cvmfs/alice.cern.ch/el7-x86_64/Packages/O2DPG/async-20240115.3.trd-1/MC/run/ANCHOR/anchorMC.sh` but at that point in time there's no MC/run/ANCHOR/anchorMC.sh file\nWhat --packagespec option should I give to use the same anchorMC.sh as that LHC24b1 sim?",
        "question": "What --packagespec option should I give to use the same anchorMC.sh as that LHC24b1 sim?"
    },
    {
        "source": "mattermost",
        "post_id": "6zkx7mhtefrw8k9urnc86gco5o",
        "create_at": 1715185009420,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "do you know where I can find the code repository version for this `VO_ALICE@O2DPG::async-20240115.3.trd-1` tag? I am not finding it on github. I don't strictly need it but I'm curious\ndo you know where I can find the code repository version for this `VO_ALICE@O2DPG::async-20240115.3.trd-1` tag? I am not finding it on github. I don't strictly need it but I'm curious",
        "question": "Where can I find the code repository version for the `VO_ALICE@O2DPG::async-20240115.3.trd-1` tag?"
    },
    {
        "source": "mattermost",
        "post_id": "oahzadjqdjgf9xrhk5weyjpa4a",
        "create_at": 1715185171137,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "oh that's what I missed, thanks a lot\noh that's what I missed, thanks a lot\n@bvolkel when I try to use the grid_submit.sh script \n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_jets_anchored.sh --jobname testJetAnchoredLHC22o_100x10Evts_2 --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2DPG::async-20240115.3.trd-1\" --wait --fetch-output --asuser alandou\n```\nI'm used to using O2sim instead of O2DPG, but there's no `O2sim::async-20240115.3.trd-1` package. I tried adding all the dependencies mentioned in alimonitor.cern.ch/packages but the log from grid_submit.sh tells me I have `too many arguments`\n@bvolkel when I try to use the grid_submit.sh script \n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_jets_anchored.sh --jobname testJetAnchoredLHC22o_100x10Evts_2 --outputspec \"*.log@disk=1\",\"*.root@disk=2\" --packagespec \"VO_ALICE@O2DPG::async-20240115.3.trd-1\" --wait --fetch-output --asuser alandou\n```\nI'm used to using O2sim instead of O2DPG, but there's no `O2sim::async-20240115.3.trd-1` package. I tried adding all the dependencies mentioned in alimonitor.cern.ch/packages but the log from grid_submit.sh tells me I have `too many arguments`\nonly giving `VO_ALICE@O2DPG::async-20240115.3.trd-1` resulted in [this job](https://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3074165792) that took 0.60 seconds and has no output\nonly giving `VO_ALICE@O2DPG::async-20240115.3.trd-1` resulted in [this job](https://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3074165792) that took 0.60 seconds and has no output\nah I see that there's a `VO_ALICE@O2sim::async-2023-PbPb-apass2-trd-20240229.1-1` package in the list\nah I see that there's a `VO_ALICE@O2sim::async-2023-PbPb-apass2-trd-20240229.1-1` package in the list\nnot sure why it's called PbPb when it has been used for pp\nnot sure why it's called PbPb when it has been used for pp\nHi, me again\nI ran the simulation; it seems to have worked fine if I look at the [log file](https://alimonitor.cern.ch/users/download.jsp?view=true&path=%2Falice%2Fcern.ch%2Fuser%2Fa%2Falandou%2Frecycle%2Falien-job-3074173007%2Fstdout): `**** Pipeline done success (global_runtime : 4719.806s) *****\n`. However I cannot find any AO2D file in the destination folder. The QC did fail but I does that stop the AO2D from being saved?",
        "question": "What could be the reason for not finding any AO2D file in the destination folder after running the simulation, and does the QC failure stop AO2D from being saved?"
    },
    {
        "source": "mattermost",
        "post_id": "jx5sd7xswb8ybf1t9dfadmbbna",
        "create_at": 1715194472609,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "I don't set any defult output spec in my run_anchored.sh script where I set the anchoring options before running ${O2DPG_ROOT}/MC/run/ANCHOR/anchorMC.sh\n",
        "question": "Where should I set the default output specification if I don't set it in my run_anchored.sh script?"
    },
    {
        "source": "mattermost",
        "post_id": "rr69y77bz3g6bd73odqytqu3oo",
        "create_at": 1715605571619,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Hey Benedikt, unfortunatlly I don't see a `.stat` file neither in my local directory nor in the one on the grid.\nDo I need to  add the `.stat` files like `--outputspec \"*.stat@disk=1\"`?\n\nThere is one more think I was stumbling across.\nWhen I look at the AO2D file and analyse it with a local task, I'm looking at histograms filled with electrons from different sources. Somehow the histograms seem a loot like double counting is happening there.\nIs this expected due to the `SEED=5` set in the anchorMC.sh script?\nHey Benedikt, unfortunatlly I don't see a `.stat` file neither in my local directory nor in the one on the grid.\nDo I need to  add the `.stat` files like `--outputspec \"*.stat@disk=1\"`?\n\nThere is one more think I was stumbling across.\nWhen I look at the AO2D file and analyse it with a local task, I'm looking at histograms filled with electrons from different sources. Somehow the histograms seem a loot like double counting is happening there.\nIs this expected due to the `SEED=5` set in the anchorMC.sh script?",
        "question": "Do I need to add the `.stat` files like `--outputspec \"*.stat@disk=1\"`?"
    },
    {
        "source": "mattermost",
        "post_id": "frw7jkhofbre5qzyrtjtsfckfc",
        "create_at": 1716455499862,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi @swenzel and @bvolkel . Following the previous discussions with our UPC users and the help from Marco in setting up STARlight on GRID, I have been trying to get the recipe to run STARlight directly on the job (instead of manually providing the HepMC files myself) but with no success... As a reminder the recipe we were talking about was:\n- upload the configuration files for STARlight and the utility files to convert to HepMC to a utility directory on `alien` \n- launch the job with the script copying these files to the working directory\n- launching starlight and converting the output to HepMC\n- launching the anchoring script\nUnfortunately all my attempts are failing according to GRID because of some issue maybe at the level of loading the environment:\n``` \nMay 23 10:55:13 [state ]: Job state transition from ASSIGNED to STARTED\nMay 23 10:55:14 [trace ]: Getting InputFile: /alice/cern.ch/user/s/siragoni/selfjobs/testJpsiInPP-20240523-085400/alien_jobscript.sh to /workdir/alien_jobscript.sh (2.537 KB)\nMay 23 10:55:14 [trace ]: Getting InputFile: /alice/cern.ch/user/s/siragoni/selfjobs/testJpsiInPP-20240523-085400/testJpsiInPP-20240523-085400.sh to /workdir/testJpsiInPP-20240523-085400.sh (23.41 KB)\nMay 23 10:55:23 [trace ]: Error setting the environment for [VO_ALICE@O2sim::v20240516-1,VO_ALICE@STARlight::20240714-2]\nMay 23 10:55:24 [state ]: Job state transition from STARTED to ERROR_IB\n``` \nThe jobs are launched with:\n``` \n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_anchored_prod_rho_pp_online_starlight.sh --jobname testJpsiInPP --outputspec \"*.log@disk=1\",\"*.root,tf*/o2*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240516-1\",\"VO_ALICE@STARlight::20240714-2\" --wait --fetch-output\n``` \nIn particular, the environments are loaded as `\"VO_ALICE@O2sim::v20240516-1\",\"VO_ALICE@STARlight::20240714-2\"`... Thanks in advance for any help!",
        "question": "What is the issue with loading the environment for the job when trying to run STARlight directly on the job using the provided recipe?"
    },
    {
        "source": "mattermost",
        "post_id": "jwxc5fpje3najyz5ua7sf3z1ao",
        "create_at": 1716459780817,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "Is it really \"20240714-2\"? 07 means future release in July. ",
        "question": "Is \"20240714-2\" a future release in July?"
    },
    {
        "source": "mattermost",
        "post_id": "5igxfokxi3bqdr69cr8z93d16y",
        "create_at": 1716799921329,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "Hi @swenzel, I did some comparisons anchored pp (Pb-Pb is unefficient) vs regular MC efficiency. For anchored, I did simulation by myself with HepMC files (Superchic 4.2 + PYTHIA8.2). Then I run anchored script. The regular MC was done by @pbuhler. There are 4 charged tracks in the event (so very low multiplicity). From comparison I have reconstruction efficiency ~41% for regular MC and 9% for anchored one. I also found that somehow up-down direction is prefered in the anchored MC (like in cosmics reconstruction). Also pT dependence is weird (almost constant vs pT) in anchored MC, while in regular it is low at low-pT and rising towards higher pT. Could you look into that, please?",
        "question": "Could you look into the reconstruction efficiency and pT dependence differences between regular MC and anchored MC?"
    },
    {
        "source": "mattermost",
        "post_id": "1ikzgkmo57nhmpcxatyomt6szw",
        "create_at": 1716803752839,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi @amatyja this may be related to an issue we recently opened a JIRA ticket for - [O2-4979](https://its.cern.ch/jira/browse/O2-4979) - we're preparing a jet-jet anchored pp MC and noticed that ~6x more tracks are rejected through the global track selection in our anchored test MC compared to the unanchored one. It also seems more tracks are rejected at high pT, so some pT dependence that may follow the trend you observe. The selection on the track DCA seems to be the primary cause of the inefficiency difference in our case, though at the moment we don't know the reason. \nwhat track selection are you applying here? It would be interesting to see the reconstructed track eta, phi and pT distributions (where we see significant differences in the trend comparing anchored and unanchored), to see if its the same issue",
        "question": "What track selection are you applying here? It would be interesting to see the reconstructed track eta, phi and pT distributions (where we see significant differences in the trend comparing anchored and unanchored), to see if it's the same issue."
    },
    {
        "source": "mattermost",
        "post_id": "qk39yodn83b1jdaewwbukfj9da",
        "create_at": 1717420096418,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Hi, after some recent discussions, I would like to use this channel to comment on some particularities when using the HepMC event generator in standalone MC tests on the GRID. \n\nIn fact, some extra care needs to be taken when using this generator with persisted files. This is due to the fact that when reading from files, it is more difficult to achieve a correct distribution of events over timeframes and MC-jobs. \n\nWhen using the default Pythia8 on-the-fly generator, this is known to be correct as long as different MC jobs have a different seed (usually taken from ALIEN_PROC_ID).\n\nUnfortunately, for HepMC, used in the following typical pattern:\n```bash\n# fetch a HepMC file from Alien\nalien.py cp HepMC_events_file.hepmc file:./events.hepmc\n\n# use this in a (unachored MC) job with 5 timeframes\n${O2DPG_ROOT}/MC/bin/o2dpg_sim_workflow.py -gen hepmc -confKey \"GeneratorFileOrCmd.fileNames=${PWD}/events.hepmc\" -tf 5 -intRate 50000 -ns 1000 --seed 11 ...\n\n# run job\n${O2DPG_ROOT}/MC/bin/o2dpg_workflow_runner.py -f workflow.json -tt aod\n```\n\nthis **did not yet work** out of the box because each timeframe read from the hepmc file **from the start**. Hence all timeframes saw the same events and statistics is likely biased.\n\nWe have, last week, made 2 important fixes in this direction ( [AliceO2Group/AliceO2#13193](https://github.com/AliceO2Group/AliceO2/pull/13193) and [AliceO2Group/O2DPG#1654](https://github.com/AliceO2Group/O2DPG/pull/1654)) which should improve upon this situation: From now on, consecutive timeframes will **seek** to the correct position in the HepMC file for reading. I would appreciate if you could test this and provide feedback. It is important to note that the HepMC file must contain enough events for the whole MC job ... otherwise it will (currently) crash.\n\nThis brings me to a second, related, point: Users doing HepMC studies **spread over multiple MC jobs** on the GRID (such as anchored MC sampling of a whole run), should make sure **not to use** the same HepMC file in each of these sub-jobs. This is because each job would again see the same event sequence.\n\nLet's look at a concrete example for anchored MC: Say, you would like to simulate a larger sample of 100K events distributed over some run. Then you could submit 10 parallel jobs, of each 10K events, to the GRID using the `--prodsplit` feature of `grid-submit.sh` with the following command line.\n```\n# will submit 10 parallel jobs running my_job\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script my_job.sh\\\n               --outputspec AO2D.root\\\n               --packagespec O2sim::v20240528-1\\\n               --prodsplit 10\n```\n\n```bash\n#!/usr/bin/bash\n## -- content of my_job.sh (custom anchored MC study) ----\n\nexport ALIEN_JDL_LPMANCHORPASSNAME=apass2\nexport ALIEN_JDL_MCANCHOR=apass2\nexport ALIEN_JDL_COLLISIONSYSTEM=pp\nexport ALIEN_JDL_CPULIMIT=8\nexport ALIEN_JDL_LPMPASSNAME=apass2\nexport ALIEN_JDL_LPMRUNNUMBER=544167\nexport ALIEN_JDL_LPMPRODUCTIONTYPE=MC\nexport ALIEN_JDL_LPMINTERACTIONTYPE=pp\nexport ALIEN_JDL_LPMPRODUCTIONTAG=LHC24a1\nexport ALIEN_JDL_LPMANCHORRUN=544167\nexport ALIEN_JDL_LPMANCHORPRODUCTION=LHC22o\nexport ALIEN_JDL_LPMANCHORYEAR=2023\n\n# inform the script about size of production and the ID of this job\n# The environment variables ALIEN_...GRIDSUBMIT are set from the `grid-submit script`\nSPLITID=${ALIEN_O2DPG_GRIDSUBMIT_SUBJOBID}\nPRODSPLIT=${ALIEN_O2DPG_GRIDSUBMIT_PRODSPLIT}\n\n# fetch the right hepmc file for this job id\nalien.py cp /somepath/HepMC_id${SPLITID}.hempc file:./hepmc_events.hepmc\n\n# set the simulation options (configuring hepmc)\nexport ALIEN_JDL_ANCHOR_SIM_OPTIONS=\"-gen hepmc -confKey GeneratorFileOrCmd.fileNames=${PWD}/hepmc_events.hepmc\"\n\n# define number of timeframes and\n# events per timeframe (should match roughly with interaction rate of run or be smaller)\nexport NTIMEFRAMES=10\nexport NSIGEVENTS=1000\n\nexport CYCLE=0\n${O2DPG_ROOT}/MC/run/ANCHOR/anchorMC.sh\n```\n\nIn summary, this example demonstrates the possibility of setting up a parallel MC study with grid_submit.py and shows how to use environment variables such as ${ALIEN_O2DPG_GRIDSUBMIT_SUBJOBID} to infer which HepMC file to use.\n\nI hope that this clarifies a few questions and issue with HepMC usage. We will also try to update the documentation at https://aliceo2group.github.io/simulation/ in this regard.",
        "question": "What are the key considerations and steps for using HepMC files in MC simulations on the GRID to avoid biased statistics and ensure correct distribution of events over timeframes?"
    },
    {
        "source": "mattermost",
        "post_id": "9p13mi1tsb81udgube3w9zriqw",
        "create_at": 1717664950813,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Dear experts, \nI submitted yesterday a few test simulations to the grid. The job status is marked as successful, however the output directory does not contain a `root` file and the `.stat` file does not match the correct statistic of events asked for from the `NTIMEFRAMES=1`\n and `NSIGEVENTS=200` in the JDL. \nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3092651539&details=1&input=0\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3092651552&details=1&input=0\n(I also noticed that the run time for the jobs is very different which is not expected.)\n\nThe job script saved seems correct: https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/f/feisenhu/selfjobs/grid_ini5_tf1_200ev-20240605-124825/alien_jobscript.sh\nThe command I have used is: \n```\n${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script /data/feisenhut/alice/O2DPG/MC/run/PWGEM/runAnchoredHFGapToDielectrons_pp_Gap5.sh --jobname grid_ini5_tf1_200ev --outputspec \"*.log@disk=1\",\"*.txt@disk=1\",\"*.root@disk=2\",\"*.stat@disk=1\" --packagespec \"VO_ALICE@O2sim::v20240605-1\" --wait --fetch-output --asuser feisenhu\n```\nIs there something I did wrong? Any help would be great. Thank you vey much.",
        "question": "Why is the output directory missing a `.root` file and not matching the correct statistic of events asked for in the JDL?"
    },
    {
        "source": "mattermost",
        "post_id": "5nzbazh6mp8abn4y6q14cbm6kh",
        "create_at": 1717674576728,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "Hi Sandro, somehow I also see the same\nhttps://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fa%2Falcaliva%2Fselfjobs%2Ftest_strangenessInJets-20240606-104135%2F001#/alice/cern.ch/user/a/alcaliva/selfjobs/test_strangenessInJets-20240606-104135/001\nthe job is DONE but there is no aod.root file\n@swenzel , indeed, my job crashes with \n\nStop on failure  True\nsetting up ROOT system\nrestdigi_1 failed ... checking retry\nJob done\nyou wrote that the restdigi task is simulating digitization for small detectors .... which ones? can one disable them if not needed?\nI tried and it doesn't work",
        "question": "Which small detectors are simulated by the restdigi task, and can they be disabled if not needed?"
    },
    {
        "source": "mattermost",
        "post_id": "ne6w7ej5mpb9t8bzfnk6e1hkah",
        "create_at": 1717710421337,
        "user_id": "bznhtse8pprufp5eogr84qhmxa",
        "message": "Dear experts, I have a question about production vertex of injected signals. Let's say a mc collision vertex (x, y, z) simulated by pythia8 is (0, 0, 1) as  an underlying event . Next, I have a cocktail generator containing pi0 and eta. When the cocktail generator is injected to the underlying pythia8 event, where is the production vertex of pi0 and eta? (0, 0, 0) or (0, 0, 1), or somewhere else? Thank you.\nI am sorry for my wide post again. If one wants pythia8 as an underlying event and injected signals (pi0, eta, eta', rho, omega, phi, Jpsi/ psi2s mesons), what is the difference between embedding simulation and cocktail simulation containing pythia8 + 8 mesons?",
        "question": "Where is the production vertex of pi0 and eta when injected into a pythia8 event with an underlying vertex at (0, 0, 1)? Is it (0, 0, 0) or (0, 0, 1), or somewhere else?"
    },
    {
        "source": "mattermost",
        "post_id": "fruayfibnjnwfrjxzzrp66miwa",
        "create_at": 1717746301725,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "If you refer to signal-background embedding as done in O2DPG, all signals should get the same vertex as the event they are embedded into. So it should be (0,0,1).",
        "question": "In signal-background embedding as done in O2DPG, should all signals get the same vertex as the event they are embedded into, specifically (0,0,1)?"
    },
    {
        "source": "mattermost",
        "post_id": "8n9kxbaz9jnefc7z3yftk7iuwa",
        "create_at": 1717769604662,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "So this seems more like a general problem. \nIs this being followed up? \nIs there something else we could try to avoid this crash and run on the grid?",
        "question": "Is there something else we could try to avoid this crash and run on the grid?"
    },
    {
        "source": "mattermost",
        "post_id": "6i8g5frfktrjjkd1waqf77pqww",
        "create_at": 1717788553589,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "Hi Sandro, I also tried again and this time I see more files produced. Still, no aod. The job went into DONE state ",
        "question": "What could be the reason for producing more files but still not generating an AOD, even though the job went into the DONE state?"
    },
    {
        "source": "mattermost",
        "post_id": "3j7rhtiizfgh8rwy855g1g7i9r",
        "create_at": 1718101676742,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "Hi Sandro. Thanks. Not clear where to add these lines ... the script that I launch contains the definition of several environment variables and then the last line is ${O2DPG_ROOT}/MC/run/ANCHOR/anchorMC.sh\nwhich job script should I modify?",
        "question": "Which job script should I modify to add the required lines?"
    },
    {
        "source": "mattermost",
        "post_id": "x74g51cgp7fgzndx6sm6zwycro",
        "create_at": 1718121578154,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, following on from [our discussion at the WP12/13 meeting last week](https://indico.cern.ch/event/1423846/contributions/5991855/attachments/2871499/5027394/O2_AnchoredMCtests_QAtask_WP12_3.pdf) about anchored MC issues we've been having, we have run our anchored and unanchored setup saving the workflow.json and all debug/ccdb files - the information is added to [the JIRA ticket](https://its.cern.ch/jira/browse/O2-4979) . It would be great if those more expert than us could take a look and see if they can spot anything in the debug files that points to the issue. Thanks a lot!",
        "question": "Could experts review the debug files to identify any issues related to anchored MC problems?"
    },
    {
        "source": "mattermost",
        "post_id": "ntpyzi5fyjrhbepqtraaipqtgh",
        "create_at": 1718183071542,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Thank you very much. Also my Jobs have succeeded. However I noticed that the output of the AO2D file is much smaller (40KB now, where it was 6MB before).\nLooking into the file it seems that a lot of branches do not have any content. \n@alcaliva Do you also see something similar, or is your output fine?\nFurther I experience a large difference in the run time of specific tests. While some finish within a 20min some need hours (4-20h) or even run into an error due to exceeding the runtime (TTL).\nSome of the jobs spent a lot of time (also hours) in WAITING (SPLIT) status.",
        "question": "Why is the size of the AO2D file much smaller and why do some jobs take a very long time to complete or fail?"
    },
    {
        "source": "mattermost",
        "post_id": "zz4mabiepp8s9moansdbegr6be",
        "create_at": 1718196043903,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "my output looks sane\n@swenzel , where does one get the total running time? I see that there are a few pipeline_action_xxxxxx.log files produced and each of them shows a global_runtime. Should one sum them all? ",
        "question": "Should the total running time be obtained by summing the global_runtime from all pipeline_action_xxxxxx.log files?"
    },
    {
        "source": "mattermost",
        "post_id": "jts7srg37pnmjfp35djny4myia",
        "create_at": 1718267840984,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi @swenzel and @bvolkel , sorry in advance for the very unusual question, but since the GRID jobs do not seem to save for me the output if the job itself fails, I am unable to check why the job failed in the first place... The output from the `stdout` is:\n``` \nStop on failure  True\nsetting up ROOT system\nrestdigi_1 failed ... checking retry\nINFO [anchorMC]: Running TPC time series\nLaunching task: ${O2_ROOT}/bin/o2-sim-digitizer-workflow -b --run --condition-not-after 3385078236000 -n 1000 --sims sgn_1 --interactionRate 675881 --incontext collisioncontext.root --disable-write-ini --configKeyValues \"HBFUtils.orbitFirstSampled=175761246;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162;DigiParams.seed=504627853;MCHDigitizer.seed=504627853\" --onlyDet ITS,TOF,FDD,MCH,MID,MFT,HMP,PHS,CPV,ZDC --ccdb-tof-sa --forceSelectedDets --combine-devices  &> restdigi_1.log &\nLaunching task: ${O2_ROOT}/bin/o2-sim-digitizer-workflow --only-context --interactionRate 675881 -b --run -n 1000 --sims sgn_2 --seed 504627854 --configKeyValues \"HBFUtils.orbitFirstSampled=175761278;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162;DigiParams.passName=${ALIEN_JDL_LPMANCHORPASSNAME:-unanchored}\" --incontext collisioncontext.root --bcPatternFile ccdb &> digicontext_2.log &\nLaunching task: ${O2_ROOT}/bin/o2-fv0-reco-workflow -b --run --condition-not-after 3385078236000 --configKeyValues \"HBFUtils.orbitFirstSampled=175761246;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162\" &> fv0reco_1.log &\nLaunching task: ${O2_ROOT}/bin/o2-emcal-reco-workflow --input-type digits --output-type cells --infile emcaldigits.root --disable-root-output --subspecificationOut 1 --configKeyValues \"HBFUtils.orbitFirstSampled=175761246;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162\" | ${O2_ROOT}/bin/o2-emcal-cell-recalibrator-workflow --input-subspec 1 --output-subspec 0 --no-timecalib --no-gaincalib --configKeyValues \"HBFUtils.orbitFirstSampled=175761246;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162\" --isMC | ${O2_ROOT}/bin/o2-emcal-cell-writer-workflow --subspec 0 -b --run --condition-not-after 3385078236000 &> emcalreco_1.log &\ncommand ${O2_ROOT}/bin/o2-sim-digitizer-workflow -b --run --condition-not-after 3385078236000 -n 1000 --sims sgn_1 --interactionRate 675881 --incontext collisioncontext.root --disable-write-ini --configKeyValues \"HBFUtils.orbitFirstSampled=175761246;HBFUtils.nHBFPerTF=32;HBFUtils.orbitFirst=161875806;HBFUtils.runNumber=536757;HBFUtils.startTime=1684649621162;DigiParams.seed=504627853;MCHDigitizer.seed=504627853\" --onlyDet ITS,TOF,FDD,MCH,MID,MFT,HMP,PHS,CPV,ZDC --ccdb-tof-sa --forceSelectedDets --combine-devices  had nonzero exit code 128\nStop on failure  True\nsetting up ROOT system\nrestdigi_1 failed ... checking retry\n``` \nAnd I am using the usual script with the addition of the new features for splitting of the HepMC files (attached), with the command:\n``` \n ${O2DPG_ROOT}/GRID/utils/grid_submit.sh --script run_anchored_prod_roman_pp_all.sh --jobname testRoman --outputspec \"*.log@disk=1\",\"*.root,tf*/o2*.root@disk=2\" --packagespec \"VO_ALICE@O2sim::v20240610-1\" --prodsplit 10 --wait --fetch-output\n``` \nWould you be able to tell me how to save these intermediate files in case? So that I can have a better look on why it failed? Thanks in advance",
        "question": "How can I save intermediate files in case of a failed job to better understand why it failed?"
    },
    {
        "source": "mattermost",
        "post_id": "duruo8faypdofgxce5u1cqttoy",
        "create_at": 1718279788653,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "That depends what you mean. Generally it might be easiest putting a `time` in front of whatever command you are running on the GRID. But if you run anchorMC with grid_submit, them you could either simply take a look in file `alien_log_${ALIEN_PROC_PID}.txt` which captures all the stdout in grid_submit (but you have to store the file to Alien) and search for ` **** Pipeline done success (global_runtime : 555.043s) *****\n`   or you take a look at `pipeline_metric_`: The time will be the last iteration index **times 5s**.",
        "question": "How can I find the runtime of the anchorMC simulation when using grid_submit?"
    },
    {
        "source": "mattermost",
        "post_id": "49repbc99jfwbdxjyf1znzkdpy",
        "create_at": 1718280577277,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "ok. Just cross-checked and they coincide with those reported in the pipeline_metric_ID files\nThanks\nHi @swenzel, is the tool for parallelization available also for generation? or is it working only for the transport? \nMy MC generator spends a lot of time in generating events (due to the specific configuration, nothing wrong with it) rather than in the GEANT part. Also, how can I monitor the CPU efficiency? The output test is here: https://alimonitor.cern.ch/catalogue/#/alice/cern.ch/user/a/alcaliva/selfjobs/strangeness_in_jets_test01-20240611-121616/001",
        "question": "Is the tool for parallelization available also for generation, or is it working only for the transport?"
    },
    {
        "source": "mattermost",
        "post_id": "fps84ias9tbymde6oywb3ttp3c",
        "create_at": 1718635666443,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Dear @swenzel,\nI have tried now to use different tags with and without your suggested solution, but it seems that my jobs on the grid still do not run properly.\nI had a look at their outputs and log files but I did not find any obvious errors or issues. They seem to run very long compared to the tests before the bug. (used to be within 20-30 min)\nSome of them now just run in to TTL Error and some complete with a very small AO2D file, seemingly not created/filled correctly.\nCould I ask you to have another look?\nI'm puzzled and can't figure out what might go wrong.\n\nYou can find the latests tests I have ran here:\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3099482856&details=1\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3099521177&details=1&input=0\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3099520910&details=1&input=0\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3099520206&details=1&input=0\nhttps://alimonitor.cern.ch/agent/jobs/details.jsp?pid=3099544419&details=1",
        "question": "Could you have another look at my recent grid jobs as they are not running properly and seem to produce issues with AO2D files or TTL errors?"
    },
    {
        "source": "mattermost",
        "post_id": "jjr1wy3rwjr95cas6dzkcn463o",
        "create_at": 1718703260922,
        "user_id": "d1emreg7tiypzd4xqx564b54qc",
        "message": "Hey @swenzel and @feisenhu \nThank you for taking a look. Debugging locally is probably a good idea.\nif I recall correctly Florian already performed some tests in the past, which looked ok with the same generators. What should have changed since then is an implementation to check the generators in the AO2D files in the analysis.\nThe PR: [AliceO2Group/O2DPG#1657](https://github.com/AliceO2Group/O2DPG/pull/1657)\nBefore this, the generators seemed to perform OK. Could it be related to this?",
        "question": "Could it be related to PR [AliceO2Group/O2DPG#1657] that generators no longer perform OK in the analysis?"
    },
    {
        "source": "mattermost",
        "post_id": "hd4cywjt378tfbc6nd8gpz4kdw",
        "create_at": 1718704790409,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Just checking on lxplus: The following command `${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;\" -g external --configFile /cvmfs/alice.cern.ch/el9-x86_64/Packages/O2DPG/daily-20240617-0200-1/MC/config/PWGEM/ini/GeneratorHFGapTriggered_BeautyNoForcedDecay_Gap3.ini -o genevents --timestamp 1664862656927 --seed 513514879 -n 200 --fromCollContext collisioncontext.root:sgn_1 &> sgngen_1.log &` (which is running event generation) only produced 2 events within 30minutes runtime. So 200 events will need 30 00 minutes ---> which would explain going out of TTL. ",
        "question": "Why is the command producing only 2 events in 30 minutes, and how long will it take to generate 200 events?"
    },
    {
        "source": "mattermost",
        "post_id": "h97dcqzu4bfnf8zrpehn6dx4zw",
        "create_at": 1718708832097,
        "user_id": "d1emreg7tiypzd4xqx564b54qc",
        "message": "Thank you for having a look and helping out here. Just for me to understand. Would this mean, that in all cases the generator gets the \"default\" flag and then an additional one, or would line 5 overwrite line 4?",
        "question": "Would line 5 overwrite line 4, or does the generator get the \"default\" flag and then an additional one in all cases?"
    },
    {
        "source": "mattermost",
        "post_id": "34h6e7z7uigp7cgtj1tcwwy7ko",
        "create_at": 1718716900740,
        "user_id": "d1emreg7tiypzd4xqx564b54qc",
        "message": "But wouldnt it then look more something like:\n```c++\nGeneratorPythia8GapTriggeredHFLepton((TString configsignal, int quarkPdg = 4, int lInputTriggerRatio = 5, int lInputExternalID = 0))\n{\n  // some default\n if (lInputExternalID == 0) {addSubGenerator(0, \"my default generator\");}\nelse { addSubGenerator(lInputExternalID, \"my external generator\");} // if that is also 0, it wouldn't be added\n  // ...\n}\n```",
        "question": "Would the function look something like this?"
    },
    {
        "source": "mattermost",
        "post_id": "z84ufwoq3jrzdrhqzqo6bbh8ka",
        "create_at": 1718717096445,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "I thought you would always have `0` as the default and `lExternalID`\nSO my understanding would be that you would always set both and **not** either-or\nhttps://github.com/AliceO2Group/O2DPG/blob/master/MC/config/PWGEM/external/generator/Generator_pythia8_GapTriggered_HFLepton.C#L88-L96\n\nAnd I was assuming that `0` would always indicate the default.\n\n",
        "question": "What is the default value for `lExternalID` and when should it be set to `0`?"
    },
    {
        "source": "mattermost",
        "post_id": "futdiwwbcbyp7bdif6jmd6kaee",
        "create_at": 1718720044351,
        "user_id": "d1emreg7tiypzd4xqx564b54qc",
        "message": "I will check again, but L88 and L96 should be either-or, not both. It should be `0` in case a min bias event from the gap trigger is generated and in case we have a \"signal\" event we want to set the ID for an external generator.\nHowever. More for my understanding. Could this be the reason the event generation takes longer than usual?",
        "question": "Could the requirement for either L88 or L96 to be set as `0` based on the event type be the reason for longer event generation times?"
    },
    {
        "source": "mattermost",
        "post_id": "uwronser4igutn7dpyes88t6sw",
        "create_at": 1718803645201,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "Thank you, for your help. The fix from yesterday works and the runtime and output seem to be normal again.\nI just have a last question. When using the addSubGenerator function, the information should be stored in the AO2D file, right? I have not found the a corresponding tree or branch.",
        "question": "When using the addSubGenerator function, the information should be stored in the AO2D file, right? I have not found the corresponding tree or branch."
    },
    {
        "source": "mattermost",
        "post_id": "ynjc7unssirzzgwiccw1yqpkch",
        "create_at": 1718804091447,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "Does this help top access the gen IDs from the AODs?\nhttps://aliceo2group.github.io/simulation/docs/generators/generatorconfig.html#generator-ids\n\nThey are in `mcCollisions` since at the moment teh IDs are attached per collision.",
        "question": "Does this help with accessing gen IDs from the AODs?"
    },
    {
        "source": "mattermost",
        "post_id": "g8dzyme1kjf58ni373856miime",
        "create_at": 1718804786053,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "But you can use `mcCollisions::getSubGeneratorID()` to get the subGen ID of that collision. Or am I misunderstanding something?",
        "question": "How can I get the subGenerator ID of a collision using ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "f7ga7e3zm3dfujfcy9o3y7m6yy",
        "create_at": 1718806057722,
        "user_id": "c97m9narciy19xj7e9sg8ucfma",
        "message": "True, the information should be accessed that way. I just tried to verify if the SubGeneratorID is saved correctly in the AO2D file and thus was looking for something like a `SubGeneratorID`-Branch within the AO2D file. Which I did not found. ",
        "question": "Why was the `SubGeneratorID` branch not found in the AO2D file when verifying if the `SubGeneratorID` is saved correctly?"
    },
    {
        "source": "mattermost",
        "post_id": "yy1n9xh97jncmmqch3jrk967no",
        "create_at": 1718806245677,
        "user_id": "migboig5jpfdi8ursydgy8izuh",
        "message": "If there are still any problems and if you can't then access the IDs. could you send me an AOD of your tests?",
        "question": "Could you send me an AOD of your tests if there are still problems accessing the IDs?"
    },
    {
        "source": "mattermost",
        "post_id": "wcatbu4sk3nupfg6pze8ttkgzo",
        "create_at": 1718983372358,
        "user_id": "ojamyqznoidf8yen67drwoxnsy",
        "message": "Dear experts, I am trying to run an anchored PbPb simulation locally but I am facing some issues. In particular, the script I am using (`run_anchored_mc.sh`, attached below) gets stuck at this command:\n`o2-grp-simgrp-tool createGRPs --timestamp 1696470629787 --run 544013 --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf 32 --field ccdb --readoutDets ITS CPV FV0 TPC TRD FDD FT0 CTP TOF HMP MFT PHS MCH MID --print --lhcif-CCDB &> grpcreate.log &`\nand continues filling a `pipeline_metric.log` file with this kind of information: `2024-06-20 23:18:19,261 INFO {'iter': 4491, 'name': 'grpcreate', 'cpu': 0.0, 'uss': 272.4609375, 'pss': 273.4990234375, 'nice': 0, 'swap': 0.0, 'label': []}` but it does not pass this step. Do you have any idea what could be causing it being stuck? Or am I missing some information in the .sh script?\nThanks a lot in advance for your assistance!\nDear experts, I am trying to run an anchored PbPb simulation locally but I am facing some issues. In particular, the script I am using (`run_anchored_mc.sh`, attached below) gets stuck at this command:\n`o2-grp-simgrp-tool createGRPs --timestamp 1696470629787 --run 544013 --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf 32 --field ccdb --readoutDets ITS CPV FV0 TPC TRD FDD FT0 CTP TOF HMP MFT PHS MCH MID --print --lhcif-CCDB &> grpcreate.log &`\nand continues filling a `pipeline_metric.log` file with this kind of information: `2024-06-20 23:18:19,261 INFO {'iter': 4491, 'name': 'grpcreate', 'cpu': 0.0, 'uss': 272.4609375, 'pss': 273.4990234375, 'nice': 0, 'swap': 0.0, 'label': []}` but it does not pass this step. Do you have any idea what could be causing it being stuck? Or am I missing some information in the .sh script?\nThanks a lot in advance for your assistance!",
        "question": "What could be causing the script to get stuck at the `o2-grp-simgrp-tool createGRPs` command, and is there any missing information in the script?"
    },
    {
        "source": "mattermost",
        "post_id": "43xrng6zwfrbpd6c9ikst85dxo",
        "create_at": 1718985486146,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Ok. I would need to see the file `grpcreate.log` please.\nOk. I would need to see the file `grpcreate.log` please.",
        "question": "What file do I need to see?"
    },
    {
        "source": "mattermost",
        "post_id": "mz3md7xbkjbndxq7gagk6pj74w",
        "create_at": 1718987026739,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Ok it hangs during a CCDB operation. Are you on Linux and if yes could you take a look in `/dev/shm/*`? Do you see any `*sem*` files? If yes, try to cleanup this directory and start again. Alternatively, please try to start the workflow from scratch **in a new workspace directory**.\nOk it hangs during a CCDB operation. Are you on Linux and if yes could you take a look in `/dev/shm/*`? Do you see any `*sem*` files? If yes, try to cleanup this directory and start again. Alternatively, please try to start the workflow from scratch **in a new workspace directory**.",
        "question": "Are you on Linux and if yes could you take a look in `/dev/shm/*`? Do you see any `*sem*` files? If yes, try to cleanup this directory and start again. Alternatively, please try to start the workflow from scratch in a new workspace directory?"
    },
    {
        "source": "mattermost",
        "post_id": "nbt8y43wpt8wpqz3i5yssazqjh",
        "create_at": 1719214141497,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi Sandro, Benedikt, I need (again!) your help. For my EMCAL simulations I need to be able to tell apart low interaction rates runs from high rate runs. To do this, I was suggested to look to the `GRP` classes, but I don't see any instance of interaction rate relevant code in either `GRPObject` or `GRPLHCIF`. Afterwards I found out that in your anchoring script for `o2dpg` (i.e. `o2dpg_sim_workflow_anchored.py`) that you manually compute the interaction rate from the `CTP scalers`. Is this the only (currently available) way of doing so?",
        "question": "Is manually computing the interaction rate from the CTP scalers in the anchoring script the only (currently available) way to distinguish between low and high interaction rate runs for EMCAL simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "38d8gob1i3rnpj1ngjhsunkq9r",
        "create_at": 1719215976276,
        "user_id": "ojamyqznoidf8yen67drwoxnsy",
        "message": "Hi @swenzel ! Apologise for the late response, removing the `sem` file worked! The simulation ends, and produces and merges the AO2Ds. Right now I am trying to simulate with an external generator enabling the embedding option (like in `run_anchored_mc_hf.sh`), but the simulation appears not to be producing the `workflow.json` and  immediately stops. Do you have any idea what could be causing this? Thanks a lot (again) in advance!\nHi @swenzel ! Apologise for the late response, removing the `sem` file worked! The simulation ends, and produces and merges the AO2Ds. Right now I am trying to simulate with an external generator enabling the embedding option (like in `run_anchored_mc_hf.sh`), but the simulation appears not to be producing the `workflow.json` and  immediately stops. Do you have any idea what could be causing this? Thanks a lot (again) in advance!",
        "question": "What could be causing the simulation to immediately stop without producing the `workflow.json` when using an external generator with the embedding option?"
    },
    {
        "source": "mattermost",
        "post_id": "e66z7sm83jn3my6bra55o473xo",
        "create_at": 1719227548143,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "If there is no `workflow.json` produced, this probably means that the pre-processing failed. In your case there is an error in file `timestampsampling...log` indicating a typo in simulation options: It is `--embeddPattern` and not `--embedPattern` (But you can omit this option alltogether in your case). Having said that, I'd like to raise awareness that embedding workflows have not been fully production-validated when used in the anchorMC script (or it needs improvement). It should work, if you specify the right amount of background events yourself (which you do). Be careful to choose the event number so that it matches the timeframe length and interaction rate. A timeframe length of 32 orbits at 10kHz should have less than `~(0.09ms/orbit * 32orbits) * 10**-3 * 10000 1/s` ~ 32 background events. If you specify more, there will be waste of CPU time. I am in the process of making these things fully automatic. This is followed here: [O2-3622](https://its.cern.ch/jira/browse/O2-3622). \nIf there is no `workflow.json` produced, this probably means that the pre-processing failed. In your case there is an error in file `timestampsampling...log` indicating a typo in simulation options: It is `--embeddPattern` and not `--embedPattern` (But you can omit this option alltogether in your case). Having said that, I'd like to raise awareness that embedding workflows have not been fully production-validated when used in the anchorMC script (or it needs improvement). It should work, if you specify the right amount of background events yourself (which you do). Be careful to choose the event number so that it matches the timeframe length and interaction rate. A timeframe length of 32 orbits at 10kHz should have less than `~(0.09ms/orbit * 32orbits) * 10**-3 * 10000 1/s` ~ 32 background events. If you specify more, there will be waste of CPU time. I am in the process of making these things fully automatic. This is followed here: [O2-3622](https://its.cern.ch/jira/browse/O2-3622). ",
        "question": "If there is no `workflow.json` produced, what does this indicate, and how should I proceed with the simulation options and background events?"
    },
    {
        "source": "mattermost",
        "post_id": "b85oh7ecnj81iek1z58diy7joo",
        "create_at": 1719556997310,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Dear experts,\n\nI have generated MC using the powheg+pythia8 package. I have mu+ and mu- pairs from the powheg as input into pythia8 during shower. These muon pairs must be considered as primaries. I would like to separate these muons coming from powheg from the muons from pythia8.\nAs suggested by @swenzel , one could use the Generator status code for these particles. But, we do not know whether the powheg particles are tagged with specific generator status codes?\nLet me know if anyone knows this fact.\nThanks.",
        "question": "Do POWHEG-generated particles have specific generator status codes that can be used to distinguish them from PYTHIA8-generated particles?"
    },
    {
        "source": "mattermost",
        "post_id": "3et4z6yq9ty5tq8wgbad9hffkr",
        "create_at": 1719908559826,
        "user_id": "ojamyqznoidf8yen67drwoxnsy",
        "message": "Dear experts, I am running some simulation for the HF group on the grid. Even though among the log file there are all the correct files, AO2D included (https://alimonitor.cern.ch/jobs/output.jsp?pid=3111504506&id=3111504507), the output directory remains empty (https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fs%2Fspolitan%2Fselfjobs%2Ftest_anchor_NoPregenFromScript3_newtag-20240701-190454#/alice/cern.ch/user/s/spolitan/selfjobs/test_anchor_NoPregenFromScript3_newtag-20240701-190454/output). Do you have any idea why is this happening? Thanks a lot in advance for your support! ",
        "question": "Why is the output directory empty even though the log files indicate that all the correct files, including AO2D, were processed?"
    },
    {
        "source": "mattermost",
        "post_id": "nrqm9nifj38p3xskenuoha53xw",
        "create_at": 1720181277356,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Just out of curiosity, I can see in my small productions that the reconstruction efficiency, for example, let's say that for exclusive Jpsi->pp events, with close to 22k events injected, only 3 events are reconstructed (using pp settings instead of PbPb due to filling schemes limitations), while in Run 2 the efficiency was at the level of 5% about? I was wondering could be the reason for such a difference... The production was carried out using the fix above `--run` for `anchorMC.sh`.\nSince anyway, I have only about 100 such Jpsis in my UPC datasets, I guess I could in principle submit about 40 jobs...\nBut I would not be able to use this AxE to measure a cross section",
        "question": "What could be the reason for the low reconstruction efficiency of Jpsi->pp events in my small production compared to Run 2?"
    },
    {
        "source": "mattermost",
        "post_id": "u5jkuo94s3bozj5j418tqehx1r",
        "create_at": 1720368810146,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Hi, I am trying to run the QED background simulations using the QEDLoader.C\nThis is the command that I am using:\n```\no2-sim -e TGeant4 -m PIPE ITS MFT FT0 FV0 FDD -n 10 -g external --configKeyValues \"GeneratorExternal.fileName=$path_to_o2/O2/Generators/share/external/QEDLoader.C ; Diamond.width[2]=6.\"\n```\nIt is crashing again and again, but I do not understand why. Am I doing something wrong?\nThis is the output:\n```\n[INFO] This is o2-sim version 1.2.0 (bdb541f5d2)\n[INFO] Built by ALIBUILD:1.17.7+jammy, ALIDIST-REV:94acc9094f464f7bdb11c946f1d3a6dae5039b79 on OS:Linux-6.5.0-41-generic\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-36848 type pub\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with 4 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 4 WORKERS\nSpawning particle server on PID 36851; Redirect output to o2sim_serverlog\nSpawning sim worker 0 on PID 37079; Redirect output to o2sim_workerlog0\nSpawning hit merger on PID 37080; Redirect output to o2sim_mergerlog\n[INFO] Process 37079 EXITED WITH CODE 1 SIGNALED 0 SIGNAL 0\n[INFO] Problem detected (or child received termination signal) ... shutting down whole system \n[INFO] TERMINATING 36851\n[INFO] TERMINATING 37079\n[INFO] TERMINATING 37080\n[ERROR] SHUTTING DOWN DUE TO SIGNALED EXIT IN COMPONENT 37079\n[INFO] Merger process 37080 returned\n[INFO] Simulation process took 86.2011 s\n\n```",
        "question": "Why is the QED background simulation crashing and how can I fix it?"
    },
    {
        "source": "mattermost",
        "post_id": "dz5mis89k3rn8nxi3nsh8rugah",
        "create_at": 1720389656794,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "This is from the o2sim_workerlog0:\n```\n[18:09:00][INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-worker-notifications-36848 type pub\n[18:09:00][INFO] Parsed primary server address ipc:///tmp/o2sim-primary-get-36848\n[18:09:00][INFO] Parsed primary server status address ipc:///tmp/o2sim-primserv-info-36848\n[18:09:00][INFO] Parsed merger address ipc:///tmp/o2sim-hitmerger-simdata-36848\n[18:09:00][INFO] Waiting for configuration answer \n[18:10:00][ERROR] No configuration received within 60000ms\n\n[18:10:01][ERROR] Could not initialize simulation\n```",
        "question": "What is the reason for the failure to initialize the simulation, as indicated by the error messages?"
    },
    {
        "source": "mattermost",
        "post_id": "zdwrpfq9s78e5r16ksz8p8io3w",
        "create_at": 1720421738212,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Nothing interesting here. What about `o2sim_serverlog`?",
        "question": "What about `o2sim_serverlog`?"
    },
    {
        "source": "mattermost",
        "post_id": "91qy49m4pfyxdn6or9n8ui1eue",
        "create_at": 1720432694169,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Yes, so I found this crash in o2sim_serverlog:\n```\n// Copyright 2019-2020 CERN and copyright holders of ALICE O2.\n// See https://alice-o2.web.cern.ch/copyright for details of the copyright holders.\n// All rights not expressly granted are reserved.\n//\n// This software is distributed under the terms of the GNU General Public\n// License v3 (GPL Version 3), copied verbatim in the file \"COPYING\".\n//\n// In applying this license CERN does not waive the privileges and immunities\n// granted to it by virtue of its status as an Intergovernmental Organization\n// or submit itself to any jurisdiction.\n\n/// \\author A+Morsch\n\n#include <string>\n#ifndef ALICEO2_SIMCONFIG_MATMAPPARAMS_H_\n#define ALICEO2_SIMCONFIG_MATMAPPARAMS_H_\n\n#include \"CommonUtils/ConfigurableParam.h\"\n#include \"CommonUtils/ConfigurableParamHelper.h\"\n\nnamespace o2\n{\nnamespace conf\n{\n/**\n ** A parameter class/struct holding values for\n ** material budget maps\n **/\nstruct MatMapParams : public o2::conf::ConfigurableParamHelper<MatMapParams> {\n  int nphi = 360;\n  float phimin = 0;\n  float phimax = 360.;\n  int ntheta = 0;\n  float thetamin = -45.;\n  float thetamax = 45.;\n  int neta = 0;\n  float etamin = -2.;\n  float etamax = 2.;\n  int nzv = 0;\n  float zvmin = -50.;\n  float zvmax = 50.;\n  float rmin = 0.;\n  float rmax = 290.;\n  float zmax = 2000;\n  O2ParamDef(MatMapParams, \"matm\");\n};\n} // namespace conf\n} // namespace o2\n#endif // ALICEO2_SIMCONFIG_MATMAPPARAMS_H_\n\n#undef  _BACKWARD_BACKWARD_WARNING_H\n\nIn file included from input_line_145:1:\n/home/x1/alice/O2/Generators/share/external/QEDepem.C:20:33: error: incomplete type 'o2::eventgen::InteractionDiamondParam' named in nested name specifier\n  auto& diamond = o2::eventgen::InteractionDiamondParam::Instance();\n                  ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\nG__O2SimConfig dictionary forward declarations' payload:12:40: note: forward declaration of 'o2::eventgen::InteractionDiamondParam'\nnamespace o2{namespace eventgen{struct InteractionDiamondParam;}}\n                                       ^\nIn file included from input_line_145:1:\n/home/x1/alice/O2/Generators/share/external/QEDepem.C:30:3: error: unknown type name 'TGenEpEmv1'\n  TGenEpEmv1* genBg = nullptr;\n  ^\n/home/x1/alice/O2/Generators/share/external/QEDepem.C:33:17: error: unknown type name 'TGenEpEmv1'\n    genBg = new TGenEpEmv1();\n                ^\nG__O2MathUtils dictionary payload:1210:5: error: no matching function for call to 'format'\n    LOGP(warning, \"bad fit\");\n    ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/x1/alice/sw/ubuntu2204_x86-64/FairLogger/v1.11.1-14/include/fairlogger/Logger.h:403:14: note: expanded from macro 'LOGP'\n#define LOGP FAIR_LOGP\n             ^\n/home/x1/alice/sw/ubuntu2204_x86-64/FairLogger/v1.11.1-14/include/fairlogger/Logger.h:434:51: note: expanded from macro 'FAIR_LOGP'\n#define FAIR_LOGP(severity, ...) LOG(severity) << fmt::format(__VA_ARGS__)\n                                                  ^~~~~~~~~~~\n/home/x1/alice/sw/ubuntu2204_x86-64/fmt/10.1.1-10/include/fmt/core.h:2786:31: note: candidate function [with T = <>] not viable: no known conversion from 'const char [8]' to 'format_string<>' (aka 'basic_format_string<char>') for 1st argument\nFMT_NODISCARD FMT_INLINE auto format(format_string<T...> fmt, T&&... args)\n                              ^\n/home/x1/alice/sw/ubuntu2204_x86-64/fmt/10.1.1-10/include/fmt/format.h:4444:13: note: candidate function template not viable: requires at least 2 arguments, but 1 was provided\ninline auto format(const Locale& loc, format_string<T...> fmt, T&&... args)\n            ^\nG__O2MathUtils dictionary payload:2042:7: error: type alias redefinition with different types ('Rotation2D<...>' vs 'Rotation2D<...>')\nusing Rotation2Df_t = Rotation2D<float>;\n      ^\nG__O2MathUtils dictionary forward declarations' payload:19:41: note: previous definition is here\nnamespace o2{namespace math_utils{using Rotation2Df_t = Rotation2D<float>;}}\n                                        ^\nG__O2MathUtils dictionary payload:2043:7: error: type alias redefinition with different types ('Rotation2D<...>' vs 'Rotation2D<...>')\nusing Rotation2Dd_t = Rotation2D<double>;\n      ^\nG__O2MathUtils dictionary forward declarations' payload:20:41: note: previous definition is here\nnamespace o2{namespace math_utils{using Rotation2Dd_t = Rotation2D<double>;}}\n                                        ^\n\n *** Break *** segmentation violation\n\n\n\n===========================================================\nThere was a crash.\nThis is the entire stack trace of all threads:\n===========================================================\n\n```\nthis crash seems to be from the QEDepem.C",
        "question": "What is the cause of the crash in QEDepem.C and how can it be resolved?"
    },
    {
        "source": "mattermost",
        "post_id": "pa9c3ctij3ynbqwbnxd7mywh3w",
        "create_at": 1720805574596,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nnow that pp anchoring is working well for jets, I'm looking at trying to run a simulation of pp anchored to Pb-Pb, using the documentation [here](https://aliceo2group.github.io/simulation/docs/o2dpgworkflow/anchored.html#run-pythia-with-a-different-collision-system).\nI just launched a simulation earlier this week, with NSIGEVENTS=500 and NTIMEFRAMES=10. I had a look at the result, and I'm seeing a few issues:\n- from the 5000 events I was expecting, I am only seeing a single timeframe with 583 mcEvents\n- from those 583 mc events, only 3 are reconstructed in the collision table\n- I attach the script I ran to this message. Is there something I am doing wrong?",
        "question": "What could be the reason for only seeing one timeframe with 583 mcEvents out of 5000 expected events and only 3 reconstructed events in the collision table?"
    },
    {
        "source": "mattermost",
        "post_id": "r7p3adyhy3fj7nd3afwd4n1ath",
        "create_at": 1721200387581,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, I have created a pull request for a jet-jet MC configuration in o2DPG - [AliceO2Group/O2DPG#1704](https://github.com/AliceO2Group/O2DPG/pull/1704) - I saw that a tag is needed to be included in asynchronous version, and the tag available for 2022 pp data is 'async-2022-pp-apass7' . Does this mean that anchoring to pass6 data is no longer supported?",
        "question": "Does anchoring to pass6 data support still exist or has it been replaced by 'async-2022-pp-apass7'?"
    },
    {
        "source": "mattermost",
        "post_id": "53zgyhderif99dn85a7jsucg9c",
        "create_at": 1721209182335,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Hi Simone\ndo you mean you have the issue in any simulation? or like me, anchored ones only?",
        "question": "Do you have the issue in any simulation or only in anchored ones?"
    },
    {
        "source": "mattermost",
        "post_id": "hskot1hy57yi5crsmhkhxt8mth",
        "create_at": 1721288657766,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, I want to run some events on the grid using a new simulation configuration ( [AliceO2Group/O2DPG#1704](https://github.com/AliceO2Group/O2DPG/pull/1704) ) . Is there a way to run tests (and maybe change some configuration parameters) with custom configurations, without having to have them pushed to the O2DPG repository?",
        "question": "Is there a way to run tests with custom simulation configurations without pushing them to the O2DPG repository?"
    },
    {
        "source": "mattermost",
        "post_id": "p69j4w9fr3ncmxwny8mkjmb4br",
        "create_at": 1721298134393,
        "user_id": "ucw6b4xzb38ttegxfbobupjujr",
        "message": "Dear experts, \nI have just started to run some MC simulation tests on my LXplus home directory, but they haven't succeeded so far. Is the GRID certificate already activated in LXplus? I am now trying to activate a certificate with the same procedure as on a PC, but it didn't work\nThis was the printout after the failed MC test run:\n```\n[INFO] This is o2-sim version 1.2.0 (99756dc7)\n[INFO] Built by ALIBUILD:1.17.7, ALIDIST-REV:ab578c1e6dbceb7a6c5739643c7a7522dd924607 on OS:Linux-5.14.0-362.24.2.el9_3.x86_64\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-2129881 type pub\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with 2 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 2 WORKERS\nSpawning particle server on PID 2129984; Redirect output to o2sim_serverlog\nSpawning sim worker 0 on PID 2130109; Redirect output to o2sim_workerlog0\nSpawning hit merger on PID 2130110; Redirect output to o2sim_mergerlog\n[INFO] Process 2130109 EXITED WITH CODE 134 SIGNALED 0 SIGNAL 0\n[INFO] Problem detected (or child received termination signal) ... shutting down whole system \n[INFO] TERMINATING 2129984\n[INFO] TERMINATING 2130109\n[INFO] TERMINATING 2130110\n[ERROR] SHUTTING DOWN DUE TO SIGNALED EXIT IN COMPONENT 2130109\n[INFO] Merger process 2130110 returned\n[INFO] Simulation process took 59.7318 s\n```\nThe run command was:\n```o2-sim -e TGeant4 -g pythia8pp -n 10 -j 2```",
        "question": "What could be the reason for the MC simulation test run failing with the error code 134 and how can I activate the GRID certificate on LXplus?"
    },
    {
        "source": "mattermost",
        "post_id": "73po4ojx1jd1pmsuihmt4gkemy",
        "create_at": 1722416768389,
        "user_id": "8gj5de5ehjgmpkrab47ts3saoe",
        "message": "Hi all,\n\nOur institute upgraded to a new server and such I had to install O2 again.\nI am not sure I did it correctly. When I try to do a test simulation, I get this error\n\n```\n[O2/latest-dev-o2] /misc/alidata150/alice_u/cas/O2Simulation/fct_jobs/fctTest $> o2-sim-run5 -m FCT -e TGeant4 -g pythia8pp -n 10 -j 24\n[INFO] This is o2-sim version 1.2.0 (193f7aa3f2)\n[INFO] Built by ALIBUILD:1.17.7, ALIDIST-REV:ec376ea3191d5c71bfc09b9ad6ea81285b45218b on OS:Linux-5.15.0-116-generic\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-1527777 type pub\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\n[ERROR] Modules specified that are not present in detector list ALICE2\n[INFO]  - 0 . FCT\n[ERROR] List of available modules for version ALICE2:\n[ERROR] \t*  0.\tITS\n[ERROR] \t*  1.\tTPC\n[ERROR] \t*  2.\tTRD\n[ERROR] \t*  3.\tTOF\n[ERROR] \t*  4.\tPHS\n[ERROR] \t*  5.\tCPV\n[ERROR] \t*  6.\tEMC\n[ERROR] \t*  7.\tHMP\n[ERROR] \t*  8.\tMFT\n[ERROR] \t*  9.\tMCH\n[ERROR] \t* 10.\tMID\n[ERROR] \t* 11.\tZDC\n[ERROR] \t* 12.\tFT0\n[ERROR] \t* 13.\tFV0\n[ERROR] \t* 14.\tFDD\n[ERROR] \t* 15.\tCTP\n[ERROR] \t* 16.\tHALL\n[ERROR] \t* 17.\tMAG\n[ERROR] \t* 18.\tDIPO\n[ERROR] \t* 19.\tCOMP\n[ERROR] \t* 20.\tPIPE\n[ERROR] \t* 21.\tABSO\n[ERROR] \t* 22.\tSHIL\n```\n\nIt seems that it could not find the upgrade detectors of ALICE 3.\n\nI built with \n```\nENABLE_UPGRADES=ON aliBuild build O2 --defaults o2 -j 24\n```\n\nand initialized alibuild with\n```\naliBuild init O2@dev\n```\n\nDoes anyone know what is going on and how I can fix this?\nNever mind, it seems I found the problem",
        "question": "What is the issue with the FCT module not being found in the ALICE2 detector version, and how can it be fixed?"
    },
    {
        "source": "mattermost",
        "post_id": "tmz954nxabykdrzc5y5s3mp83c",
        "create_at": 1722428005011,
        "user_id": "1kdp9jemajgauyc6a1geigoome",
        "message": "Dear experts, I am running a test for an anchored simulation with private jobs. The jobs is completed successfully (see https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/f/fgrosa/selfjobs/test_anchor_TestDebug_EmbedPatt1_5ev_4tf-20240731-111630/001/logtmp_3126560560.txt) but only the `logtmp` file is saved and not the AO2D, even if it was specified in the JDL: https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/f/fgrosa/selfjobs/test_anchor_TestDebug_EmbedPatt1_5ev_4tf-20240731-111630/test_anchor_TestDebug_EmbedPatt1_5ev_4tf-20240731-111630.jdl \nDo you know what could cause it and a way to solve it? Thanks!",
        "question": "What could cause the AO2D not to be saved even though it was specified in the JDL, and how can it be solved?"
    },
    {
        "source": "mattermost",
        "post_id": "xsno54orjbrijpda8iuskg8y9w",
        "create_at": 1722428090218,
        "user_id": "8gj5de5ehjgmpkrab47ts3saoe",
        "message": "I said in my previous message I found the problem. I did not. If anyone could help, that would be greatly appreciated",
        "question": "I still can't find the problem with the ALICE O2 simulations. Can anyone help?"
    },
    {
        "source": "mattermost",
        "post_id": "7y7ahttac7yh7ja1ecti9hogya",
        "create_at": 1722429858576,
        "user_id": "8gj5de5ehjgmpkrab47ts3saoe",
        "message": "That clears up a lot of confusion.\nI now ran with\n```\no2-sim --detectorList ALICE3 -m FCT -e TGeant4 -g pythia8pp -n 10 -j 24\n```\nIn the terminal it says \n```\n[INFO] This is o2-sim version 1.2.0 (1e78fb8d61)\n[INFO] Built by ALIBUILD:1.17.10, ALIDIST-REV:bc5f5a46049071028e71b61f91e146ff946070a2 on OS:Linux-5.15.0-116-generic\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-1897184 type pub\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE3'\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE3'\n[INFO] Running with 24 sim workers \n[INFO] CREATING SIM SHARED MEM SEGMENT FOR 24 WORKERS\nSpawning particle server on PID 1897336; Redirect output to o2sim_serverlog\nSpawning sim worker 0 on PID 1897514; Redirect output to o2sim_workerlog0\nSpawning hit merger on PID 1897515; Redirect output to o2sim_mergerlog\n[INFO] DISTRIBUTING EVENT : 1\n[INFO] DISTRIBUTING EVENT : 2\n[INFO] DISTRIBUTING EVENT : 3\n[INFO] DISTRIBUTING EVENT : 4\n[INFO] DISTRIBUTING EVENT : 5\n[INFO] DISTRIBUTING EVENT : 6\n[INFO] DISTRIBUTING EVENT : 7\n[INFO] DISTRIBUTING EVENT : 8\n[INFO] DISTRIBUTING EVENT : 9\n[INFO] DISTRIBUTING EVENT : 10\n[INFO] EVENT FINISHED : 10\n[INFO] EVENT FINISHED : 2\n[INFO] EVENT FINISHED : 8\n[INFO] EVENT FINISHED : 3\n[INFO] EVENT FINISHED : 1\n[INFO] EVENT FINISHED : 6\n[INFO] EVENT FINISHED : 4\n[INFO] EVENT FINISHED : 9\n[INFO] EVENT FINISHED : 5\n[INFO] SIMULATION IS DONE. INITIATING SHUTDOWN.\n[INFO] EVENT FINISHED : 7\n[INFO] Merger process 1897515 returned\n[INFO] Simulation process took 46.4407 s\n[INFO] SIMULATION RETURNED SUCCESFULLY\n[O2/latest-dev-o2] /misc/alidata150/alice_u/cas/O2Simulation/fct_jobs/fctTest $> ls\nFCT_layout.cfg\t\to2sim_configuration.ini      o2sim_grpMagField.root  o2sim_mergerlog\nMCStepLoggerSenVol.dat\to2sim_geometry-aligned.root  o2sim_grp.root\t     o2sim_proc-cut.dat\nMCStepLoggerVolMap.dat\to2sim_geometry.root\t     o2sim_HitsFCT.root      o2sim_serverlog\no2sim_1897514_par.root\to2sim_grpecs.root\t     o2sim_Kine.root\t     o2simtopology_1897184.json\no2sim_1897514.root\to2sim_grplhcif.root\t     o2sim_MCHeader.root     o2sim_workerlog0\n```\n\nOnly the FCT seems to be active, just like I want. But the output still says \n```\n[INFO] Running with official detector version 'ALICE2'\n```\nIs that just an output bug?",
        "question": "Is the output saying \"Running with official detector version 'ALICE2'\" just a bug?"
    },
    {
        "source": "mattermost",
        "post_id": "3fjf5r8rrb83ujfeacbsigfjar",
        "create_at": 1722430235846,
        "user_id": "8gj5de5ehjgmpkrab47ts3saoe",
        "message": "The \"-m\" flag to specify which modules to load still works as before then?",
        "question": "Does the \"-m\" flag to specify which modules to load still work as before?"
    },
    {
        "source": "mattermost",
        "post_id": "iawkkfuo1fykdrzqd7h4t954fw",
        "create_at": 1722951803611,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi @swenzel , @pbuhler @mbroz and I wanted to ask you on behalf of the PWGUD if there were standard values of the following parameters: \n```c++\n# the following are example values\nexport NTIMEFRAMES=2\nexport NSIGEVENTS=50\nexport SPLITID=100\nexport PRODSPLIT=153\nexport CYCLE=0\n``` \nto ensure a very good reconstruction efficiency, or if these are automatically set by the system if unset\nSeparate thread instead for EMCAL, if the PR for the interaction rate can be merged so that I can run my tests...",
        "question": "Are there standard values for the parameters NTIMEFRAMES, NSIGEVENTS, SPLITID, PRODSPLIT, and CYCLE to ensure good reconstruction efficiency, or are these parameters automatically set by the system if not specified?"
    },
    {
        "source": "mattermost",
        "post_id": "8z6kp7yaciye3rtrhpdbup67ny",
        "create_at": 1722952421931,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "The numbers for `NTIMEFRAMES` and `NSIGEVENTS` need to specified by the user. They really select the amount of statistics per MC job. Most important is NTIMEFRAMES as the number of timeframes to be simulated. `NSIGEVENTS` means \"the maximum number of events to be put into the timeframe\". The actual number can be smaller if NSIGEVENTS would not fit into the timeframe given an interaction rate.\nNTIMEFRAMES is typically on the order of 10-20. Larger numbers may be stressful for the compute engine.\n`PRODSPLIT` is a number that specifies the total number of parallel MC jobs that run in an anchored MC production. `SPLITID` < PRODSPLITS assigns an ID to a job within a production. `SPLITID` + `PRODSPLIT` + `CYCLE` determine the timestamp during a run ... at which this MC job anchors (see here https://aliceo2group.github.io/simulation/docs/o2dpgworkflow/anchored.html). A real production would launch exactly `PRODSPLIT` parallel jobs ... and individual jobs would have `SPLITIDS` ranging from 0 to `PRODSPLIT-1`. So to have statistics across a whole run ... one would need to submit multiple MC jobs and have each of them use a different SPLITID.",
        "question": "What is the purpose of specifying `NTIMEFRAMES` and `NSIGEVENTS`, and how do they affect the simulation?"
    },
    {
        "source": "mattermost",
        "post_id": "ia55wot8fpb69nau9e3isg14ac",
        "create_at": 1722954010561,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Thanks a lot for both this and the merge! Yes, we are all following this documentation. If you would let me rephrase the question, would you expect large changes in reconstruction efficiencies by changing these parameters? Or it should be somewhat stable regardless of them?",
        "question": "Would you expect large changes in reconstruction efficiencies by changing these parameters, or should it be somewhat stable regardless of them?"
    },
    {
        "source": "mattermost",
        "post_id": "dt8mh3477t85zxuizbwqyn1bbr",
        "create_at": 1723555529403,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "If I want to know how many resources a simulation test spends, what log file should I look at?",
        "question": "What log file should I look at to know how many resources a simulation test spends?"
    },
    {
        "source": "mattermost",
        "post_id": "1oymjencxp8a9bkr86ehkw4twe",
        "create_at": 1723640865371,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "is there line that shows the total cpu and memory used? or should I add them myself?",
        "question": "is there a line that shows the total CPU and memory used, or should I add them myself?"
    },
    {
        "source": "mattermost",
        "post_id": "15nkpu74sbyppp3tj4ch69kb8a",
        "create_at": 1723649203794,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Hi @alandou : Could you be slightly more specific? What are you after here exactly and **why**?  (Do you need CPU efficiency? overall CPU time? overall walltime? mean memory used? max memory used?). The total runtime of the jobs are already printed by the pipeline runner. Everything else can be calculated from the `pipeline_metrics` files.",
        "question": "What specific metrics are you looking for regarding the ALICE O2 simulations, and why do you need them?"
    },
    {
        "source": "mattermost",
        "post_id": "crbqo3zbnp888pku5jpj6s1tbw",
        "create_at": 1723821890565,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "Hi @swenzel, many thanks! One question: why my local test produces 3 different pipeline_metric files? ",
        "question": "Why does my local test produce 3 different pipeline_metric files?"
    },
    {
        "source": "mattermost",
        "post_id": "67sat58hxjbmzn8zmctfrj6aaw",
        "create_at": 1723990791093,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "This is because anchorMC performs 3 different workflows. You can do a grep \n```\ngrep \"runner.py\" anchorMC.sh` ... one can see what the 3 stages are doing:\n\n`${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt ${ALIEN_JDL_O2DPGWORKFLOWTARGET:-aod} --cpu-limit ${ALIEN_JDL_CPULIMIT:-8} --dynamic-resources ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -tt tpctimes ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --target-labels QC --cpu-limit ${ALIEN_JDL_CPULIMIT:-8} -k`\n\nThe first one creates AOD, which I believe is the important one. The other 2 are some special things for TPC time-series and QC tasks.\n```",
        "question": "What are the three stages of the workflow performed by anchorMC and what is the purpose of each stage?"
    },
    {
        "source": "mattermost",
        "post_id": "36fyoadsrirhdmqbgxnzpkw44y",
        "create_at": 1724054201226,
        "user_id": "ffcgsbfzijfsbj1p14w6w7nz9e",
        "message": "Dear experts,\n\nI am using following script to produce injected L* with gap with embedding. But, I find the reconstruction rate of the produced collisions is very less around 4 out of 50. How could I increase the reconstruction efficiency? ",
        "question": "How could I increase the reconstruction efficiency when producing injected L* with gap with embedding?"
    },
    {
        "source": "mattermost",
        "post_id": "mg41m1qpjp89uxm8io4hxhozer",
        "create_at": 1724060216504,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "What is the software tag used? Did you try with latest O2 on CVFMS?",
        "question": "What is the software tag used, and did you try with the latest O2 on CVFMS?"
    },
    {
        "source": "mattermost",
        "post_id": "1uxp6drbdiyez8nyoppk9gx8qc",
        "create_at": 1724146951257,
        "user_id": "9wmacn4dwjyr7j56du7q3zh6ah",
        "message": "Dear Experts, I am currently trying to run sim workflows with pythia8powheg with a custom config to include my own powheg.lhe input. I have run this both locally and on lxplus and have noticed that it always seems to include the default config file, no matter how I pass my own. Currently I just pass it as `-confKey \"GeneratorPythia8.config=/my_conf_path/pythia8_powheg.cfg\"`. When I look in the genevents_serverlog it does seem like it finds my config and sets GeneratorPythia8.config correctly, but then loads pythia with the default config. I have also ran a pythiahf sim with a default config in the same way and experienced the same issue - in this case the sim workflow successfully finishes with the default config. I am not sure where I am going wrong, any feedback is appreciated.",
        "question": "Why is the simulation always including the default config file instead of the one specified via the `-confKey` parameter, even though the log indicates that it finds and sets the correct configuration path?"
    },
    {
        "source": "mattermost",
        "post_id": "s6jixrr5dprbfgj8g74sk4r1so",
        "create_at": 1724223611279,
        "user_id": "eiexotkj4tr5byhopwtwkopkyr",
        "message": "Hello, in the job_script I have following setup (that works) there are two types of quotation marks:\n`export ALIEN_JDL_ANCHOR_SIM_OPTIONS='-gen pythia8 -proc \"jets\" -ptHatMin 5 -ptHatMax 600 -mod \"--skipModules ZDC\" -weightPow 4 -ini \"\\$O2DPG_ROOT/MC/config/PWGGAJE/ini/hook_jets.ini\"'`\nI need to write it directly to the JDL as `ANCHOR_SIM_OPTIONS`, how should I write the quotations? Apparently this doesn't work: \n`ANCHOR_SIM_OPTIONS = '-gen pythia8 -proc \"jets\" -ptHatMin 5 -ptHatMax 600 -mod \"--skipModules ZDC\" -weightPow 4 -ini \"/cvmfs/alice.cern.ch/el9-x86_64/Packages/O2DPG/async-v1-01-02b-1/MC/config/PWGGAJE/ini/hook_jets.ini\"';`\nNeither this:\n`ANCHOR_SIM_OPTIONS = \"-gen pythia8 -proc jets -ptHatMin 5 -ptHatMax 600 -weightPow 4 -ini /cvmfs/alice.cern.ch/el9-x86_64/Packages/O2DPG/async-v1-01-02b-1/MC/config/PWGGAJE/ini/hook_jets.ini\"; ` \nThe problem is with the process name that is somehow not recognized.",
        "question": "How should I write the `ANCHOR_SIM_OPTIONS` directly in the JDL to include the process name and other options with the correct quotation marks so that the process name is recognized?"
    },
    {
        "source": "mattermost",
        "post_id": "mwae7ma3zprk7r8wswn7o7auco",
        "create_at": 1724397837053,
        "user_id": "m7gcuh797jdhtjznffpdranw6a",
        "message": "Dear expert,\nWhile doing aliBuild build EVTGEN, I got the build error. I attached the error log. This error may be reported on the following page. Is the problem solved now? If this problem has been solved, please tell me how to fix it. Thanks.\n\nhttps://alice-talk.web.cern.ch/t/o2-dpg-evtgen/1202",
        "question": "What is the build error encountered while doing aliBuild build EVTGEN and how can it be fixed?"
    },
    {
        "source": "mattermost",
        "post_id": "ia1fd65hg3gmpqfeajqmcgofno",
        "create_at": 1725532071524,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi everyone (I guess especially @swenzel ). With everyone from UPC (@mbroz @amatyja ) we have in fact observed some effects both from user and centrally submitted jobs. Basically, if we inject events from hepMC files almost nothing is reconstructed (I was in fact reporting unusually low efficiencies here some time back, but now we can maybe point in a determinate direction). Whereas direct injection of STARlight events through an interface seems to work (fine? the efficiency will have to be checked of course). If we inject hepMC events of STARlight+DPMJET, where we have larger-ish multiplicities at forward rapidities then a lot of events are reconstructed. The situation is reported here: https://indico.cern.ch/event/1444319/ . These observations led me to postulate that maybe there's also something wrong with the TVX triggers in simulations. This also led to another hypothesis in the group that in simulations there is also usually the simulation of soft electron-positron pairs on top of the injected events. This could justify a small FIT signal in my opinion, which could solve the issue. If this is still current, then maybe there is a bug in the software that with hepMC files this additional simulation is not run... But it would be nice if there were documentation about which processes are simulated that end up in being a \"single\" event in a simulation, so that we can check our steps too... Thanks in advance!!!!!\nThere is a JIRA ticket for these central productions: [O2-5292](https://its.cern.ch/jira/browse/O2-5292)",
        "question": "What might be causing the low event reconstruction efficiency when injecting hepMC files, and could there be a bug in the software related to this issue?"
    },
    {
        "source": "mattermost",
        "post_id": "bx6nzw6a83ddpc8uasy84shygh",
        "create_at": 1725871757676,
        "user_id": "irbenxbcdf8bzbm4kh18cijr7w",
        "message": "Hi @swenzel, Is the workflow with QED background included by default in standalone user tests (for all HepMC simulations) or only in the central framework?  ",
        "question": "Is the workflow with QED background included by default in standalone user tests (for all HepMC simulations) or only in the central framework?"
    },
    {
        "source": "mattermost",
        "post_id": "m9bbz7rnytdkjxn7zt149mftqc",
        "create_at": 1725891010002,
        "user_id": "bznhtse8pprufp5eogr84qhmxa",
        "message": "Dear experts, I would like to work on AEGIS. I did `aliBuild init AEGIS`. This command gave me:\n```\nGit fetch for repository for AEGIS...\nDone git fetch for repository for AEGIS\nTraceback (most recent call last):\n  File \"/usr/bin/aliBuild\", line 133, in <module>\n    doMain(args, parser)\n  File \"/usr/bin/aliBuild\", line 80, in doMain\n    doInit(args)\n  File \"/usr/lib/python3.6/site-packages/alibuild_helpers/init.py\", line 87, in doInit\n    git(cmd)\n  File \"/usr/lib/python3.6/site-packages/alibuild_helpers/git.py\", line 68, in git\n    raise RuntimeError(\"Error {} from git {}: {}\".format(err, \" \".join(args), output))\nRuntimeError: Error 128 from git clone --origin upstream https://github.com/AliceO2Group/AEGIS.git --reference /home/dsekihat/alice/sw/MIRROR/aegis -b v1.5.3-alice2 ./AEGIS: Cloning into './AEGIS'...\n```\nHow can I install AEGIS?",
        "question": "How can I install AEGIS?"
    },
    {
        "source": "mattermost",
        "post_id": "rtq5miawejgidr4htjc5d3ut1w",
        "create_at": 1725897881852,
        "user_id": "bznhtse8pprufp5eogr84qhmxa",
        "message": "Hello @slokos , Thank you. It works for me. But, even if AEGIS is compiled by `aliBuild build AEGIS`, how can I modify source codes in AEGIS? I am sorry for my ignorance.",
        "question": "How can I modify source codes in AEGIS if it is compiled by `aliBuild build AEGIS`?"
    },
    {
        "source": "mattermost",
        "post_id": "pyfsz6mocjyzdcw3apty6kbr7y",
        "create_at": 1725898358346,
        "user_id": "bznhtse8pprufp5eogr84qhmxa",
        "message": "Dear experts, I am sorry to disturb you. Where and how can I modify source codes of AEGIS after `aliBuild build AEGIS`? Thank you.",
        "question": "Where and how can I modify source codes of AEGIS after `aliBuild build AEGIS`?"
    },
    {
        "source": "mattermost",
        "post_id": "z8stmnb1g3dqjnsner3who76cc",
        "create_at": 1725959174209,
        "user_id": "349mzxje5pbz9fes49wk6cz9xc",
        "message": "Dear Experts, I'd like to run UPC analysis on MC data. The script crashes after it reads the metadata from the AO2D file with `Error 65543: GLX: Failed to create context: GLXBadFBConfig`\n\nThis is what I do:\n```\nOPTION=\"--configuration json://configurationSG.json\"\n\no2-analysis-track-propagation ${OPTION} |\\\no2-analysis-timestamp ${OPTION} |\\\no2-analysis-pid-tof-full ${OPTION} |\\\no2-analysis-pid-tof-beta ${OPTION} |\\\no2-analysis-pid-tof-base ${OPTION} |\\\no2-analysis-pid-tpc ${OPTION} |\\\no2-analysis-pid-tpc-base ${OPTION} |\\\no2-analysis-ft0-corrected-table ${OPTION} |\\\no2-analysis-event-selection ${OPTION} |\\\no2-analysis-trackselection ${OPTION} |\\\no2-analysis-mccollision-converter ${OPTION} |\\\no2-analysis-multiplicity-table ${OPTION} |\\\no2-analysis-ud-dgcand-producer ${OPTION} --aod-writer-json OutputDirectorSGMC.json --aod-file AO2D.root\n```\n\nAny idea would help, thanks! ",
        "question": "What is the cause of the `Error 65543: GLX: Failed to create context: GLXBadFBConfig` when running the UPC analysis script on MC data?"
    },
    {
        "source": "mattermost",
        "post_id": "jxb3iy69pffwfm41yh951qtruh",
        "create_at": 1727030238384,
        "user_id": "z3tj8hbhxib68rioh8xzijd6mo",
        "message": "Hello, I am do a simulation using option --skipModules in order to remove certain passive parts. The geometry file looks good, but the simiulation results look like those removed parts are still present. ",
        "question": "Why do the simulation results still show the removed parts even though I used the --skipModules option to remove certain passive parts?"
    },
    {
        "source": "mattermost",
        "post_id": "tzxaeuayg3dcffwjj6569cyrde",
        "create_at": 1727181611265,
        "user_id": "9wmacn4dwjyr7j56du7q3zh6ah",
        "message": "Dear experts, I am attempting to run my workflow as a grid job to test with more events. I have run it on lxplus for 5 events, which worked fine. For my workflow I pass my own custom config, ini and trigger files, as well as my own powheg.lhe input. When it runs the grid job, it seems to copy the workflow script and run it within the grid environment. The job immediately fails, which I assume is due to none of my custom files being available within the grid environment. Is there a way to run a job with custom input files? Will I need to manually upload the custom files to my '/alice/cern.ch/user/...' directory and refer to their path there in the workflow script? Any advice will be appreciated.",
        "question": "Is there a way to run a job with custom input files on the grid, or do I need to manually upload them to the '/alice/cern.ch/user/...' directory and refer to their path there in the workflow script?"
    },
    {
        "source": "mattermost",
        "post_id": "3kc7nh5ntiyt3gghm3o19hyrza",
        "create_at": 1728035071155,
        "user_id": "oyh35b7cytdcjbpbqb7ytq1gpc",
        "message": "Dear @all,\nthe generator configuration files (.ini) in the O2DPG repository used for your simulations contained the environment variable\nO2DPG_ROOT which was making the whole framework not flexible and unable to run\nspecific configurations with different O2DPG releases. For this reason it was decided to introduce\nthe new O2DPG_MC_CONFIG_ROOT environment variable which, starting from the 04/10/2024 build,\nfigures in all the previous configurations and must be set in the new ones from now on.\nA GitHub action has been setup to make sure that this new rule is followed.\nBy default the new variable is set to O2DPG_ROOT when loading an environment, pointing to your current build O2DPG_ROOT folder,\nbut you can easily change it afterwards by exporting O2DPG_MC_CONFIG_ROOT to a new path.\nLet us know if you have any question.",
        "question": "What is the new O2DPG_MC_CONFIG_ROOT environment variable and how should it be used in simulations starting from the 04/10/2024 build?"
    },
    {
        "source": "mattermost",
        "post_id": "1a83rhaj53rg8gqyo3hh7qdfgy",
        "create_at": 1729503269020,
        "user_id": "919mo57ehi889km811xqgxwzwr",
        "message": "Hi everyone, I have been asked by my fellow UD members to show a possible way to simulate in o2 small private generators, e.g. a particle gun for some new particle or decay that has just been thought, and what I was doing was to generate some events on local with just some kinematics, producing an output which is identical to STARlight to be able to use the hepMC converter and feeding it to GRID.\nI see however my job failing with:\n```\ncommand export HEPMCEVENTSKIP=$(${O2DPG_ROOT}/UTILS/InitHepMCEventSkip.sh ../HepMCEventSkip.json 0);${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCCDB --run 536757 --configKeyValues \"HepMC.eventsToSkip=${HEPMCEVENTSKIP:-0};MFTBase.buildAlignment=true;GeneratorFileOrCmd.fileNames=/workdir/starlight.hepmc;\" -g hepmc -o genevents --timestamp 1684652284403 --seed 504627853 -n 200000 --fromCollContext collisioncontext.root:sgn_1; RC=$?; ${O2DPG_ROOT}/UTILS/UpdateHepMCEventSkip.sh ../HepMCEventSkip.json 1; [[ ${RC} == 0 ]] had nonzero exit code 1\nStop on failure  True\nsetting up ROOT system\nsgngen_1 failed ... checking retry\nINFO [anchorMC]: Running TPC time series\n``` \nAnd with trace:\n```\n**Oct 21Â **11:26:14****Â \\[proc \\]:Â **00:11:06**Â 666Â 2.53Â 0.00Â 16.83Â 233.30Â 233.30Â 112Â 25Â 2750Â 46.28Â 389.25Â 389.25Â 1000  \n**Oct 21Â **11:26:14****Â \\[trace \\]: \\[FATAL\\]: Monitor has detected an error: Core directory detected: core.1778. Aborting!  \n**Oct 21Â **11:26:14****Â \\[trace \\]: JobWrapper: SIGTERM received. Killing payload and proceeding to upload.  \n**Oct 21Â **11:26:14****Â \\[proc \\]: Execution completed. Time spent:  \n**Oct 21Â **11:26:14****Â \\[trace \\]: Payload killed. Executable exit code was 143  \n**Oct 21Â **11:26:15****Â \\[trace \\]: Going to uploadOutputFiles(exitStatus=ERROR\\_E, outputDir=[/alice/cern.ch/user/s/siragoni/recycle/alien-job-3187922911](https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fs%2Fsiragoni%2Frecycle%2Falien-job-3187922911 \"today 11:22\"))  \n**Oct 21Â **11:26:15****Â \\[trace \\]: Registering temporary log files inÂ [/alice/cern.ch/user/s/siragoni/recycle/alien-job-3187922911.](https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fs%2Fsiragoni%2Frecycle%2Falien-job-3187922911 \"today 11:22\")Â You must doÂ *'registerOutput 3187922911'*Â within 24 hours of the job termination to preserve them. After this period, they are automatically deleted.  \n**Oct 21Â **11:26:15****Â \\[state \\]: Job state transition from RUNNING to SAVING  \n**Oct 21Â **11:26:15****Â \\[trace \\]: No output given for ERROR\\_E in JDL. Defaulting to std\\*  \n**Oct 21Â **11:26:15****Â \\[trace \\]: Uploading: log\\_archive.zip toÂ [/alice/cern.ch/user/s/siragoni/recycle/alien-job-3187922911](https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fs%2Fsiragoni%2Frecycle%2Falien-job-3187922911 \"today 11:22\")  \n**Oct 21Â **11:26:15****Â \\[trace \\]:Â [/alice/cern.ch/user/s/siragoni/recycle/alien-job-3187922911/log\\_archive.zip](https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fs%2Fsiragoni%2Frecycle%2Falien-job-3187922911 \"today 11:22\"): uploaded as requested  \n**Oct 21Â **11:26:15****Â \\[state \\]: Job state transition from SAVING to ERROR\\_E\n```\nThe two hepMC files (real starlight and my own) are identical in format, apart from the string:\n``` \nP X 0 0.000000e+00 0.000000e+00 0.000000e+00 3.115470e+00 3.115470e+00 3 X X -1 X\n``` \nWhich is just the string of the unused mother particle. May I ask for some advice?\nJust a ping",
        "question": "What could be the reason for the simulation job failing with a core directory detected error when using a custom generator file, and how can I resolve it?"
    },
    {
        "source": "mattermost",
        "post_id": "akxnj9yzkpb9tedqpfxyczzorr",
        "create_at": 1729688667558,
        "user_id": "tchrdk7jtibcbbempsxh5bg8uc",
        "message": "Dear experts (especially maybe @swenzel),\n\nIs `TVirtualMC::TrackPosition(Double_t &x, Double_t &y, Double_t &z)` (https://github.com/vmc-project/vmc/blob/master/source/include/TVirtualMC.h#L686) also returning coordinates relative to the global origin (i.e. IP = (0,0,0)) or is some physics collision vertex also considered?\n\nMany thanks\n\n(cc @afurs)\nConfirmed by Ruben that this is ideed relative to the global origin, i.e. the VMC don't know about the collision vertex (@afurs)",
        "question": "Is `TVirtualMC::TrackPosition(Double_t &x, Double_t &y, Double_t &z)` returning coordinates relative to the global origin (i.e. IP = (0,0,0)) or is some physics collision vertex also considered?"
    },
    {
        "source": "mattermost",
        "post_id": "x9e5o4myzt8ui85yd7dj6chsuy",
        "create_at": 1729759507871,
        "user_id": "oyh35b7cytdcjbpbqb7ytq1gpc",
        "message": "Ciao @siragoni could you please send me the genevents_serverlog file? More information should be available there...\nApologies for the delay",
        "question": "Could you please send me the genevents_serverlog file? More information should be available there."
    },
    {
        "source": "mattermost",
        "post_id": "smc3ehxixfrx8jt5efk73qwaho",
        "create_at": 1730106810845,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "The vertex of MC events is available via MCEventHeader. Where would you need to access this information?",
        "question": "Where would you need to access the vertex information from MCEventHeader?"
    },
    {
        "source": "mattermost",
        "post_id": "q8pwcupcz3nhdgwuwapmgy5gsw",
        "create_at": 1730368686272,
        "user_id": "eiexotkj4tr5byhopwtwkopkyr",
        "message": "Hello, I'm working with production with embedding and have spotted following feature of  mccollision::.generatorsID(). In the production with signal only, the ID is 127, but in the embedded production this moves for signal generator to 255. How can I select the signal generator consistently in the task so I don't need to set different value for embedded and non-embedded production?  ",
        "question": "How can I select the signal generator consistently in the task so I don't need to set different values for embedded and non-embedded production?"
    },
    {
        "source": "mattermost",
        "post_id": "o7roq1tsb3g3fxxox6ns9bz8uy",
        "create_at": 1730474913594,
        "user_id": "eiexotkj4tr5byhopwtwkopkyr",
        "message": "Well unfortunately those getters solves nothing. getSouceId returns 0 for signal in non-embedded production and 1 in embedded, so its exactly the same problem but with different numbers. getGeneratorId returns 127 for everything,  ",
        "question": "What is the issue with the getters getSouceId and getGeneratorId in the ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "199q8a73gpy1dy5zj55x6mqmha",
        "create_at": 1730708093952,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "Ok. Could you please open a JIRA bug report with a reproducer script? Thanks",
        "question": "Could you please open a JIRA bug report with a reproducer script?"
    },
    {
        "source": "mattermost",
        "post_id": "3zbpp957c7bc7jf536w9x5ta8o",
        "create_at": 1730723127048,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\ncan the `PhaseSpace:bias2Selection` pythia option for 2->2 processes be activated for heavy ion simulations in pythia? or is it only for pp collisions",
        "question": "Can the `PhaseSpace:bias2Selection` pythia option for 2->2 processes be activated for heavy ion simulations in pythia?"
    },
    {
        "source": "mattermost",
        "post_id": "bswijcp3sfyymy9knrh5jb6noe",
        "create_at": 1730735503307,
        "user_id": "eiexotkj4tr5byhopwtwkopkyr",
        "message": "Here it is: [O2-5502](https://its.cern.ch/jira/browse/O2-5502) \nHello, I have the following pull request for O2DPG that needs a little assistance ([AliceO2Group/O2DPG#1765](https://github.com/AliceO2Group/O2DPG/pull/1765)). It is waiting there already one month. May I kindly ask for some feedback?   ",
        "question": "May I kindly ask for some feedback on the pull request ([AliceO2Group/O2DPG#1765](https://github.com/AliceO2Group/O2DPG/pull/1765)) that has been waiting for one month?"
    },
    {
        "source": "mattermost",
        "post_id": "sweuk3h6q786jp1qazkh64nk9r",
        "create_at": 1739278845175,
        "user_id": "pfqn8z49t7drmg9w8aqxi1brir",
        "message": "Hi all, we're running some pp events anchored to the Pb-Pb 2023 conditions, and have some issues with obtaining the number of events per TF that we ask for. I attach the sgngen log file (sgngen_2.log) - from what I can see from the warnings here, it seems to be because the number that are requested (400) are different from another value defined in collisioncontext, 'sgn', and at the event generation stage, the value from collisioncontext is taken.\n\nI note that for pp 13 teV simulations that I have run in the past, there is no issue requesting any number of collisions - from the same log for these collisions (sgngen_1.log attached), a different value 'sgn_1' in collisioncontext is used and is consistent with the user-defined value, though I don't know the reason. Any help on how to resolve this would be much appreciated!",
        "question": "Why is the number of events per TF requested different from the value defined in collisioncontext 'sgn' when running pp events anchored to Pb-Pb 2023 conditions, and how can this issue be resolved?"
    },
    {
        "source": "mattermost",
        "post_id": "f95gdtr553f7xxwcqu4iytcnyh",
        "create_at": 1739505911733,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "The problem is a bit subtle. It goes back to the fact that we are not simulating a given number of events but a given number of timeframes, since this is really our unit in Run3. In principle the number of events is determined from the number of timeframes (-tf) and the interaction rate and the length of the timeframe in orbits. The argument (-ns N) now means \"at max N events per timeframe but never more than the timeframe allows\". We usually now suggest to set it to some  large value and we could even get rid of the argument overall. The actual number of events is dynamic and reported in a file like 0_0_0_59.stat; I hope this answers your question. Suggestions for improvements are welcome.",
        "question": "What is the meaning of the argument (-ns N) in the context of ALICE O2 simulations, and how does it relate to the number of events and timeframes?"
    },
    {
        "source": "mattermost",
        "post_id": "d5hczhto5inwj8sn9jqwgqjtma",
        "create_at": 1739520711179,
        "user_id": "cb3ujfswxpd6tm5fj9z53byray",
        "message": "Hi @swenzel very good that this is now limited, thanks!!. However, I believe there should be no degeneracy in the input parameters at all: if IR and TF count is enough to uniquely determine what o2sim should do we should not introduce an event counter as it will (and did) lead to troubles (e.g. unfilled TFs). Another option would be to provide only IR and Nevents and let the code calculate number of TFs, rounding up/downwards in the last TF to avoid partially filled TFs. This last option would also allow the user to have more directly the expected number of events (which is also not quite the case even right now, since a very large number will not mean anything)... Just food for thought. Thanks again! ",
        "question": "Should the input parameters for o2sim be limited to IR and Nevents, allowing the code to calculate the number of TFs, or should we keep the current approach including an event counter?"
    },
    {
        "source": "mattermost",
        "post_id": "f6jq8ftizprajjoqxx3xo37rge",
        "create_at": 1739528617469,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "Hi all, I have just realised that in our simulations all hypernuclei leave no-signal/trace in any detectors.\nLooking at the sim log (in attachment), it seems that no ionisation process (hIoni) is set for hypertriton. This might also be related to the fact that the user-definition of the particle in the O2MCApplication.cxx is skipped, as hypertriton is already defined in Geant. Is there a way to enable the ionisation process for hypertriton via .in config file? Any help would be very appreciated! ",
        "question": "How can I enable the ionisation process for hypertriton via the .in config file in ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "ugymqs5j1tn17q4ph4q5zubfiy",
        "create_at": 1739529950186,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@ihrivnac : Would you have an idea here ?",
        "question": "Would you have an idea here?"
    },
    {
        "source": "mattermost",
        "post_id": "3wb6rehfkjnqpdywkbiz484u7o",
        "create_at": 1742399869699,
        "user_id": "d1emreg7tiypzd4xqx564b54qc",
        "message": "Hi,\nI want to run a small local simulation in which I inject a particle in a pythia event. For this I wanted to use a cocktail generator as definded in the attached json file.\nI would now also like to force the decay of the particle. Here I am not really sure how to do it. What decayer is actually used in the case of this hybrid/cocktail approach? Could I just use a costume pythia configuration and add a line like:\n`553:oneChannel = 1 1.0 0 -11 11`?",
        "question": "What decayer is actually used in the case of this hybrid/cocktail approach, and could I force the decay of a particle by adding a line to a custom Pythia configuration?"
    },
    {
        "source": "mattermost",
        "post_id": "7u114h3c8jfq8qxpzzc8iwrtuh",
        "create_at": 1742458119206,
        "user_id": "doujrcnqnpbj5pzj1jk7zx3xxw",
        "message": "Greetings. I want to visualize the detectors from a simulation from o2sim_geometry.root. Is there a way to do this using o2?",
        "question": "Is there a way to visualize the detectors from a simulation using o2?"
    },
    {
        "source": "mattermost",
        "post_id": "exd5s5pyziniif1qw43tohpajw",
        "create_at": 1743437891576,
        "user_id": "izu1hy8fzb8j3rcs53pdztbkdy",
        "message": "Dear experts,\n\nI'm trying to set up a simple Pythia8 simulation chain in O2 without Geant4, producing AO2D output for analysis. I found an example that resembled what I wanted in ```O2/run/SimExample/McTracksToAOD```, I based my workflow on this example, but I'm encountering an issue with histogram outputs.\n\nI modified the example to:\n- Generate Pythia8 events (```dpl-config1.json```)\n- Convert MC tracks to AO2D\n- Analyze jets using FastJet (added jet histograms)\n\nAttached files:\n```mctracks_to_aod_simple_task.cxx``` (my analysis task)\n```dpl-config1.json``` (configuration)\n```run_Pythia8.sh``` (workflow script)\n```CMakeList.txt```\n\nThe Problem:\nWhen running run_Pythia8.sh, the workflow completes without errors, I get AnalysisResults.root with only the aod-consumer-test-task table but I'm missing the required histograms, can you help me ?\n\nThanks",
        "question": "Why are the histograms missing in the AnalysisResults.root file when running the Pythia8 simulation chain for AO2D output in O2?"
    },
    {
        "source": "mattermost",
        "post_id": "nizganzpq7njtqtrxpffkpofwa",
        "create_at": 1743990743386,
        "user_id": "m7gcuh797jdhtjznffpdranw6a",
        "message": "Dear experts,\nI want to run a simulation using Grid computing. However, my quota is only 9 GB and I would like to increase it. Could you tell me how to increase it ? \nBest regards",
        "question": "How can I increase my quota to run simulations using Grid computing?"
    },
    {
        "source": "mattermost",
        "post_id": "jcw6h5xpbfffjxkfoh1zynikso",
        "create_at": 1744131377050,
        "user_id": "ojamyqznoidf8yen67drwoxnsy",
        "message": "Dear experts, I am experiencing some problems when trying to build O2Sim. After updating O2DPG, O2, and alidist, the build of O2sim breaks when compiling Clang@v18.1.8. Is this a known issue? I attach here the log. Thanks a lot!",
        "question": "Is there a known issue with building O2Sim after updating O2DPG, O2, and alidist, specifically when compiling Clang@v18.1.8?"
    },
    {
        "source": "mattermost",
        "post_id": "b7zjtzme5pbi8b535nka3sqycr",
        "create_at": 1744183968609,
        "user_id": "ojamyqznoidf8yen67drwoxnsy",
        "message": "Hi @swenzel ! Ok, thanks ;)\nDear experts, I am encountering some problems in the simulation, and I am not quite sure where the problem lies from the logs. Here's the link to the [script](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/s/spolitan/selfjobs/test_anchor_corrBkg_pp-20250409-123057/alien_jobscript.sh) I am currently using to simulate,  and attached here are the trace I get from running on grid, and the stdoout file. Thanks in advance for your support! :)\nDear experts, I am encountering some problems in the simulation, and I am not quite sure where the problem lies from the logs. Here's the link to the [script](https://alimonitor.cern.ch/users/download.jsp?view=true&path=/alice/cern.ch/user/s/spolitan/selfjobs/test_anchor_corrBkg_pp-20250409-123057/alien_jobscript.sh) I am currently using to simulate,  and attached here are the trace I get from running on grid, and the stdoout file. Thanks in advance for your support! :)",
        "question": "What is the issue with the simulation and how can I identify it from the logs?"
    },
    {
        "source": "mattermost",
        "post_id": "66mxjedw1fdw8ybbsc9pbf1pih",
        "create_at": 1744212800950,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "You are missing an argument for the `-nb` option. The environment variable `${NBKGEVENTS}` is not defined.\nYou are missing an argument for the `-nb` option. The environment variable `${NBKGEVENTS}` is not defined.\nI debugged this by executing an exact reproducer in a local environment: Given any GRID process ID, one can (a) generate a reproducer script by executing `${O2DPG_ROOT}/GRID/utils/getReproducerScript.sh ALIEN_PROC_ID`. (In your case the ALIEN_PROC_ID is 3313529485). (b) Execute the resulting script `reproducer_script_3313529485.sh` say on lxplus.cern.ch (this needs your alien-tokens initialized beforehand). (c) inspect the files for clear errormessages ... in this case it was in `timestampsampling...log`.\nI debugged this by executing an exact reproducer in a local environment: Given any GRID process ID, one can (a) generate a reproducer script by executing `${O2DPG_ROOT}/GRID/utils/getReproducerScript.sh ALIEN_PROC_ID`. (In your case the ALIEN_PROC_ID is 3313529485). (b) Execute the resulting script `reproducer_script_3313529485.sh` say on lxplus.cern.ch (this needs your alien-tokens initialized beforehand). (c) inspect the files for clear errormessages ... in this case it was in `timestampsampling...log`.",
        "question": "What is the missing argument for the `-nb` option and how can I resolve the issue with the undefined `${NBKGEVENTS}` environment variable?"
    },
    {
        "source": "mattermost",
        "post_id": "9wnt96daefyqzfo71bi1hp6hqw",
        "create_at": 1744623844515,
        "user_id": "1uiqyb17bbyemb9j8gqi7ncqdy",
        "message": "Dear Experts,\nHow do I access `isPhysicalPrimary()` boolean at the generator level (`o2sim_Kine.root`)\nI see that for AO2D level, it can be accessed from `o2::aod::mcparticle::IsPhysicalPrimary`\nBut I cannot find the correct class to access it on the generator level.",
        "question": "How do I access the `isPhysicalPrimary()` boolean at the generator level in ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "wk7zqbeitjgmdc6aikubbfpeoc",
        "create_at": 1745228579339,
        "user_id": "ffcgsbfzijfsbj1p14w6w7nz9e",
        "message": "Dear Experts, I am trying to generate L* injected anchored MC using latest O2Sim tag. But, it says in sgngen_1.log that\n```\nRunning: TIME=\"#walltime %e\\n#systime %S\\n#usertime %U\\n#maxmem %M\\n#CPU %P\" /usr/bin/time --output=sgngen_1.log_time ./sgngen_1.log_tmp.sh\n[INFO] This is o2-sim version 1.2.0 (6963217343)\n[INFO] Built by ALIBUILD:1.17.15+noble, ALIDIST-REV:3a178e8f9deb62029aae320268c532f7b717e4f7 on OS:Linux-6.11.0-21-generic\n[INFO] BINDING TO ADDRESS ipc:///tmp/o2sim-notifications-921618 type pub\n[INFO] Running with official detector version 'ALICE2'\n[INFO] Running with official detector version 'ALICE2'\nError in <TFile::TFile>: file /home/hirak/alice/MCtest/L1520/tf1/collisioncontext.root does not exist\n[FATAL] Could not open collision context file collisioncontext.root\nFor later analysis we write a core dump to core_dump_921618\n./sgngen_1.log_tmp.sh: line 4: 921618 Aborted                 (core dumped) ${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode kCollContext --run 526641 --configKeyValues \"MFTBase.buildAlignment=true;\" -g external --configFile /home/hirak/alice/MCtest/L1520/run.ini -o genevents --embedIntoFile ../bkg_MCHeader.root --timestamp 1664862745505 --seed 504627853 -n 200 --fromCollContext collisioncontext.root:sgn\nTASK-EXIT-CODE: 134\n```\n\nThe script is attached. Earlier this script worked well. How to solve this issue, now? Thanks in advance.",
        "question": "How to solve the issue of the collision context file not existing when trying to generate L* injected anchored MC using the latest O2Sim tag?"
    },
    {
        "source": "mattermost",
        "post_id": "dx6ppgaikffqjdpcwsatp5mzto",
        "create_at": 1745318267584,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "There have been several changes in the MC workflow logic that could be causing this issue. Most notably, the timeframe generation structure was refactored to account for the timeframe history effect (i.e., pileup between timeframes) and to support \"full timeframes\" with embedding. Your script seems to fall into a corner case: embedding with essentially empty timeframes â€” which hasn't been thoroughly tested yet. I'll look into fixing that.\n\nFor now, you're requesting 200 signal events per timeframe, embedded into 200 background events (reused across each timeframe). This setup is generally not compatible with the updated logic, which assumes that we want to simulate full timeframes with history effects, both of which complicate handling of a fixed number of events.\n\nTo fix your study *now*, Iâ€™d recommend the following new general strategy:\n\n- Tune the number of timeframes, not the number of events.\n\n- Adjust the timeframe length in orbits, not by \n  manually setting the number of signals. You can \n  do this by setting export \n  ALIEN_JDL_MC_ORBITS_PER_TF=32 for example.\n  At 600 kHz, you might want to use a lower \n  number, like export \n  ALIEN_JDL_MC_ORBITS_PER_TF=4 or 5, to get \n  roughly 200 signal events per timeframe.\n\n- Set NSIGNAL to a large value, like 100000.\n  The actual number of signals will be determined \n  dynamically based on the interaction rate and \n  timeframe length. (This will eventually become the \n  default behavior.)\n",
        "question": "What is the new strategy to fix the study now given the changes in the MC workflow logic?"
    },
    {
        "source": "mattermost",
        "post_id": "cw591noqo3rtz84g66zmexf8oh",
        "create_at": 1745394058939,
        "user_id": "cpbtrxhrtjrpjnqbthnhr9y8rw",
        "message": "Hi @swenzel , I am trying to generate a single event for testing purpose, and I get in the logs: `The number of events on the command line 1 and in the collision context differ. We take the one from collision context 43`\nI guess this is a consequence of what you were mentioning yesterday. But it is not clear to me whether it is still possible to generate a single event or not",
        "question": "Is it still possible to generate a single event for testing purposes given the discrepancy between the number of events specified on the command line and in the collision context?"
    },
    {
        "source": "mattermost",
        "post_id": "63zq3wp9hibxdr8h88649dhwih",
        "create_at": 1747409653828,
        "user_id": "18pm5mzp4fdwixkmabpboxhoty",
        "message": "Hi,\nI am generating Pythia HI events and injecting them into an analysis framework. This is the example I am running. https://github.com/AliceO2Group/AliceO2/blob/dev/run/SimExamples/McTracksToAOD/run_Pythia8.sh\n \nI wish to access information like the number of neutron and proton spectators in HI collisions. Such information can be found in the table called o2::aod::HepMCHeavyIon.\n\nWhat additional workflow do I need to include to generate such a table?",
        "question": "What additional workflow do I need to include to generate the o2::aod::HepMCHeavyIon table that contains information like the number of neutron and proton spectators in HI collisions?"
    },
    {
        "source": "mattermost",
        "post_id": "jwom9baqgpgn9jwnqn6cmgecjw",
        "create_at": 1747574620498,
        "user_id": "z3tj8hbhxib68rioh8xzijd6mo",
        "message": "Hello, just a small question, what is a correct way to set the range of impact parameter for heavy ion collisions? I have used file pythia8_hi.cfg and tried to set \nHeavyIon:bWidth 1.0              \nand \nHeavyIon:bMax 1.0\n\nbut none was helpful\n",
        "question": "What is the correct way to set the range of impact parameter for heavy ion collisions in ALICE O2 simulations?"
    },
    {
        "source": "mattermost",
        "post_id": "yfuq3sfmf3fojpwf3kc931zo6o",
        "create_at": 1747662589346,
        "user_id": "3p9eksxi9fy5tnfitymam8z76c",
        "message": "Hello, do we have a macro that can give the material distribution in radiation or interaction length for certain eta/phi at certain R, or something similar?",
        "question": "Do we have a macro that can give the material distribution in radiation or interaction length for certain eta/phi at certain R, or something similar?"
    },
    {
        "source": "mattermost",
        "post_id": "wdwdw8atqi815cep8f3uore7jy",
        "create_at": 1747831102399,
        "user_id": "3p9eksxi9fy5tnfitymam8z76c",
        "message": "Hey, does someone know if the material changed between the MC LHC24f3c and LHC24f3d? Specifically around 50 cm radius?",
        "question": "Does the material change between MC LHC24f3c and LHC24f3d specifically around a 50 cm radius?"
    },
    {
        "source": "mattermost",
        "post_id": "4gr891feej8jjxp9qzwe1b473r",
        "create_at": 1748941982557,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI'm trying to find the PYTHIA tune used in general purpose Run3 pp simulations.\nLooking at O2DPG for \"tune\" (in particular in the o2dpg_sim_workflow `externalPythia8Config == None` case, or in .cfg files or mkpy8cfg.py) , I do not see any setting for it except for some PWG specific configs. So can I safely assume that the tune used is the default PYTHIA tune? (Monash 2013 if I understand the PYTHIA documentation correctly)\n",
        "question": "What is the PYTHIA tune used in general purpose Run3 pp simulations, and can I assume it is the default PYTHIA tune (Monash 2013)?"
    },
    {
        "source": "mattermost",
        "post_id": "96hqkd3d6b8wi8n57tojxwt3wy",
        "create_at": 1749045916033,
        "user_id": "eoxmbzf96brtdfd7rs9qm77tjr",
        "message": "Hi @swenzel, I'm testing a new generator, the jobs go to DONE but no AOD.root is produced\nSee: https://alimonitor.cern.ch/catalogue/?path=%2Falice%2Fcern.ch%2Fuser%2Fa%2Falcaliva%2Fselfjobs%2FdeuteronCoal-20250604-103303%2F001#/alice/cern.ch/user/a/alcaliva/selfjobs/deuteronCoal-20250604-103303/001\n\nDo you perhaps know what is the cause of this? ",
        "question": "Do you perhaps know what is the cause of this? No AOD.root is produced even though the jobs go to DONE."
    },
    {
        "source": "mattermost",
        "post_id": "guy9sfy4gif6bfrn97ti7jgp1h",
        "create_at": 1749575367799,
        "user_id": "oyh35b7cytdcjbpbqb7ytq1gpc",
        "message": "Dear all, recently the new Pythia8.315 version has been released in our simulation framework. This comes with an important bug fix that has been around since the upgrade from Pythia6 to Pythia8 and discovered only recently. The issue is related to the case where diquarks or strange quarks are assumed to be produced at a later average time than the up and down quarks, when the Lund symmetric fragmentation function has to be generalized (with a wrong calculation so far). By default diquarks are assumed to be produced later, so the bug fix has an impact on correlations between baryons and antibaryons, and to some degree on baryon spectra. On the other hand, event shapes should only be slightly affected. A full description of the fix can be found here https://pythia.org/pdfdoc/aextra.pdf, and a short one on the release note for the latest Pythia8 version https://pythia.org/history/. The new `StringZ:useOldAExtra` switch has been introduced for backwards compatibility. This is switched `off` by default, but all the old tunes **must** have it turned ON to ensure their validity, since they were tuned with this behaviour. New tunes will be released in the future including the new released fix.\nAt this stage, it would be extremely useful for the users to study the impact on key observables, especially those related to baryon correlations, so to communicate to the Pythia authors any significant and important findings. ",
        "question": "What is the impact of the new Pythia8.315 version on baryon correlations and baryon spectra, and what should users do to study this impact?"
    },
    {
        "source": "mattermost",
        "post_id": "x1af9abka38emxbz6cbikoxejy",
        "create_at": 1749579551875,
        "user_id": "gi6dw66sw3r47qmbsa6dgaatio",
        "message": "Dear experts, I am trying to run test simulations on the Grid in order to request a MC production. I have a few questions:\n- I want to use pre-generated event pools for this MC production. As far as I understand, I need to pass  a separate json-file in `ALIEN_JDL_ANCHOR_SIM_OPTIONS` in order to specify the event pool and another generator for the minimum-bias gap events. I uploaded this `generator_conf.json` to my personal directory in MonALISA and specified the path accordingly. Is this correct?\n- If I open the log files by clicking on the job `PID` in the `My jobs` page on MonALISA, I get the following error message in stdout:\n> ERROR [anchorMC]: Problem during anchor timestamp sampling and workflow creation. Exiting.\n\nDo you know what this means? Is there a way to get more detailed output and error messages from the tasks that are run?\n- I tried storing the logs and stdout/stderr files by specifying them in the --outputspec and --erroroutputspec options respectively. The argument passed to --erroroutputspec is however not recognized, but the option is apparently needed so that the commands are correctly interpreted. How can I also make sure that stdout and stderr are stored permanently?\nFrom the error message above I would deduce that the workflow creation fails and that therefore all the other log-files are not produced, but without them it's difficult for me to figure out what the problem is.\nMany thanks in advance!",
        "question": "- I want to use pre-generated event pools for this MC production. As far as I understand, I need to pass a separate json-file in `ALIEN_JDL_ANCHOR_SIM_OPTIONS` in order to specify the event pool and another generator for the minimum-bias gap events. Is this correct?"
    },
    {
        "source": "mattermost",
        "post_id": "48qy6ajinfny3b8y5har356c7w",
        "create_at": 1749634216935,
        "user_id": "oyh35b7cytdcjbpbqb7ytq1gpc",
        "message": "Hi @pstahlhu could you please redirect me to the masterjob you launched so that I can check the full configuration? ",
        "question": "Could you please redirect me to the masterjob you launched so that I can check the full configuration?"
    },
    {
        "source": "mattermost",
        "post_id": "w1b8qu1hstbzdnc689u1ecrh4e",
        "create_at": 1750154889031,
        "user_id": "9wmacn4dwjyr7j56du7q3zh6ah",
        "message": "Dear experts, I am running O2 simulations with the O2DPG workflow scripts. I am primarily interested in studies in the forward muon arm and don't really make use of the central barrel - except maybe the ITS. I see that it is possible to exclude the ZDC, but haven't found a way to exclude other detectors. The TPC is incredibly computationally expensive, which is wasted resources when i do not make use of it. Is there a way to exclude this from the workflow? ",
        "question": "Is there a way to exclude the TPC and other unnecessary detectors from the O2 simulations to save computational resources?"
    },
    {
        "source": "mattermost",
        "post_id": "qgscby6ihbfciftwc4fd9rgj5o",
        "create_at": 1750171179757,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "I general, we do not have full support for this kind of modularity (I think the AOD converter can not fully handle missing TPC inputs ... but to be verified). However, it depends what you would like to study: (a) Do you need AO2D.root --> then I think this is not easily possible. (b) Do you merely need say MID reconstruction objects? Then you could simply specify `o2dpg_workflow_runner.py -tt midreco` and the MC workflow would only execute the path on the grap needed for MIDreco. In this case, it will likely skip TPC digitization and reconstruction. If you are using anchorMC.sh then this can be achieved with setting env variable `export ALIEN_JDL_O2DPGWORKFLOWTARGET=midreco` before launching anchorMC.",
        "question": "Can we run the MC workflow for MID reconstruction objects only and skip TPC digitization and reconstruction?"
    },
    {
        "source": "mattermost",
        "post_id": "8n1qheja7trh3dhstjk7ur4n6a",
        "create_at": 1750174676840,
        "user_id": "9wmacn4dwjyr7j56du7q3zh6ah",
        "message": "In the case of option (b), when working on the MID cluster size, I have simply run 'o2-sim' directly to generate hits and then run the MID reconstruction manually - which worked fine for that context. For the current task I would probably need to access AOD, as I want to generate training data for W->muon events, where I want to access global forward tracks - as I want to access parameters such as the kinematics, matching chi-squared and probably DCA etc. - most of the quantities contained in the AOD forward-tracks table. Will it be possible to also access these quantities by similarly running 'o2-sim' directly and then doing the full reconstruction up until 'o2-globalfwd-matcher-workflow'? Which I can then process with a ROOT script. Or is my best bet to run the full O2DPG workflow script and generate the AOD to be analyzed by O2Physics? ",
        "question": "Can 'o2-sim' followed by the full reconstruction up to 'o2-globalfwd-matcher-workflow' provide access to the same quantities (like kinematics, matching chi-squared, and DCA) as generating the AOD through the full O2DPG workflow?"
    },
    {
        "source": "mattermost",
        "post_id": "98ap1enoufdftjcanybpd763qy",
        "create_at": 1750340612886,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "If you need AO2D, then you could try (after [AliceO2Group/O2DPG#2036](https://github.com/AliceO2Group/O2DPG/pull/2036) is merged) to simply reduce the number of readoutDetectors to a minimal set. Something like `--readoutDets MFT,MCH,MID,ITS` passed either directly to `o2dpg_sim_workflow.py` or via `ALIEN_JDL_ANCHOR_SIM_OPTIONS` if you use anchorMC (`https://aliceo2group.github.io/simulation/docs/o2dpgworkflow/anchored.html?highlight=anchorMC`). This will only generate hits for MCH,MFT,MID,ITS and hence all processing for TPC, TRD etc should be fast(er). I checked that ITS needs to be included, otherwise it crashes.",
        "question": "What minimal set of readout detectors should I use to run ALICE O2 simulations faster while still including the ITS detector?"
    },
    {
        "source": "mattermost",
        "post_id": "6pusqg6xhbdaxpb7zt39woihwa",
        "create_at": 1750412488324,
        "user_id": "mrz4qi4dm7gm8gxycg9qt8qmbr",
        "message": "Dear Marco, all,\nCould you advise what would be the easiest way to generate some events with this new Pythia version (for pp collisions) locally? The output can be just simple hep-mc files, or the AO2D.root files. \nI wanted to check if baryon angular correlations have improved...\nI have O2sim installed.",
        "question": "What is the easiest way to generate events with the new Pythia version for pp collisions locally, and what types of output files can I expect?"
    },
    {
        "source": "mattermost",
        "post_id": "8iwmq1fsjjnm5py3xwh8nqt73o",
        "create_at": 1750682762743,
        "user_id": "mrz4qi4dm7gm8gxycg9qt8qmbr",
        "message": "Is there a way to run this without ALICE reconstruction? Just pure MC truth?",
        "question": "Is there a way to run simulations without ALICE reconstruction, just using pure MC truth?"
    },
    {
        "source": "mattermost",
        "post_id": "uptpzwwtbb8fzqbkffw3exijhe",
        "create_at": 1750686543767,
        "user_id": "n87pwhqdcpbhifomoihzirqwrr",
        "message": "Dear experts,\nI am looking at the tracking efficiency in pp, in MC anchored to the 2022 13.6 TeV data (LHC22o) and to the 2024 5.36 TeV pp ref data (LHC24ap).\nI am finding very different behaviours in pt, eta and phi between those two datasets, and do not understand why the difference is so big. Does anyone have an idea as to what might be the reason I am seeing such differences?",
        "question": "What might be the reason for the large differences in tracking efficiency between the 2022 13.6 TeV data (LHC22o) and the 2024 5.36 TeV pp ref data (LHC24ap) in pt, eta, and phi?"
    },
    {
        "source": "mattermost",
        "post_id": "su557ww8qibaij5mjzerb9o7ma",
        "create_at": 1750883095760,
        "user_id": "9wmacn4dwjyr7j56du7q3zh6ah",
        "message": "Dear experts, I have recently encountered an unexpected behaviour of the O2DPG workflow that I don't remember seeing in the past. It seems like very few of the simulated events end up getting reconstructed and saved at the AO2D level. For example, to test if it was not just my workflow being incorrectly configured, I ran the proton-proton minimum bias example found at [O2DPG_pp_minbias](https://github.com/comrademarvin/O2DPG/blob/master/MC/run/examples/O2DPG_pp_minbias.sh) for 1 TF and 20 events. When I check the AO2D, it will then have 63 entries in the McCollision table, but only 2 reconstructed event entries in the Collision table. I first noticed this when my script (for W->muon events) that produced predictable results in the past, when more than 90% of the events and simulated tracks got reconstructed, only outputted a reconstruction efficiency of a few percent - the amount of reconstructed tracks is now very low compared to the simulated ones. I have observed this for every simulation workflow that I have run to test. I also made sure to update to the more recent versions of O2 and O2DPG. Any idea what could be happening for so many of the events to not get reconstructed?",
        "question": "Why are very few of the simulated events ending up being reconstructed and saved at the AO2D level in the O2DPG workflow?"
    },
    {
        "source": "mattermost",
        "post_id": "g9h58qqhtpnduk5pdqwgqci5qo",
        "create_at": 1750938151261,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "I cannot comment too much on reco efficiency. Running this script on a larger sample (full timeframe) with about 1400 events at 500kHz yields ~700 primary vertices found. It does seem a bit low. Maybe @shahoian can comment. (Settings in unanchored MC non-optimal, ...)?",
        "question": "What does the low number of primary vertices found (about 700 out of 1400 events) suggest about the settings in the unanchored MC, and should @shahoian be consulted?"
    },
    {
        "source": "mattermost",
        "post_id": "gz1jedw9w38kx8y5g8hca7z1he",
        "create_at": 1750940307912,
        "user_id": "uz3jj8r7ffgcdxwhbs3grc5n1e",
        "message": "@jpotgiet could you show your exact simulation settings, so that I could reproduce it?",
        "question": "Could you show your exact simulation settings so that I could reproduce it?"
    },
    {
        "source": "mattermost",
        "post_id": "81gojimu3inuudzk9oj964ufoa",
        "create_at": 1750946815403,
        "user_id": "uz3jj8r7ffgcdxwhbs3grc5n1e",
        "message": "Hi, I've generated 3 TFs with the default settings, it generates ~65-70 events against requested 20, putting all extra events into the orbit preceding the 1st orbit requested for the nominal simulation (by design, to have the occupancy of this 1st orbit realistic). Of these 20 potentially reconstructable events it finds 12 and 9 PVs in the tf1 and tf2 and 0 in the tf3. Note that by default it takes run from designated 2kGaus field range, the eff. might be lower in this range.\nThe reason for the inefficiency in the tf3 is that the generated vertices Z for this event look like in the attachment, while for other TFs it is expected gaussian of sigma ~5. @swenzel any idea what could go wrong?\n",
        "question": "What could be the reason for the inefficiency in the tf3, where no primary vertices are found, while other TFs find primary vertices?"
    },
    {
        "source": "mattermost",
        "post_id": "5ns6gmwdqprhmp8s5ok4smscwc",
        "create_at": 1750946985997,
        "user_id": "1ws47bhqkfrbfe35f6ebziqrfh",
        "message": "@shahoian : Will take a look! But otherwise the 50% efficiency in tf1/tf2 is normal?",
        "question": "Is the 50% efficiency in tf1/tf2 normal?"
    },
    {
        "source": "mattermost",
        "post_id": "orhsreoar7djfbpiu9cmfphz7c",
        "create_at": 1751375053029,
        "user_id": "kpfmky1pz7rideeof1wictw5io",
        "message": "Dear expert, Is there a Pbâ€“Pb MC AO2D for LHC23zzh pass4, and under which tag? I was trying to locate it under /sim folder in MonALISE Repository, but without luck. Thank you in advance for your help and advise.",
        "question": "Is there a Pbâ€“Pb MC AO2D for LHC23zzh pass4, and under which tag?"
    },
    {
        "source": "mattermost",
        "post_id": "dh3h1m4ci7grjbth7j6mkcnuhw",
        "create_at": 1751561352525,
        "user_id": "gj5d5qtdoi8wixnd7snys6ceaa",
        "message": "Dear experts,\n\nWhen generating anchored MC locally, I have a very strange issue (that I couldn't find elsewhere in this channel):\n\n- I first generate 40 TF with 4000 events each using the attached script (note that `anchorMC.sh` corresponds to the current master of O2DPG). All is good.\n- I then re-run the script \"for fun\" with the exact same configuration, and within the first 5-6 seconds of the script's execution, my `tf9/` folder is mysteriously deleted and the script fails (since `tf9` was removed and re-generated, it doesn't contain necessary things like `collisioncontext.root`)\n- If I re-run again (without modifying anything), my `tf8` is deleted (and the script fails)\n- If I re-run again (without modifying anything), my `tf7` is deleted (and the script fails)\n... (this can continue)\n- At some point I can remove the log_done from pre-collision context, then on the next invocation of the attached script, it will *still* remove another tf (decremented from the previous run of the script), but since it knows to re-run the pre-collision context task, everything gets moved into the correct spots and the previously deleted tfs will re-generate fully\n\nFor me, the expected behavior when re-running the script with the same configuration \"for fun\" would be that nothing happens (i.e. all tasks have been marked as done, so there is nothing to do), but this is definitely not happening in my case... Also the above behavior is deterministic in that it's always starting at tf9, then tf8, then 7, etc.....\n\nAny help would be very much appreciated!\n\n\n\n",
        "question": "What is the unexpected behavior when re-running the script to generate anchored MC, and how does it affect the `tf` folders?"
    },
    {
        "source": "mattermost",
        "post_id": "7asfd1xqtpfa3y356k74m6hanr",
        "create_at": 1752153034435,
        "user_id": "3a5ytz8r33fcme33fb8gbicr6e",
        "message": "Dear experts, @mgiacalo, recently (~this week) I noticed a problem in compiling Rivet on Ubuntu 24.04 when running `aliBuild build O2sim --defaults o2`. It looks like the compilation fails due to some hdf5 headers not found. I managed to compile O2sim successfully by disabling Rivet. ",
        "question": "Why does compiling Rivet fail when running `aliBuild build O2sim --defaults o2` on Ubuntu 24.04, and how can I successfully compile O2sim with Rivet?"
    },
    {
        "source": "mattermost",
        "post_id": "4sjuyy5a8pnzdjzq9cazc7tugw",
        "create_at": 1752238476594,
        "user_id": "kpfmky1pz7rideeof1wictw5io",
        "message": "Thank you, David. I have found it. Now I am looking for matching MC Simulated Data; any help would be appreciated. Thank you in advance\nDear Experts,\nI am looking for Monte Carlo simulated/generated datasets (AO2D). Is the alice/sim/ folder in MonALISA the correct place to find these data?",
        "question": "Is the alice/sim/ folder in MonALISA the correct place to find Monte Carlo simulated/generated datasets (AO2D)?"
    }
]