## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/MC/analysis_testing/README.md

**Start chunk id:** 04fd492dbbd804326f52fa901891db41c4154a8b2d008e1598445a08ab556c6b

## Content

**Question:** What are the steps required to enable and include an analysis in the simulation pipeline, and how are these steps reflected in the JSON configuration?

**Answer:** To enable and include an analysis in the simulation pipeline, several steps must be followed, which are reflected in the JSON configuration as follows:

1. Set `enabled` to `true` to activate the analysis.
2. Specify the `name` of the analysis, which should be short and meaningful.
3. Define the tasks required for the analysis by listing them under the `tasks` key. These tasks are derived from `O2Physics` and will be integrated into the common command-line pipeline.
4. Indicate whether the analysis can be run on Monte Carlo (MC) data or real data by setting `valid_mc` or `valid_data` to `true`, respectively.

These steps ensure the analysis is properly configured and included in the pipeline for both MC and data as needed.

---

**Question:** What is the effect of not specifying the `-tt` option when running `o2_dpg_workflow_runner.py`?

**Answer:** When the `-tt` option is not specified in the command `o2_dpg_workflow_runner.py -f workflow_analysis_test.json -tt Analysis_<analysis-name>`, all tasks within the workflow will be executed.

---

**Question:** What are the steps to validate the outputs of an analysis task using the `o2dpg_analysis_test_config.py` script, and how can you specify a different output directory if needed?

**Answer:** To validate the outputs of an analysis task using the `o2dpg_analysis_test_config.py` script, you should run:

```bash
${O2DPG_ROOT}/MC/analysis_testing/o2dpg_analysis_test_config.py validate-output --tasks <analysis-name1> [<analysis-name2> [...]] [-d <output-directory>]
```

Here, `<analysis-name1>`, `<analysis-name2>`, etc., represent the names of the analysis tasks you want to validate. The `-d <output-directory>` option allows you to specify a different output directory if the default `Analysis` directory is not used.

---

**Question:** What steps are required to ensure an analysis is executed during MC GRID productions or data reconstruction using AnalysisQC, and why might a discussion about runtime and resource needs be necessary?

**Answer:** To ensure an analysis is executed during MC GRID productions or data reconstruction using AnalysisQC, the following steps are required:

1. Define the analysis according to the specified method.
2. Ensure the `enabled` flag is set to `true` for the analysis definition.

A discussion about runtime and resource needs is necessary because:
- The automated execution of defined analyses can impact the performance and duration of the MC production or data reconstruction process.
- Ensuring that the computational resources are sufficient to handle the additional workload without causing delays or performance issues is crucial.
- Assessing the resource needs helps in planning and managing the computational infrastructure effectively.

---

**Question:** What is the significance of specifying the `expected_output` list in the analysis configuration?

**Answer:** Specifying the `expected_output` list in the analysis configuration serves the purpose of enabling automated post-processing. This list defines the anticipated outputs that the analysis is expected to produce, allowing for the development of scripts or tools that can process these outputs systematically and efficiently. By clearly defining what is expected, it simplifies the integration of post-processing steps, ensuring that the correct files and data formats are handled appropriately.

---

**Question:** What is the required directory structure for placing specific configurations for an analysis, and why is it important that the sub-directory name matches exactly the name of the analysis?

**Answer:** For placing specific configurations for an analysis, the required directory structure involves creating a sub-directory that matches exactly the name of your analysis. Inside this directory, you should create a further sub-directory indicating the collision system. Within this collision system sub-directory, place the `analysis-testing-mc.json` or `analysis-testing-data.json` file as needed.

It is important that the sub-directory name matches exactly the name of the analysis to ensure that the specific configuration for that analysis is correctly identified and used. If the name does not match exactly, the system will not be able to find and apply the specific configuration, potentially leading to the use of default settings that may not align with your analysis requirements.

---

**Question:** What command-line options must be used to run the analysis on MC data and specify an output directory different from the default?

**Answer:** To run the analysis on MC data and specify an output directory different from the default, the following command-line options must be used:

```bash
${O2DPG_ROOT}/MC/analysis_testing/o2dpg_analysis_test_workflow.py -f <path-to-aod> --is-mc -a <custom-output-directory> -o <workflow-filename>
```

Replace `<path-to-aod>` with the path to the AOD file, `<custom-output-directory>` with the desired output directory, and `<workflow-filename>` with the desired name for the workflow file.

---

**Question:** What is the primary purpose of the Analysis testing (AnalysisQC) as described in the document?

**Answer:** The primary purpose of Analysis testing (AnalysisQC) is for testing various analyses, ensuring their functionality and correctness, without being intended to replace the production analysis procedures.