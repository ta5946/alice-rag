## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/DATA/production/README.md

**Start chunk id:** 84759886e94c6b468a3b98c4f5412fd47ba4717d205b6d52fdb56754b2b3ba30

## Content

**Question:** How many workflows are mentioned in the `production.desc` file and what are they called?

**Answer:** Two workflows are mentioned in the `production.desc` file. They are called `synchronous-workflow` and `synchronous-workflow-1numa`.

---

**Question:** What are the differences between the `synchronous-workflow` and `synchronous-workflow-1numa` in terms of GPU and NUMA domain usage?

**Answer:** The `synchronous-workflow` utilizes 8 GPUs and operates across 2 NUMA domains, whereas the `synchronous-workflow-1numa` employs only 4 GPUs without NUMA domain pinning.

---

**Question:** What specific conditions must be met for the `synchronous-workflow-1numa` to be fully sufficient, and how does it differ from the `synchronous-workflow` in terms of GPU and NUMA domain usage?

**Answer:** For the `synchronous-workflow-1numa` to be fully sufficient, it must be used for pp (proton-proton) processing. This workflow uses only 4 GPUs without NUMA pinning, which is adequate for pp data processing requirements. In contrast, the `synchronous-workflow` employs 8 GPUs and operates across 2 NUMA domains.

---

**Question:** What are the three modes available in the `run-workflow-on-inputlist.sh` script and what do they do?

**Answer:** The three modes available in the `run-workflow-on-inputlist.sh` script are DD, TF, and CTF.

- **DD Mode:** This mode is used to read raw timeframes using DataDistribution / StfBuilder. It does not support a list of local files as input; instead, it should be used with a few local files via the TF mode.

- **TF Mode:** This mode is used to read raw timeframes using the o2-raw-tf-reader-workflow. It supports a list of files to be processed, which can be provided either as a name of a list-file or a comma-separated list.

- **CTF Mode:** This mode is used to read CTFs using the o2-ctf-reader-workflow. It also supports a list of files, which can be provided as a name of a list-file or a comma-separated list.

---

**Question:** What are the specific steps required to use the DD mode for processing a few local files, and why is the TF mode necessary in this case?

**Answer:** To process a few local files using the DD mode, the TF mode is necessary because DD mode does not support a list of local files as input. Instead, one should use the TF mode, which allows a comma-separated list of files. This is achieved by providing a comma-separated list of file names as the second argument in the command.

---

**Question:** What are the specific conditions under which the DD mode does not support processing a list of local files, and which mode should be used instead to process a few local files?

**Answer:** The DD mode does not support processing a list of local files. To process a few local files instead, the TF mode should be used.

---

**Question:** What happens if no timeout value is provided for the third parameter?

**Answer:** If no timeout value is provided for the third parameter, the processing will not be aborted due to a timeout.

---

**Question:** What is the impact of running the tool in `DD` mode on the StfBuilder, and how should the SHM size be specified?

**Answer:** In `DD` mode, the SHM size for the StfBuilder must be specified in MB, not bytes. This requirement ensures the StfBuilder has sufficient shared memory to operate correctly in distributed mode. The SHM size should be provided using the `DDSHMSIZE` environment variable.

---

**Question:** What is the minimum SHMSIZE value required for the StfBuilder when running in `DD` mode, and in what unit is it specified (MB or bytes)?

**Answer:** The minimum SHMSIZE value required for the StfBuilder when running in `DD` mode is 32000 MB.

---

**Question:** What does the `QC_REDIRECT_MERGER_TO_LOCALHOST=1` option in the qc-workflow.sh script do?

**Answer:** The `QC_REDIRECT_MERGER_TO_LOCALHOST=1` option in the qc-workflow.sh script redirects all messages intended for remote QC mergers to be handled locally instead. This is useful for performing local QC testing without the need to send data to remote servers.

---

**Question:** What is the impact of using the `QC_REDIRECT_MERGER_TO_LOCALHOST=1` option on the communication channels during local testing?

**Answer:** During local testing, using the `QC_REDIRECT_MERGER_TO_LOCALHOST=1` option impacts the communication channels by redirecting all messages intended for remote QC mergers to `localhost`. This ensures that data and messages that would normally be sent to remote machines are instead handled locally, allowing the testing to occur without the need to send data externally. The use of `pub/sub` channels makes this redirection non-blocking, meaning that the workflow can proceed without being held up by the redirection process.

---

**Question:** What specific configuration change is required in the qc-workflow.sh script to ensure that all QC messages intended for remote mergers are instead processed locally during local testing, and how does this affect the behavior of channels in the testing environment?

**Answer:** To ensure that all QC messages intended for remote mergers are instead processed locally during local testing, the specific configuration change required in the qc-workflow.sh script is to set the option `QC_REDIRECT_MERGER_TO_LOCALHOST=1`. This configuration change redirects all messages that would normally be sent to remote machines to `localhost`, effectively routing them for local processing.

In the testing environment, the behavior of channels is non-blocking due to their `pub/sub` nature. This means that when a message is published, it does not wait for a response or acknowledgment; instead, it continues processing without being blocked by the message delivery. As a result, the local processing of messages is seamless and does not interfere with the overall workflow's continuity.