## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/MC/bin/o2dpg_sim_workflow.py

**Start chunk id:** 00b3e3575dc6def81e640978c79dc28a88c2ab122e231c896f07d7f7ed94da6c

## Content

# each timeframe should be processed for a distinct bunch crossing range based on the timeframe identifier
startOrbit = (tf-1 + int(args.production_offset)*NTIMEFRAMES)*orbitsPerTF
globalTFConfigValues = { "HBFUtils.orbitFirstSampled" : args.first_orbit + startOrbit,
                         "HBFUtils.nHBFPerTF" : orbitsPerTF,
                         "HBFUtils.orbitFirst" : args.first_orbit,
                         "HBFUtils.runNumber" : args.run }
# the timestamp is set here only if it is explicitly specified (otherwise, it will be derived from the simulation GRP and digitization)
if (args.sor != -1):
    globalTFConfigValues["HBFUtils.startTime"] = args.sor

---

# detectors serving CTP require special handling as CTP needs these inputs simultaneously; this needs to be improved.
tneeds = [ContextTask['name']]
if includeQED:
     tneeds += [QED_task['name']]
FT0FV0EMCCTPDIGItask = createTask(name="ft0fv0emcctp_digi_" + str(tf), needs=tneeds,
                                     tf=tf, cwd=timeframeworkdir, lab=["DIGI","SMALLDIGI"], cpu='1')
FT0FV0EMCCTPDIGItask['cmd'] = ('','ln -nfs ../bkg_HitsFT0.root . ; ln -nfs ../bkg_HitsFV0.root . ; ln -nfs ../bkg_HitsEMC.root; ln -nfs ../bkg_Kine.root; ')[doembedding]
FT0FV0EMCCTPDIGItask['cmd'] += task_finalizer([
      '${O2_ROOT}/bin/o2-sim-digitizer-workflow', 
      getDPL_global_options(), 
      f'-n {args.ns}', 
      simsoption,
      '--onlyDet FT0,FV0,EMC,CTP', 
      f'--interactionRate {INTRATE}',
      f'--incontext {CONTEXTFILE}',
      f'--store-ctp-lumi {CTPSCALER}',
      '--disable-write-ini',

---

# ===| TPC reco |===
tpcLocalCFreco=dict()

# handle distortion corrections and scaling using MC maps
# this assumes the lumi inside the maps is stored in FT0 (pp) scalers
# for PbPb data, a conversion factor from ZDC to FT0 (pp) must be specified
tpc_corr_options_mc=''

tpcCorrmapLumiMode = args.tpc_corrmap_lumi_mode

---

+ ' --fromCollContext collisioncontext.root:' + signalprefix
   if GENERATOR=="hepmc":
      SGNGENtask['cmd'] += "; RC=$?; ${O2DPG_ROOT}/UTILS/UpdateHepMCEventSkip.sh ../HepMCEventSkip.json " + str(tf) + '; [[ ${RC} == 0 ]]'
   if sep_event_mode == True:
      workflow['stages'].append(SGNGENtask)
      signalneeds.append(SGNGENtask['name'])
   if args.make_evtpool:
      if generationtimeout > 0:
         # final adjustment of the command for event pools and timeout --> we need to check the return code
         # if there is a timeout, we continue processing and accept return code 124
         SGNGENtask['cmd'] += ' ; RC=$? ; [[ ${RC} == 0 || ${RC} == 124 ]]'
      continue

---

# elif GENERATOR == 'extgen': what happens if the generator is not pythia8?
   # NOTE: The setup for the generator might be managed in a separate file or files (one per potential generator).

   workflow['stages'].append(SGN_CONFIG_task)
   
   # default configuration for extkinO2 signal simulation (no transport)
   extkinO2Config = ''
   if GENERATOR == 'extkinO2':
      extkinO2Config = ';GeneratorFromO2Kine.randomize=true;GeneratorFromO2Kine.rngseed=' + str(TFSEED)

   # construct the final configuration key for signal simulation
   CONFKEY = constructConfigKeyArg(create_geant_config(args, args.confKey + extkinO2Config))
   # -----------------
   # transport signals
   # -----------------
   signalneeds=[ SGN_CONFIG_task['name'], GRP_TASK['name'] ]
   signalneeds.append(PreCollContextTask['name'])

---

DOCUMENT:
    SGNGENtask['cmd']=''
   if GENERATOR=="hepmc":
     if tf == 1:
      # calculate the offset number
       eventOffset = environ.get('HEPMCOFFSET')
       print("HEPMCOFFSET: ", eventOffset)
       if eventOffset is None:
        eventOffset = 0
       cmd = 'export HEPMCEVENTSKIP=$(${O2DPG_ROOT}/UTILS/InitHepMCEventSkip.sh ../HepMCEventSkip.json ' + str(eventOffset) + ');'
     elif tf > 1:
       # calculate the skip number
       cmd = 'export HEPMCEVENTSKIP=$(${O2DPG_ROOT}/UTILS/ReadHepMCEventSkip.sh ../HepMCEventSkip.json ' + str(tf) + ');'
     SGNGENtask['cmd'] = cmd

---

sgnmem = 6000 if COLTYPE == 'PbPb' else 4000
SGNtask = createTask(name='sgnsim_'+str(tf), needs=signalneeds, tf=tf, cwd='tf'+str(tf), lab=["GEANT"],
                     relative_cpu=7/8, n_workers=NWORKERS_TF, mem=str(sgnmem))
sgncmdbase = '${O2_ROOT}/bin/o2-sim -e ' + str(SIMENGINE) + ' ' + str(MODULES) + ' -n ' + str(NSIGEVENTS) + ' --seed ' + str(TFSEED)       \
             + ' --field ccdb -j ' + str(NWORKERS_TF) + ' ' + str(CONFKEY) + ' ' + str(INIFILE) + ' -o ' + signalprefix + ' ' + embeddinto       \
             + ('', ' --timestamp ' + str(args.timestamp))[args.timestamp!=-1] + ' --run ' + str(args.run)
if sep_event_mode:
   SGNtask['cmd'] = sgncmdbase + ' -g extkinO2 --extKinFile genevents_Kine.root ' + ' --vertexMode kNoVertex'
else:
   SGNtask['cmd'] = sgncmdbase + ' -g ' + str(GENERATOR) + ' ' + str(TRIGGER) + ' --vertexMode kCCDB '
if not isActive('all'):
   SGNtask['cmd'] += ' --readoutDetectors ' + " ".join(activeDetectors)

---

[
    tpc_corr_scaling_options,
    tpc_corr_options_mc
]
workflow['stages'].append(ITSTPCMATCHtask)

---

if not args.make_evtpool:
   # AOD merging as one final step
   aodmergerneeds = ['aod_' + str(tf) for tf in range(1, NTIMEFRAMES + 1)]
   AOD_merge_task = createTask(name='aodmerge', needs=aodmergerneeds, lab=["AOD"], mem='2000', cpu='1')
   AOD_merge_task['cmd'] = 'set -e ; [ -f aodmerge_input.txt ] && rm aodmerge_input.txt; '
   AOD_merge_task['cmd'] += 'for i in `seq 1 ' + str(NTIMEFRAMES) + '`; do echo "tf${i}/AO2D.root" >> aodmerge_input.txt; done; '
   AOD_merge_task['cmd'] += 'o2-aod-merger --input aodmerge_input.txt --output AO2D.root'
   # generate MonaLisa event statistics file
   AOD_merge_task['cmd'] += ' ; ${O2DPG_ROOT}/MC/bin/o2dpg_determine_eventstat.py'
   AOD_merge_task['alternative_alienv_package'] = "None" # latest software required for this step
   workflow['stages'].append(AOD_merge_task)

---

#<--------- MFT-MCH forward matching
MFTMCHMATCHtask = createTask(name='mftmchMatch_'+str(tf), needs=[MCHMIDMATCHtask['name'], MFTRECOtask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
MFTMCHMATCHtask['cmd'] = task_finalizer(
    ['${O2_ROOT}/bin/o2-globalfwd-matcher-workflow',
     putConfigValues(['ITSAlpideConfig',
                      'MFTAlpideConfig',
                      'FwdMatching'], {"FwdMatching.useMIDMatch": "true"}),
     ('', ' --disable-mc')[args.no_mc_labels]])

if args.fwdmatching_assessment_full == True:
    MFTMCHMATCHtask['cmd'] += ' | '
    MFTMCHMATCHtask['cmd'] += task_finalizer(
        ['${O2_ROOT}/bin/o2-globalfwd-assessment-workflow',
         getDPL_global_options(),
         ('', ' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(MFTMCHMATCHtask)

---

# MCH reco: requiring access to kinematics ... thus some additional logic is needed here
mchreconeeds = [getDigiTaskName("MCH")]
if usebkgcache:
   mchreconeeds += [ BKG_KINEDOWNLOADER_TASK['name'] ]

#<--------- MCH reco workflow
MCHRECOtask = createTask(name='mchreco_'+str(tf), needs=mchreconeeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
MCHRECOtask['cmd'] = ('','ln -nfs ../bkg_Kine.root . ;')[doembedding]
MCHRECOtask['cmd'] += task_finalizer(
   ['${O2_ROOT}/bin/o2-mch-reco-workflow', 
    getDPL_global_options(), 
    putConfigValues(), 
    ('',' --disable-mc')[args.no_mc_labels],
    '--enable-clusters-root-output'])
workflow['stages'].append(MCHRECOtask)

---

#<--------- PHS reconstruction workflow
PHSRECOtask = createTask(name='phsreco_'+str(tf), needs=[getDigiTaskName("PHS")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
PHSRECOtask['cmd'] = task_finalizer([
   '${O2_ROOT}/bin/o2-phos-reco-workflow', 
   getDPL_global_options(), 
   putConfigValues(), 
   ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(PHSRECOtask)

#<--------- CPV reconstruction workflow
CPVRECOtask = createTask(name='cpvreco_'+str(tf), needs=[getDigiTaskName("CPV")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
CPVRECOtask['cmd'] = task_finalizer(
   ['${O2_ROOT}/bin/o2-cpv-reco-workflow', 
    getDPL_global_options(), 
    putConfigValues(), 
    ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(CPVRECOtask)

---

#<---------- primary vertex finding
pvfinder_sources = dpl_option_from_config(anchorConfig,
                                         'o2-primary-vertexing-workflow',
                                         'vertexing-sources',
                                         default_value='ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,FDD,HMP,FV0,TRD,MCH,CTP')
pvfinder_matching_sources = dpl_option_from_config(anchorConfig,
                                                   'o2-primary-vertexing-workflow',
                                                   'vertex-track-matching-sources',
                                                   default_value='ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,FDD,HMP,FV0,TRD,MCH,CTP')
pvfinderneeds = [TRDTRACKINGtask2['name'],

---

### MID
if MID is active:
    addQCPerTF(taskName='MIDTaskQC',
               needs=[MIDRECOtask['name']],
               readerCommand='o2-mid-digits-reader-workflow | o2-mid-tracks-reader-workflow',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mid-task.json')
    
### MCH
if MCH is active:
    addQCPerTF(taskName='MCHDigitsTaskQC',
               needs=[MCHRECOtask['name']],
               readerCommand='o2-mch-digits-reader-workflow',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mch-digits-task.json')
    addQCPerTF(taskName='MCHErrorsTaskQC',
               needs=[MCHRECOtask['name']],
               readerCommand='o2-mch-errors-reader-workflow',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mch-errors-task.json')
    addQCPerTF(taskName='MCHRecoTaskQC',
               needs=[MCHRECOtask['name']])

---

SCDCALIBtask = createTask(name='scdcalib_'+str(tf), needs=[PVFINDERtask['name']], tf=tf, cwd=timeframeworkdir, lab=["CALIB"], mem='4000')
      SCDCALIBtask['cmd'] = task_finalizer(
         [ '${O2_ROOT}/bin/o2-tpc-scdcalib-interpolation-workflow',
           getDPL_global_options(bigshm=True),
           putConfigValues(['scdcalib']),
           '--vtx-sources ' + scdcalib_vertex_sources,
           '--tracking-sources ' + scdcalib_track_sources,
           '--tracking-sources-map-extraction ' + scdcalib_track_extraction,
           '--sec-per-slot 1 ',
           '--send-track-data'
        ])
      workflow['stages'].append(SCDCALIBtask)

---

DOCUMENT:
    addQCPerTF(taskName='ITSTracksClusters',
               needs=[ITSRECOtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS" --cluster-types "ITS"',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/its-clusters-tracks-qc.json')

     ### CPV
     if CPV_isActive():
        addQCPerTF(taskName='CPVDigitsQC',
                   needs=[getDigiTaskName("CPV")],
                   readerCommand='o2-cpv-digit-reader-workflow',
                   configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/cpv-digits-task.json')
        addQCPerTF(taskName='CPVClustersQC',
                   needs=[CPVRECOtask['name']],
                   readerCommand='o2-cpv-cluster-reader-workflow',
                   configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/cpv-clusters-task.json')

---

parser.add_argument('-ptHatMin', help='Minimum pT hard value when no bin is specified', default=0)
parser.add_argument('-ptHatMax', help='Maximum pT hard value when no bin is specified', default=-1)
parser.add_argument('-weightPow', help='Power to flatten the pT hard spectrum', default=-1)

---

DOCUMENT:
    workflow['stages'].append(BKG_CONFIG_task)

        # configuration for background task
        INIBKG=''
        if args.iniBkg != '':
           INIBKG=' --configFile ' + args.iniBkg

        # determine the final configKey values for background transport
        CONFKEYBKG = constructConfigKeyArg(create_geant_config(args, args.confKeyBkg))

---

#<------------- TPC Residuals Aggregator
  scdaggreg_secperslot = dpl_option_from_config(anchorConfig,
                                                'o2-calibration-residual-aggregator',
                                                'sec-per-slot',
                                                default_value='600')
  scdaggreg_outputtype = dpl_option_from_config(anchorConfig,
                                                'o2-calibration-residual-aggregator',
                                                'output-type',
                                                default_value='trackParams,unbinnedResid')

---

# query initial configKey arguments for signal transport; primarily utilized to configure generators
simInitialConfigKeys = create_geant_config(args, args.confKey)

# iterate through timeframes
for tf in range(1, NTIMEFRAMES + 1):
   TFSEED = SIMSEED + tf
   print("Timeframe " + str(tf) + " seed: ", TFSEED)
   timeframeworkdir='tf'+str(tf)

   # ----  transport task -------   
   # generate QED background for PbPb collisions

   QEDdigiargs = ""
   if includeQED:
     qedneeds=[GRP_TASK['name'], PreCollContextTask['name']]
     QED_task=createTask(name='qedsim_'+str(tf), needs=qedneeds, tf=tf, cwd=timeframeworkdir, cpu='1')
     ########################################################################################################
     #
     # CAUTION: MODIFICATIONS TO PARAMETERS/CUTS HERE CAN Invalidate THE QED INTERACTION RATES USED ELSEWHERE
     #
     ########################################################################################################

---

# recalculate the number of workers to enhance CPU efficiency
NWORKERS_TF = compute_n_workers(INTRATE, COLTYPE, n_workers_user = NWORKERS) if (not args.force_n_workers) else NWORKERS

---

# Adjust (residual) geometry alignment for the simulation phase
# Detectors that need special alignments (e.g., to correct residual effects) should be included in this list and download these files.
# These objects will override standard alignments **and** will be applied exclusively during the transport simulation and digitization steps (Det/Calib/Align is read only in the simulation, as reconstruction tasks utilize GLO/Config/AlignedGeometry automatically).
SIM_ALIGNMENT_PREFETCH_TASK = createTask(name='sim_alignment', cpu='0')
SIM_ALIGNMENT_PREFETCH_TASK['cmd'] = '${O2_ROOT}/bin/o2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch -p MID/MisCalib/Align --timestamp ' + str(args.timestamp) + ' --created-not-after '  \
                                      + str(args.condition_not_after) + ' -d ${ALICEO2_CCDB_LOCALCACHE}/MID/Calib/Align --no-preserve-path ; '

---

tpcCorrmapLumiMode = args.tpc_corrmap_lumi_mode

if tpcDistortionType == 0:  # disable distortion corrections
    tpc_corr_options_mc = ' --corrmap-lumi-mode 0 '
    tpcLocalCFreco['TPCCorrMap.lumiMean'] = '-1'
elif tpcDistortionType == 1:  # disable scaling
    tpc_corr_options_mc = ' --corrmap-lumi-mode ' + str(tpcCorrmapLumiMode) + ' '
    tpcLocalCFreco['TPCCorrMap.lumiInst'] = str(CTPSCALER)
    tpcLocalCFreco['TPCCorrMap.lumiMean'] = str(CTPSCALER)
elif tpcDistortionType == 2:  # full scaling with CTP values
    if COLTYPE == 'PbPb':
        tpcLocalCFreco['TPCCorrMap.lumiInstFactor'] = str(lumiInstFactor)
    tpc_corr_options_mc = ' --corrmap-lumi-mode ' + str(tpcCorrmapLumiMode) + ' '
    tpcLocalCFreco['TPCCorrMap.lumiInst'] = str(CTPSCALER)

---

# also generate the stat file with the event count
POOL_merge_task['cmd'] += '; RC=$?; root -l -q -b -e "auto f=TFile::Open(\\\"evtpool.root\\\"); auto t=(TTree*)f->Get(\\\"o2sim\\\"); int n=t->GetEntries(); std::ofstream((\\\"0_0_0_\\\"+std::to_string(n)+\\\".stat\\\").c_str()) << \\\"# MonaLisa stat file for event pools\\\";" ; [[ ${RC} == 0 ]]'
workflow['stages'].append(POOL_merge_task)

---

if includeTPCResiduals:
  print("Adding TPC residuals extraction and aggregation")

  #<------------- TPC residuals extraction
  scdcalib_vertex_sources = dpl_option_from_config(anchorConfig,
                                                   'o2-tpc-scdcalib-interpolation-workflow',
                                                   'vtx-sources',
                                                   default_value='ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,FDD,HMP,FV0,TRD,MCH,CTP')

---

--ptHatMax='+str(PTHATMAX)
         if WEIGHTPOW   > 0:
            SGN_CONFIG_task['cmd'] = SGN_CONFIG_task['cmd'] + ' --weightPow=' + str(WEIGHTPOW)
      # if we set up pythia8 here, we must also update the configuration
      # TODO: we need an appropriate configuration container/manager to integrate these local configurations with external ones, etc.
      args.confKey = args.confKey + ";GeneratorPythia8.config=pythia8.cfg"

---

#<--------- MID reconstruction workflow
MIDRECOtask = createTask(name='midreco_'+str(tf), needs=[getDigiTaskName("MID")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
MIDRECOtask['cmd'] = task_finalizer(
   ['${O2_ROOT}/bin/o2-mid-digits-reader-workflow',
    ('',' --disable-mc')[args.no_mc_labels]])
MIDRECOtask['cmd'] += ' | '
MIDRECOtask['cmd'] += task_finalizer(['${O2_ROOT}/bin/o2-mid-reco-workflow', 
                                      getDPL_global_options(), 
                                      putConfigValues(),('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(MIDRECOtask)

---

DOCUMENT:
    anchor_lumi_type = dpl_option_from_config(anchorConfig, 'o2-tpcits-match-workflow', '--lumi-type', section = 'full', default_value = '')
   if anchor_lumi_type != '':
      anchor_lumi_type = '--lumi-type ' + anchor_lumi_type
   anchor_corrmaplumi_mode = dpl_option_from_config(anchorConfig, 'o2-tpcits-match-workflow', '--corrmap-lumi-mode', section = 'full', default_value = '')
   if anchor_corrmaplumi_mode != '':
      anchor_corrmaplumi_mode = '--corrmap-lumi-mode ' + anchor_corrmaplumi_mode
   
   tpc_corr_scaling_options = anchor_lumi_type + ' ' + anchor_corrmaplumi_mode
   
   # why not simplify it to:
   # tpc_corr_scaling_options = '--lumi-type 1' if tpcDistortionType != 0 else ''

---

# We might still need to manually adjust configurations for consistency:
#
# * Force simpler TPC digitization if TPC reconstruction lacks the mc-time-gain option:
async_envfile = 'env_async.env' if environ.get('ALIEN_JDL_O2DPG_ASYNC_RECO_TAG') is not None else None
tpcreco_mctimegain = option_if_available('o2-tpc-reco-workflow', '--tpc-mc-time-gain', envfile=async_envfile)
if tpcreco_mctimegain == '':
   # This was informed by Jens Wiechula@TPC; it addresses the dEdX issue https://its.cern.ch/jira/browse/O2-5486 related to the 2tag mechanism
   print ("TPC reconstruction does not support --tpc-mc-time-gain. Adjusting some configurations for TPC digitization")
   overwrite_config(anchorConfig['ConfigParams'],'TPCGasParam','OxygenCont',5e-6)
   overwrite_config(anchorConfig['ConfigParams'],'TPCGEMParam','TotalGainStack',2000)
   overwrite_config(anchorConfig['ConfigParams'],'GPU_global','dEdxDisableResidualGain',1)
# TODO: encapsulate this in a function for better modularity

---

DOCUMENT:
    SGNtask['cmd'] += ' --readoutDetectors ' + " ".join(activeDetectors)
   
   SGNtask['cmd'] += ' --fromCollContext collisioncontext.root'
   workflow['stages'].append(SGNtask)

---

parser.add_argument('-interactionRate',help='Rate of interactions used in digitization', default=-1)
parser.add_argument('-bcPatternFile',help='File containing bunch crossing pattern for digitization (a file name or "ccdb")', default='')
parser.add_argument('-meanVertexPerRunTxtFile',help='Text file with mean vertex settings per run', default='')
parser.add_argument('-eCM',help='Center-of-mass energy', default=-1)
parser.add_argument('-eA',help='Energy of beam A', default=-1) #6369 PbPb, 2.510 pp 5 TeV, 4 pPb
parser.add_argument('-eB',help='Energy of beam B', default=-1)
parser.add_argument('-col',help='Collision system: pp, PbPb, pPb, Pbp, etc. Specify if embedding a different collision system for the signal', default='pp')
parser.add_argument('-field',help='L3 magnetic field strength rounded to kGauss; allowed values: +-2, +-5, 0; +-5U for uniform field; or "ccdb" to fetch from conditions database', default='ccdb')
parser.add_argument('--with-qed',action='store_true', help='Include QED background contribution (always included for PbPb)')

---

(' --combine-devices','')[args.no_combine_dpl_devices],
tpc_corr_scaling_options,
tpc_corr_options_mc
]
TOFTPCMATCHERtask['cmd'] = task_finalizer(tofmatcher_cmd_parts)
workflow['stages'].append(TOFTPCMATCHERtask)

---

#!/usr/bin/env python3

#BEGIN DOCUMENT

#BEGIN PARAPHRASE

---

# apply overrides
for e in localCF:
    cf[e] = localCF[e]

for e in cf:
    returnstring += (';', '')[isfirst] + str(e) + "=" + str(cf[e])
    isfirst = False

returnstring = returnstring + '"'
return returnstring

# parsing passName from environment variable
PASSNAME = '${ALIEN_JDL_LPMANCHORPASSNAME:-unanchored}'

---

+ ' ' + putConfigValues({"DigiParams.maxOrbitsToDigitize" : str(orbitsPerTF)},{"DigiParams.passName" : str(PASSNAME)}) \
                        + ' --incontext ' + CONTEXTFILE + QEDdigiargs
   ContextTask['cmd'] += ' --bcPatternFile ccdb'
   workflow['stages'].append(ContextTask)

---

#<--------- TOF-TPC(-ITS) global track matcher workflow
toftpcmatchneeds = [TOFRECOtask['name'], TPCRECOtask['name'], ITSTPCMATCHtask['name'], TRDTRACKINGtask2['name']]
toftracksrcdefault = dpl_option_from_config(anchorConfig, 'o2-tof-matcher-workflow', 'track-sources', default_value='TPC,ITS-TPC,TPC-TRD,ITS-TPC-TRD')
TOFTPCMATCHERtask = createTask(name='toftpcmatch_'+str(tf), needs=toftpcmatchneeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1000')
tofmatcher_cmd_parts = [
  '${O2_ROOT}/bin/o2-tof-matcher-workflow',
  getDPL_global_options(),
  putConfigValues(['ITSClustererParam',
                   'TPCGasParam',
                   'TPCCorrMap',
                   'ITSCATrackerParam',
                   'MFTClustererParam',
                   'GPU_rec_tpc',
                   'trackTuneParams'], tpcLocalCFreco),
  ' --track-sources ' + toftracksrcdefault,
  (' --combine-devices','')[args.no_combine_dpl_devices],

---

pvfinderneeds = [TRDTRACKINGtask2['name'], 
                 FT0RECOtask['name'], 
                 FV0RECOtask['name'], 
                 EMCRECOtask['name'], 
                 PHSRECOtask['name'], 
                 CPVRECOtask['name'], 
                 FDDRECOtask['name'], 
                 ZDCRECOtask['name'], 
                 HMPMATCHtask['name'], 
                 HMPMATCHtask['name'], 
                 ITSTPCMATCHtask['name'], 
                 TOFTPCMATCHERtask['name'], 
                 MFTMCHMATCHtask['name'], 
                 MCHMIDMATCHtask['name']]

---

#<--------- FV0 reconstruction workflow
FV0RECOtask = createTask(name='fv0reco_'+str(tf), requires=[getDigiTaskName("FV0")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
FV0RECOtask['cmd'] = task_finalizer(['${O2_ROOT}/bin/o2-fv0-reco-workflow', 
                                     getDPL_global_options(), 
                                     putConfigValues(),
                                     ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(FV0RECOtask)

---

# determine the final configuration key for QED simulation
QEDBaseConfig = "GeneratorExternal.fileName=$O2_ROOT/share/Generators/external/QEDLoader.C;QEDGenParam.yMin=-7;QEDGenParam.yMax=7;QEDGenParam.ptMin=0.001;QEDGenParam.ptMax=1.;QEDGenParam.xSectionHad="+str(XSecSys[COLTYPE])+";QEDGenParam.Z="+str(Zsys[COLTYPE])+";QEDGenParam.cmEnergy="+str(ECMS)+";Diamond.width[2]=6."
QEDCONFKEY = constructConfigKeyArg(create_geant_config(args, QEDBaseConfig + args.confKeyQED))

---

SIM_ALIGNMENT_PREFETCH_TASK['cmd'] += '${O2_ROOT}/bin/o2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch -p MCH/MisCalib/Align --timestamp ' + str(args.timestamp) + ' --created-not-after ' + str(args.condition_not_after) + ' -d ${ALICEO2_CCDB_LOCALCACHE}/MCH/Calib/Align --no-preserve-path '
workflow['stages'].append(SIM_ALIGNMENT_PREFETCH_TASK)

---

readerCommand='o2-ft0-recpoints-reader-workflow --infile o2reco_ft0.root',
                configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/ft0-reconstruction-config.json')

---

# the run number for data taking or a default if not specified
parser.add_argument('-run', type=int, help="Specify the run number for this Monte Carlo simulation. Refer to https://twiki.cern.ch/twiki/bin/view/ALICE/O2DPGMCSamplingSchema for predefined choices.", default=300000)
parser.add_argument('-productionTag',help="Tag for the production of this Monte Carlo simulation", default='unknown')
# the timestamp when this Monte Carlo workflow will be executed
# - should ideally align with the "run" number above
# - an external tool can sample it, or we can sample it here
parser.add_argument('--timestamp', type=int, help="The anchoring timestamp (defaults to current time)", default=-1)
parser.add_argument('--conditionDB',help="URL for CCDB for QC workflows", default='http://alice-ccdb.cern.ch')
parser.add_argument('--qcdbHost',help="URL for uploading QC objects", default='http://ali-qcdbmc-gpn.cern.ch:8083')

---

parser.add_argument('--run-anchored', action='store_true', help=argparse.SUPPRESS)
parser.add_argument('--alternative-reco-software', default="", help=argparse.SUPPRESS) # an advanced feature to specify the CVFMS alienv software version for reconstruction steps, distinct from the default setting
parser.add_argument('--dpl-child-driver', default="", help="The child driver to employ in DPL processes (for expert users)")
parser.add_argument('--event-gen-mode', choices=['separated', 'integrated'], default='separated', help="Indicates whether event generation occurs prior to (separated) or within the detector simulation (integrated).")

---

# Training alignment for machine learning
parser.add_argument('--fwdmatching-save-trainingdata', action='store_true', help='enables the saving of parameters at each plane for machine learning training')

args = parser.parse_args()
print (args)

# Ensure that O2DPG and O2 are loaded
O2DPG_ROOT=environ.get('O2DPG_ROOT')
O2_ROOT=environ.get('O2_ROOT')
QUALITYCONTROL_ROOT=environ.get('QUALITYCONTROL_ROOT')
O2PHYSICS_ROOT=environ.get('O2PHYSICS_ROOT')

if O2DPG_ROOT is None:
   print('Error: This requires O2DPG to be loaded')
#   exit(1)

if O2_ROOT is None:
   print('Error: This requires O2 to be loaded')
#   exit(1)

if (args.include_qc or args.include_local_qc) and QUALITYCONTROL_ROOT is None:
   print('Error: The arguments --include-qc and --include-local-qc require QUALITYCONTROL_ROOT to be loaded')
#   exit(1)

if args.include_analysis and (QUALITYCONTROL_ROOT is None or O2PHYSICS_ROOT is None):
   print('Error: The argument --include-analysis requires both O2PHYSICS_ROOT and QUALITYCONTROL_ROOT to be loaded')
#   exit(1)

---

#<--------- ITS reconstruction task 
ITSMemEstimate = 12000 if havePbPb else 2000 # PbPb requires significantly more memory (in worst case)
ITSRECOtask = createTask(name='itsreco_'+str(tf), needs=[getDigiTaskName("ITS")],
                         tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu='1', mem=str(ITSMemEstimate))  
ITSRECOtask['cmd'] = task_finalizer([
  "${O2_ROOT}/bin/o2-its-reco-workflow",
  getDPL_global_options(bigshm=havePbPb),
  '--trackerCA',
  '--tracking-mode async',
  putConfigValues(["ITSVertexerParam", 
                   "ITSAlpideParam",
                   "ITSClustererParam", 
                   "ITSCATrackerParam"], 
                  {"NameConf.mDirMatLUT" : ".."}),
  ('',' --disable-mc')[args.no_mc_labels]
])
workflow['stages'].append(ITSRECOtask)

---

# MFT reco: requiring access to kinematics (when assessment is enabled)
mftreconeeds = [getDigiTaskName("MFT")]
if usebkgcache:
    mftreconeeds += [ BKG_KINEDOWNLOADER_TASK['name'] ]

#<--------- MFT reco workflow
MFTRECOtask = createTask(name='mftreco_'+str(tf), needs=mftreconeeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
MFTRECOtask['cmd'] = ('','ln -nfs ../bkg_Kine.root . ;')[doembedding]
MFTRECOtask['cmd'] += task_finalizer([
   '${O2_ROOT}/bin/o2-mft-reco-workflow', 
   getDPL_global_options(), 
   putConfigValues(['MFTTracking', 
                    'MFTAlpideParam', 
                    'ITSClustererParam',
                    'MFTClustererParam']),
   ('','--disable-mc')[args.no_mc_labels],
   ('','--run-assessment')[args.mft_assessment_full]])
workflow['stages'].append(MFTRECOtask)

---

if det=='ALLSMALLER': # combining all smaller digits into a single DPL workflow
    if usebkgcache:
        for d in itertools.chain(smallsensorlist, ctp_trigger_inputlist):
            tneeds += [ BKG_HITDOWNLOADER_TASKS[d]['name'] ]
    t = createTask(name=name, needs=tneeds,
                   tf=tf, cwd=timeframeworkdir, lab=["DIGI","SMALLDIGI"], cpu='1')
    t['cmd'] = ('','ln -nfs ../bkg_Hits*.root . ;')[doembedding]
    detlist = ''
    detlist = ','.join(smallsensorlist)
    t['cmd'] += commondigicmd + ' --onlyDet ' + detlist
    t['cmd'] += ' --ccdb-tof-sa --forceSelectedDets '
    t['cmd'] += (' --combine-devices ','')[args.no_combine_dpl_devices]
    t['cmd'] += ('',' --disable-mc')[args.no_mc_labels]
    workflow['stages'].append(t)
    return t

---

# identify the start of the run, earlier values are prioritized (refer to BasicCCDBManager::getRunDuration for more details)
STF=0
# extract SOR using pattern matching
for t in tokens:
  match_obj=re.match(r"\s*(STF\s*=\s*)([0-9]*)\s*", t)
  if match_obj != None:
    STF=int(match_obj[2])
    break
if STF > 0:
  return STF

SOX=0
# extract SOX using pattern matching
for t in tokens:
  match_obj=re.match(r"\s*(STF\s*=\s*)([0-9]*)\s*", t)
  if match_obj != None:
    SOX=int(match_obj[2])
    break
if SOX > 0:
  return SOX

SOR=0
# extract SOR using pattern matching
for t in tokens:
  match_obj=re.match(r"\s*(SOR\s*=\s*)([0-9]*)\s*", t)
  if match_obj != None:
    SOR=int(match_obj[2])
    break
    
return SOR

---

DOCUMENT:
    dump_workflow(workflow['stages'], output_file=args.o, meta=vars(args))

# save a configuration to allow reproduction of this workflow
task_finalizer.dump_collected_config(config_file="final_config.json")

exit(0)

---

DOCUMENT:
    PreCollContextTask['cmd'] += ' --bcPatternFile ccdb'  # <--- the object should have been set in (local) CCDB
if includeQED:
   if PDGA==2212 or PDGB==2212:
      # QED is not supported in pp and pA collisions
      print('o2dpg_sim_workflow: Warning! QED is not supported in pp or pA collisions')
      includeQED = False
   else:
      qedrate = INTRATE * QEDXSecExpected[COLTYPE] / XSecSys[COLTYPE]   # hadronic interaction rate * cross_section_ratio
      qedspec = 'qed' + ',' + str(qedrate) + ',10000000:' + str(NEventsQED)
      PreCollContextTask['cmd'] += ' --QEDinteraction ' + qedspec
workflow['stages'].append(PreCollContextTask)


if doembedding:
    if not usebkgcache:
        # ---- handle background transport task ----
        NBKGEVENTS=args.nb
        GENBKG=args.genBkg
        if GENBKG =='':
           print('o2dpg_sim_workflow: Error! background generator name for embedding not provided')
           exit(1)

---

elif 'MCH' is active and 'MFT' is active :
    addQCPerTF(taskName='MCHMFTTaskQC',
               needs=[MFTMCHMATCHtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "MCH,MFT,MFT-MCH" --cluster-types "MCH,MFT"',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mftmch-tracks-task.json')

---

BKG_HITDOWNLOADER_TASKS={}
for sensor in [ 'TPC', 'TRD' ] + smallsensorlist + ctp_trigger_inputlist:
   if usebkgcache:
      BKG_HITDOWNLOADER_TASKS[sensor] = createTask(str(sensor) + 'hitdownload', cpu='0', lab=['BKGCACHE'])
      BKG_HITDOWNLOADER_TASKS[sensor]['cmd'] = 'alien.py cp ' + args.use_bkg_from + 'bkg_Hits' + str(sensor) + '.root .'
      workflow['stages'].append(BKG_HITDOWNLOADER_TASKS[sensor])
   else:
      BKG_HITDOWNLOADER_TASKS[sensor] = None

if usebkgcache:
   BKG_KINEDOWNLOADER_TASK = createTask(name='bkgkinedownload', cpu='0', lab=['BKGCACHE'])
   BKG_KINEDOWNLOADER_TASK['cmd'] = 'alien.py cp ' + args.use_bkg_from + 'bkg_Kine.root .'
   workflow['stages'].append(BKG_KINEDOWNLOADER_TASK)

# Some binary files are downloaded for processing.
# These files/objects might eventually be queried directly within these tasks.

---

#<--------- TOF reconstruction task
TOFRECOtask = createTask(name='tofmatch_'+str(tf), needs=[ITSTPCMATCHtask['name'], getDigiTaskName("TOF")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
TOFRECOtask["cmd"] = task_finalizer([
    '${O2_ROOT}/bin/o2-tof-reco-workflow',
    getDPL_global_options(),
    '--use-ccdb',
    putConfigValues(),
    ('',' --disable-mc')[args.no_mc_labels]
])
workflow['stages'].append(TOFRECOtask)

---

# parameters for background event storage
parser.add_argument('--upload-bkg-to', help='destination for uploading background event files (alien path)')
parser.add_argument('--use-bkg-from', help='use background events from the specified alien path')

# option for early cleanup
parser.add_argument('--early-tf-cleanup', action='store_true', help='flag to cleanup interim products after each timeframe')

---

#<--------- TPC reconstruction task
TPCRECOtask = createTask(name='tpcreco_' + str(tf), needs=tpcreconeeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], relative_cpu=3/8, mem='16000')
TPCRECOtask['cmd'] = task_finalizer([
  '${O2_ROOT}/bin/o2-tpc-reco-workflow',
  getDPL_global_options(bigshm=True),
  '--input-type clusters',
  '--output-type tracks,send-clusters-per-sector',
  putConfigValues(["GPU_global",
                   "TPCGasParam", 
                   "TPCCorrMap", 
                   "GPU_rec_tpc", 
                   "trackTuneParams"], 
                   {"GPU_proc.ompThreads":NWORKERS_TF} | tpcLocalCFreco),
  ('',' --disable-mc')[args.no_mc_labels],
  tpc_corr_scaling_options, 
  tpc_corr_options_mc,
  tpcreco_mctimegain])
workflow['stages'].append(TPCRECOtask)

---

DOCUMENT:
    GRP_TASK['cmd'] += ' --readoutDets ' + " ".join(activeDetectors) + ' --print ' + ('','--lhcif-CCDB')[args.run_anchored]
if (args.run_anchored != True) and len(args.bcPatternFile) > 0:
    GRP_TASK['cmd'] += ' --bcPatternFile ' + str(args.bcPatternFile)
if len(CONFKEYMV) > 0:
    # this allows the possibility to use a different MeanVertex object than the one from CCDB
    GRP_TASK['cmd'] += ' --vertex Diamond --configKeyValues "' + CONFKEYMV + '"'

---

parser.add_argument('--first-orbit', default=256, type=int, help=argparse.SUPPRESS)  # to define the initial orbit number for HBFUtils (only utilized when anchoring); set to 256 by default for convenience to accommodate some early orbits
                                                                                     # (it might be better to handle this directly in the O2 digitization code)
parser.add_argument('--orbits-early', default=1, type=float, help=argparse.SUPPRESS) # specifies the number of orbits to begin simulating earlier
                                                                                     # to minimize the impact of the start of the timeframe in MC --> influences the collision context
parser.add_argument('--sor', default=-1, type=int, help=argparse.SUPPRESS) # may be used to specify the start of the run (autodetermined otherwise from the run number)
parser.add_argument('--run-anchored', action='store_true', help=argparse.SUPPRESS)

---

"--
    "--disable-mc" if args.no_mc_labels else "",
    "--enable-truncation 0" if environ.get("O2DPG_AOD_NOTRUNCATE") or environ.get("ALIEN_JDL_O2DPG_AOD_NOTRUNCATE") else "",
    "--disable-strangeness-tracker" if args.no_strangeness_tracking else "",
    f"--aod-timeframe-id ${{ALIEN_PROC_ID}}{aod_df_id}" if not args.run_anchored else "",
]
# For future consideration: AODtask['disable_alternative_reco_software'] = True # do not apply reco software here (we prefer the latest aod converter)
workflow['stages'].append(AODtask)

---

if the TOF and TRD are active:
    add a quality control per trigger frame with the task name 'TOFMatchWithTRDQC',
    requiring [TOFTPCMATCHERtask['name']],
    using the command 'o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC,ITS-TPC-TRD,ITS-TPC-TRD-TOF,TPC-TRD,TPC-TRD-TOF" --cluster-types none',
    and referencing the configuration file at 'json://${O2DPG_ROOT}/MC/config/QC/json/tofMatchedTracks_AllTypes_direct_MC.json'.

    ### ITS
    add a quality control per trigger frame with the task name 'ITSTrackSimTask',
    requiring [ITSRECOtask['name']],
    using the command 'o2-global-track-cluster-reader --track-types "ITS" --cluster-types "ITS"',
    and referencing the configuration file at 'json://${O2DPG_ROOT}/MC/config/QC/json/its-mc-tracks-qc.json'.

---

DOCUMENT:
    SCDAGGREGtask = createTask(name='scdaggreg_'+str(tf), needs=[SCDCALIBtask['name']], tf=tf, cwd=timeframeworkdir, lab=["CALIB"], mem='1500')
      SCDAGGREGtask['cmd'] = task_finalizer(
         [ '${O2_ROOT}/bin/o2-calibration-residual-aggregator',
           getDPL_global_options(bigshm=True),
           '--sec-per-slot ' + scdaggreg_secperslot,
           '--enable-ctp ',
           '--enable-track-input',
           '--output-dir ./',
           '--output-type ' +  scdaggreg_outputtype,
           '--meta-output-dir /dev/null'
         ])
      workflow['stages'].append(SCDAGGREGtask)

   # conditional
   #
   # QC tasks follow
   #

   if includeFullQC or includeLocalQC:

     def addQCPerTF(taskName, needs, readerCommand, configFilePath, objectsFile=''):
       task = createTask(name=taskName + '_local' + str(tf), needs=needs, tf=tf, cwd=timeframeworkdir, lab=["QC"], cpu=1, mem='2000')
       objectsFile = objectsFile if len(objectsFile) > 0 else taskName + '.root'

---

# ------------------
# Digitization Steps
# ------------------
CONTEXTFILE='collisioncontext.root'

# Determine interaction rate, which should be taken from CDB; otherwise, use default values.
INTRATE=int(args.interactionRate)
BCPATTERN=args.bcPatternFile

# For embedding, use the intended background collision type rather than the signal.
COLTYPEIR=COLTYPE
if doembedding:
   COLTYPEIR=args.colBkg

if INTRATE < 0:
   if COLTYPEIR=="PbPb":
      INTRATE=50000 #Hz
   elif COLTYPEIR=="pp":
      INTRATE=500000 #Hz
   else: #pPb?
      INTRATE=200000 #Hz ???

# TOF -> "--use-ccdb-tof" (alternatively, use CCCDBManager "--ccdb-tof-sa")
simsoption=' --sims ' + ('bkg,'+signalprefix if doembedding else signalprefix)

---

DOCUMENT:
    # If the beam energy B has not been set, assign it the value of beam energy A.
        if EBEAMBBKG < 0 and ECMSBKG < 0:
           EBEAMBBKG=EBEAMABKG
           print('o2dpg_sim_workflow: Beam energy in A and B beams set to be the same')
           if PDGABKG != PDGBBKG:
              print('o2dpg_sim_workflow: Warning! Different background beams have different beam energies!')

        if ECMSBKG > 0:
           if PDGABKG != PDGBBKG:
              print('o2dpg_sim_workflow: Warning! ECM set for different background beams!')

        if ECMSBKG < 0 and EBEAMABKG < 0 and EBEAMBBKG < 0:
           print('o2dpg_sim_workflow: Error! ECM or beam energy not set for background beams!!!')
           exit(1)

---

# TODO: update the Xsection ratio dynamically
QEDdigiargs=' --simPrefixQED qed' + ' --qed-x-section-ratio ' + str(QEDXSecExpected[COLTYPE]/XSecSys[COLTYPE])
workflow['stages'].append(QED_task)

---

#<------------- AOD producer
# TODO This section requires additional refinement; sources and dependencies should be dynamically constructed.
aod_info_sources_default = 'ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,ZDC,FDD,HMP,FV0,TRD,MCH,CTP'
aodinfosources = dpl_option_from_config(anchorConfig, 'o2-aod-producer-workflow', 'info-sources', default_value=aod_info_sources_default)
aodneeds = [PVFINDERtask['name'], SVFINDERtask['name']]

if usebkgcache:
  aodneeds += [ BKG_KINEDOWNLOADER_TASK['name'] ]

aod_df_id = '{0:03}'.format(tf)

---

DOCUMENT:
    tpcclussect['cmd'] = ((digitmergerstr,'')[args.no_tpc_digitchunking] + ' ${O2_ROOT}/bin/o2-tpc-reco-workflow ' + getDPL_global_options(bigshm=True) + ' --input-type ' + ('digitizer','digits')[args.no_tpc_digitchunking] + ' --output-type clusters,send-clusters-per-sector --tpc-native-cluster-writer \" --outfile tpc-native-clusters-part'+ str((int)(s/sectorpertask)) + '.root\" --tpc-sectors ' + str(s)+'-'+str(s+sectorpertask-1) + ' ' + putConfigValues(["GPU_global"], {"GPU_proc.ompThreads" : 4}) + ('',' --disable-mc')[args.no_mc_labels])
    tpcclussect['env'] = { "OMP_NUM_THREADS" : "4" , "TBB_NUM_THREADS" : "4" }
    tpcclussect['semaphore'] = "tpctriggers.root"
    tpcclussect['retry_count'] = 2  # the task has a race condition, hence it's sensible to retry
    workflow['stages'].append(tpcclussect)

---

#<--------- FT0 reconstruction task 
FT0RECOtask = createTask(name='ft0reco_'+str(tf), needs=[getDigiTaskName("FT0")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1000')
FT0RECOtask["cmd"] = task_finalizer([
     '${O2_ROOT}/bin/o2-ft0-reco-workflow',
     getDPL_global_options(ccdbbackend=False), # note: when calibrations (or CCDB objects) are reenabled, we need to set ccdbbackend=True
     '--disable-time-offset-calib', # as the effect is not simulated in MC
     '--disable-slewing-calib', # and the effect is also not simulated in MC
     putConfigValues()
   ])
workflow['stages'].append(FT0RECOtask)

---

def putConfigValues(listOfMainKeys=[], localCF = {}):
    """
    Generates the final --configValues string to be passed to the workflows by utilizing globalTFConfigValues and additional parameters.
    listOfMainKeys : a list of keys to be applied from the global configuration object.
    localCF: a dictionary that maps keys to parameters, potentially overriding settings from the global config.
    """
    returnstring = ' --configKeyValues "'
    cf = globalTFConfigValues.copy()
    isfirst=True

    # now include the relevant keys
    # from the external config
    for key in listOfMainKeys:
        # attempt to find the key directly in the dictionary (backward compatible)
        keydict = anchorConfig.get(key)
        if keydict is None:
            # otherwise, look under the ConfigurableKey entry (standard)
            keydict = anchorConfig.get("ConfigParams",{}).get(key)
        if keydict is not None:
            for k in keydict:
                cf[key+"."+k] = keydict[k]

---

DOCUMENT:
    PVFINDERtask = createTask(name='pvfinder_'+str(tf), needs=pvfinderneeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu=NWORKERS_TF, mem='4000')
    PVFINDERtask['cmd'] = task_finalizer(
        [ '${O2_ROOT}/bin/o2-primary-vertexing-workflow', 
          getDPL_global_options(),
          putConfigValues(['ITSAlpideParam',
                           'MFTAlpideParam', 
                           'pvertexer', 
                           'TPCGasParam', 
                           'TPCCorrMap', 
                           'ft0tag'], 
                          {"NameConf.mDirMatLUT" : ".."}),
          '--vertexing-sources ' + pvfinder_sources,
          '--vertex-track-matching-sources ' + pvfinder_matching_sources,
          (' --combine-source-devices','')[args.no_combine_dpl_devices],
          ('',' --disable-mc')[args.no_mc_labels]
        ])
    workflow['stages'].append(PVFINDERtask)

---

def strip_json_prefix(path):
    return re.sub(r'^json://', '', path)

---

if args.fwdmatching_save_trainingdata == True:
  MFTMCHMATCHTraintask = createTask(name='mftmchMatchTrain_'+str(tf), needs=[MCHMIDMATCHtask['name'], MFTRECOtask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
  MFTMCHMATCHTraintask['cmd'] = '${O2_ROOT}/bin/o2-globalfwd-matcher-workflow ' + putConfigValues(['ITSAlpideConfig','MFTAlpideConfig'],{"FwdMatching.useMIDMatch":"true"})
  MFTMCHMATCHTraintask['cmd'] += getDPL_global_options()
  workflow['stages'].append(MFTMCHMATCHTraintask)

  # HMP tasks
  #<--------- HMP forward matching
  HMPRECOtask = createTask(name='hmpreco_'+str(tf), needs=[getDigiTaskName('HMP')], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1000')
  HMPRECOtask['cmd'] = task_finalizer(
    ['${O2_ROOT}/bin/o2-hmpid-digits-to-clusters-workflow', 
     getDPL_global_options(ccdbbackend=False), 
     putConfigValues()])
  workflow['stages'].append(HMPRECOtask)

---

# prepare the collision context/timeframe structure for all timeframes at once
precollneeds=[GRP_TASK['name']]
# specify the maximum number of QED events to be simulated per timeframe.
# A significant pool of QED events (0.6*INTRATE) is essential to prevent repetition in the same or adjacent ITS readout frames, thus avoiding the activation of already fired pixels and discarding the event.
# This approach is detailed in https://its.cern.ch/jira/browse/O2-5861
NEventsQED = max(10000, int(INTRATE*0.6))
# hadronic cross section values are derived from Glauber MC
XSecSys = {'PbPb': 8., 'OO': 1.273, 'NeNe': 1.736}
# QED cross section values were determined using TEPEMGEN
# These values pertain to OO and NeNe at 5.36 TeV, whereas the older PbPb value remains unchanged.
# If the collision energy alters, these values must be updated.
# Further information on the calculation can be found in the TEPEMGEN directory of AEGIS, specifically in the epemgen.f file.

---

--output=pythia8.cfg                                      \
                                  --seed='+str(TFSEED)+'                                    \
                                  --idA='+str(PDGA)+'                                       \
                                  --idB='+str(PDGB)+'                                       \
                                  --eCM='+str(ECMS)+'                                       \
                                  --eA='+str(EBEAMA)+'                                      \
                                  --eB='+str(EBEAMB)+'                                      \
                                  --process='+str(PROCESS)+'                                \
                                  --ptHatMin='+str(PTHATMIN)+'                              \
                                  --ptHatMax='+str(PTHATMAX)
         if WEIGHTPOW   > 0:

---

# calorimeters
#<--------- EMC reco workflow
EMCRECOtask = createTask(name='emcalreco_'+str(tf), needs=[getDigiTaskName("EMC")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
# initial step
EMCRECOtask['cmd'] = task_finalizer([
   '${O2_ROOT}/bin/o2-emcal-reco-workflow', 
   putConfigValues(),
   '--input-type digits',
   '--output-type cells', 
   '--infile emcaldigits.root',
   '--disable-root-output', 
   '--subspecificationOut 1',
   ('',' --disable-mc')[args.no_mc_labels]])
# intermediate step
EMCRECOtask['cmd'] += ' | ' 
EMCRECOtask['cmd'] += task_finalizer([
   '${O2_ROOT}/bin/o2-emcal-cell-recalibrator-workflow', 
   putConfigValues(),
   '--input-subspec 1', 
   '--output-subspec 0',
   '--no-timecalib', 
   '--no-gaincalib',
   (' --isMC','')[args.no_mc_labels]])
# final step
EMCRECOtask['cmd'] += ' | ' 
EMCRECOtask['cmd'] += task_finalizer([

---

DOCUMENT:
    workflow={}
    workflow['stages'] = []

### Establish global environment variables applicable to all tasks
global_env = {'ALICEO2_CCDB_CONDITION_NOT_AFTER': args.condition_not_after} if args.condition_not_after else None
globalinittask = createGlobalInitTask(global_env)
globalinittask['cmd'] = 'o2-ccdb-cleansemaphores -p ${ALICEO2_CCDB_LOCALCACHE}'
workflow['stages'].append(globalinittask)
####

usebkgcache=args.use_bkg_from!=None
includeFullQC=args.include_qc=='True' or args.include_qc==True
includeLocalQC=args.include_local_qc=='True' or args.include_local_qc==True
includeAnalysis = args.include_analysis
includeTPCResiduals=True if environ.get('ALIEN_JDL_DOTPCRESIDUALEXTRACTION') == '1' else False
ccdbRemap = environ.get('ALIEN_JDL_REMAPPINGS')

qcdir = "QC"
if (includeLocalQC or includeFullQC) and not isdir(qcdir):
    mkdir(qcdir)

---

workflow['stages'].append(tpcclus)
tpcreconeeds.append(tpcclus['name'])

---

### PHS
if the PHS is active:
    include quality control per trigger frame with the task name 'PHSCellsClustersQC',
    which depends on the task named [PHSRECOtask['name']],
    using the command 'o2-phos-reco-workflow --input-type cells --output-type clusters --disable-mc --disable-root-output' for the reader,
    and configure it with the file 'json://${O2DPG_ROOT}/MC/config/QC/json/phs-cells-clusters-task.json'.

---

def getDPL_global_options(bigshm=False, ccdbbackend=True):
    common=" -b --run "
    if len(args.dpl_child_driver) > 0:
        common=common + ' --child-driver ' + str(args.dpl_child_driver)
    if ccdbbackend:
        common=common + " --condition-not-after " + str(args.condition_not_after)
        if ccdbRemap != None:
            common=common + " --condition-remap " + ccdbRemap
    if args.noIPC!=None:
        return common + " --no-IPC "
    if bigshm:
        return common + " --shm-segment-size ${SHMSIZE:-50000000000} "
    else:
        return common
    
# prepare and publish the GRPs and other GLO objects for consistent usage later in the pipeline
orbitsPerTF=int(args.orbitsPerTF)
GRP_TASK = createTask(name='grpcreate', cpu='0')
GRP_TASK['cmd'] = 'o2-grp-simgrp-tool createGRPs --timestamp ' + str(args.timestamp) + ' --run ' + str(args.run) + ' --publishto ${ALICEO2_CCDB_LOCALCACHE:-.ccdb} -o grp --hbfpertf ' + str(orbitsPerTF) + ' --field ' + args.field

---

# CLEANUP
# --------
# In the GRID environment, it is crucial to perform cleanup promptly due to limited disc space, which could constrain the number of timeframes. We provide a timeframe cleanup function that removes digits, clusters, and other unnecessary files as soon as possible.
# TODO: Implement cleanup based on labels or task names
   if args.early_tf_cleanup == True:
     TFcleanup = createTask(name='tfcleanup_'+str(tf), needs= [ AODtask['name'] ], tf=tf, cwd=timeframeworkdir, lab=["CLEANUP"], mem='0', cpu='1')
     TFcleanup['cmd'] = 'rm *digi*.root;'
     TFcleanup['cmd'] += 'rm *cluster*.root'
     workflow['stages'].append(TFcleanup)

---

### GLO + RECO
addQCPerTF(taskName='vertexQC',
           needs=[PVFINDERtask['name']],
           readerCommand='o2-primary-vertex-reader-workflow',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/vertexing-qc-direct-mc.json')
addQCPerTF(taskName='ITSTPCmatchQC',
           needs=[ITSTPCMATCHtask['name']],
           readerCommand='o2-global-track-cluster-reader --track-types "ITS,TPC,ITS-TPC"',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/ITSTPCmatchedTracks_direct_MC.json')
if isActive('TOF'):
    addQCPerTF(taskName='TOFMatchQC',
               needs=[TOFTPCMATCHERtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC" --cluster-types none',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/tofMatchedTracks_ITSTPCTOF_TPCTOF_direct_MC.json')
if isActive('TOF') and isActive('TRD'):

---

parser.add_argument('-e', help='simengine', default='TGeant4', choices=['TGeant4', 'TGeant3', 'TFluka'])
parser.add_argument('-tf', type=int, help='number of timeframes', default=2)
parser.add_argument('--production-offset', help='Offset that defines the bunch-crossing range within a (GRID) production. This offset sets the first orbit to Offset multiplied by the number of TimeFrames times OrbitsPerTimeframe (up for further refinement)', default=0)
parser.add_argument('-j', '--n-workers', dest='n_workers', help='number of workers (if applicable)', default=8, type=int)
parser.add_argument('--force-n-workers', dest='force_n_workers', action='store_true', help='by default, the number of workers is recalculated based on the interaction rate; use this flag to prevent such recalculation')

---

+ ' --incontext ' + str(CONTEXTFILE) + ' --disable-write-ini --early-forward-policy always --forceSelectedDets ' \
                         + ' --tpc-distortion-type ' + str(tpcDistortionType)                                                             \
                         + putConfigValues(["TPCGasParam","TPCGEMParam","TPCEleParam","TPCITCorr","TPCDetParam"],
                                              localCF=tpcLocalCF)
   TPCDigitask['cmd'] += (' --tpc-chunked-writer','')[args.no_tpc_digitchunking]
   TPCDigitask['cmd'] += ('',' --disable-mc')[args.no_mc_labels]
   # we include additional command line options (for advanced users) using an environment variable
   if environ.get('O2DPG_TPC_DIGIT_EXTRA') != None:
      TPCDigitask['cmd'] += ' ' + environ['O2DPG_TPC_DIGIT_EXTRA']
   workflow['stages'].append(TPCDigitask)
   # END TPC digi part

---

WORKFLOW:
    workflow['stages'].append(GRP_TASK)

# QED is currently active only for events with identical beam species
QED_enabled = True if (PDGA==PDGB and PDGA!=2212) else False
includeQED = (QED_enabled or (doembedding and QED_enabled)) or (args.with_qed == True)
signalprefix='sgn'

# Vertexing is not performed for event pool generation; instead, the vertex is sourced from the CCDB or from CollContext
# (Note that the CCDB scenario includes the kDiamond case as it is handled within GRP_TASK)
vtxmode_precoll = 'kNoVertex' if args.make_evtpool else 'kCCDB'
vtxmode_sgngen = 'kCollContext'

---

# Some subsequent tasks require geometry and grp with fixed names, so we offer this solution.
# Alternatively, given our timeframe isolation, we can use standard o2sim files.
# We must be cautious here and differentiate between embedding and non-embedding scenarios.
# This is necessary to prevent confusion in itstpcmatching (see O2-2026). Since only one of the GRPs is updated during digitization, we need to handle this distinction.
if doembedding:
   LinkGRPFileTask=createTask(name='linkGRP_'+str(tf), needs=[BKG_HEADER_task['name'] if usebkgcache else BKGtask['name'] ], tf=tf, cwd=timeframeworkdir, cpu='0',mem='0')
   LinkGRPFileTask['cmd']='''
                          ln -nsf ../bkg_grp.root o2sim_grp.root;
                          ln -nsf ../bkg_grpecs.root o2sim_grpecs.root;
                          ln -nsf ../bkg_geometry.root o2sim_geometry.root;
                          ln -nsf ../bkg_geometry.root bkg_geometry.root;

---

# to be activated once MFT Digits should be processed with five different setups
for flp in range(5):
  addQCPerTF(taskName='mftDigitsQC' + str(flp),
             needs=[getDigiTaskName("MFT")],
             readerCommand='o2-qc-mft-digits-root-file-reader --mft-digit-infile=mftdigits.root',
             configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mft-digits-' + str(flp) + '.json',
             objectsFile='mftDigitsQC.root')
addQCPerTF(taskName='mftClustersQC',
           needs=[MFTRECOtask['name']],
           readerCommand='o2-global-track-cluster-reader --track-types none --cluster-types MFT',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mft-clusters.json')
addQCPerTF(taskName='mftTracksQC',
           needs=[MFTRECOtask['name']],
           readerCommand='o2-global-track-cluster-reader --track-types MFT --cluster-types MFT',

---

#<--------- ITS-TPC track matching task
TRDTRACKINGtask = createTask(name='trdreco_'+str(tf), dependencies=[TRDDigitask['name'], ITSTPCMATCHtask['name'], TPCRECOtask['name'], ITSRECOtask['name']], tf=tf, cwd=timeframeworkdir, labels=["RECO"], cpu='1', mem='2000')
TRDTRACKINGtask['cmd'] = task_finalizer(['${O2_ROOT}/bin/o2-trd-tracklet-transformer',
                                         getDPL_global_options(), 
                                         putConfigValues(),
                                         ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(TRDTRACKINGtask)

---

DOCUMENT:
    CONFKEYMV='Diamond.width[2]='+str(MV_SZ)+';Diamond.width[1]='+str(MV_SY)+';Diamond.width[0]='+str(MV_SX)+';Diamond.position[2]='+str(MV_VZ)+';Diamond.position[1]='+str(MV_VY)+';Diamond.position[0]='+str(MV_VX)+';'
    args.confKey=args.confKey + CONFKEYMV
    args.confKeyBkg=args.confKeyBkg + CONFKEYMV
    print("** Configuration Key args including MeanVertex:",args.confKey)
else:
   print ("Pandas not available. External file for mean vertex not read")

---

# Retrieve mean vertex parameters from an external text file
if (pandas_available):
  if len(args.meanVertexPerRunTxtFile) > 0:
    if len(CONFKEYMV) > 0:
       print("confKey already sets diamond, stop!")
       sys.exit(1)
    df = pd.read_csv(args.meanVertexPerRunTxtFile, delimiter="\t", header=None)
    df.columns = ["runNumber", "vx", "vy", "vz", "sx", "sy", "sz"]
    MV_SX = float(df.loc[df['runNumber'].eq(args.run), 'sx'])
    MV_SY = float(df.loc[df['runNumber'].eq(args.run), 'sy'])
    MV_SZ = float(df.loc[df['runNumber'].eq(args.run), 'sz'])
    MV_VX = float(df.loc[df['runNumber'].eq(args.run), 'vx'])
    MV_VY = float(df.loc[df['runNumber'].eq(args.run), 'vy'])
    MV_VZ = float(df.loc[df['runNumber'].eq(args.run), 'vz'])
    print("** Using mean vertex parameters from file",args.meanVertexPerRunTxtFile,"for run =",args.run,
    ": \n \t vx =",MV_VX,", vy =",MV_VY,", vz =",MV_VZ,",\n \t sx =",MV_SX,", sy =",MV_SY,", sz =",MV_SZ)

---

# Ensures that this task is not executed for multiple TimeFrames simultaneously, preventing attempts to modify the same file.
   task['semaphore'] = objectsFile
   workflow['stages'].append(task)

### MFT

---

AODtask = createTask(name='aod_'+str(tf), needs=aodneeds, tf=tf, cwd=timeframeworkdir, lab=["AOD"], mem='4000', cpu='1')
AODtask['cmd'] = ('','ln -nfs ../bkg_Kine.root . ;')[doembedding]
AODtask['cmd'] += '[ -f AO2D.root ] && rm AO2D.root; '
AODtask['cmd'] += task_finalizer([
   "${O2_ROOT}/bin/o2-aod-producer-workflow",
   "--reco-mctracks-only 1",
   "--aod-writer-keep dangling",
   "--aod-writer-resfile AO2D",
   '--aod-writer-resmode "UPDATE"',
   f"--run-number {args.run}",
   getDPL_global_options(bigshm=True),
   f"--info-sources {aodinfosources}",
   f"--lpmp-prod-tag {args.productionTag}",
   "--anchor-pass ${ALIEN_JDL_LPMANCHORPASSNAME:-unknown}",
   "--anchor-prod ${ALIEN_JDL_LPMANCHORPRODUCTION:-unknown}",
   created_by_option,
   "--combine-source-devices" if not args.no_combine_dpl_devices else "",
   "--disable-mc" if args.no_mc_labels else "",

])

---

# adjust timeframeID, orbits, and seed values, including qed
# apply maximum collision offset
# apply vertexing
interactionspecification = signalprefix + ',' + str(INTRATE) + ',' + str(1000000) + ':' + str(1000000)
if doembedding:
   interactionspecification = 'bkg,' + str(INTRATE) + ',' + str(NTIMEFRAMES*args.ns) + ':' + str(args.nb) + ' ' + signalprefix + ',' + args.embeddPattern

---

addQCPerTF(taskName='MCHRecoTaskQC',
           needs=[MCHRECOtask['name']],
           readerCommand='o2-mch-reco-workflow --disable-root-output',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mch-reco-task.json')
addQCPerTF(taskName='MCHTracksTaskQC',
           needs=[MCHRECOtask['name']],
           readerCommand='o2-global-track-cluster-reader --track-types MCH --cluster-types MCH',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mch-tracks-task.json')

---

else:
    # we load a standard configuration
    print("** Using standard configuration **")
    anchorConfig = anchorConfig_generic
# apply any external user preferences to the configuration
# these preferences will override previous settings
if args.overwrite_config != '':
    # apply the final JSON override
    config_overwrite = load_external_config(args.overwrite_config)
    # ensure both configurations follow the same structure
    if ("ConfigParams" in anchorConfig) != ("ConfigParams" in config_overwrite):
        print("Error: overwrite config does not match base config format; cannot combine")
        exit(1)
    
    # merge the dictionaries, with anchorConfig taking priority
    merge_dicts(anchorConfig, config_overwrite)

---

# third part
EMCRECOtask['cmd'] += ' | '
EMCRECOtask['cmd'] += task_finalizer([
   '${O2_ROOT}/bin/o2-emcal-cell-writer-workflow',
   getDPL_global_options(),
   '--subspec 0', 
   ('', ' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(EMCRECOtask)

---

DOCUMENT:
    TPCCLUSMERGEtask=createTask(name='tpcclustermerge_'+str(tf), needs=tpcclustertasks, tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu='1', mem='10000')
    TPCCLUSMERGEtask['cmd']='${O2_ROOT}/bin/o2-commonutils-treemergertool -i tpc-native-clusters-part*.root -o tpc-native-clusters.root -t tpcrec' #--asfriend preferable but does not work
    workflow['stages'].append(TPCCLUSMERGEtask)
    tpcreconeeds.append(TPCCLUSMERGEtask['name'])
    else:
        tpcclus = createTask(name='tpccluster_' + str(tf), needs=tpcclusterneed, tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu=NWORKERS_TF, mem='2000')
        tpcclus['cmd'] = '${O2_ROOT}/bin/o2-tpc-chunkeddigit-merger --tpc-lanes ' + str(NWORKERS_TF)
        tpcclus['cmd'] += ' | ${O2_ROOT}/bin/o2-tpc-reco-workflow ' + getDPL_global_options() + ' --input-type digitizer --output-type clusters,send-clusters-per-sector ' + putConfigValues(["GPU_global","TPCGasParam","TPCCorrMap"],{"GPU_proc.ompThreads" : 1}) + ('',' --disable-mc')[args.no_mc_labels]

---

# this allows us to adjust the workflow based on detector presence
# these include all detectors assumed to be active
readout_detectors = args.readoutDets
# here we list all detectors set in an anchored script
activeDetectors = dpl_option_from_config(anchorConfig, 'o2-ctf-reader-workflow', key='onlyDet', default_value='all')
if activeDetectors == 'all':
    # if "all" is specified, use the detectors passed to this script (which could be "all" or a subset)
    activeDetectors = readout_detectors
elif readout_detectors != 'all' and activeDetectors != 'all':
    # in this scenario, both are comma-separated lists. We find the intersection
    r = set(readout_detectors.split(','))
    a = set(activeDetectors.split(','))
    activeDetectors = ','.join(r & a)
# in the final scenario, use the detectors from the anchored configuration

---

parser.add_argument('--condition-not-after', type=int, help="limits the consideration to CCDB objects not created after this timestamp (for TimeMachine)", default=3385078236000)
parser.add_argument('--orbitsPerTF', type=int, help="defines the timeframe size in terms of LHC orbits", default=32)
parser.add_argument('--anchor-config', help="a JSON file to provide external context for the workflow (such as config values) from data reconstruction workflows.", default='')
parser.add_argument('--overwrite-config', help="an additional JSON file with configs to override default settings or those from --anchor-config", default='')
parser.add_argument('--dump-config', help="saves a JSON file with all settings used in the workflow", default='user_config.json')
parser.add_argument('-ns', type=int, help='specifies the number of signal events per timeframe', default=20)
parser.add_argument('-gen', help='specifies the generator: pythia8 or extgen', default='')

---

tpcdigimem = 12000 if havePbPb else 9000
TPCDigitask = createTask(name='tpcdigi_'+str(tf), needs=tpcdigineeds, tf=tf, cwd=timeframeworkdir, lab=["DIGI"], cpu=NWORKERS_TF, mem=str(tpcdigimem))
TPCDigitask['cmd'] = ('','ln -nfs ../bkg_HitsTPC.root . ;')[doembedding]
TPCDigitask['cmd'] += '${O2_ROOT}/bin/o2-ccdb-downloadccdbfile --host http://alice-ccdb.cern.ch -p TPC/Config/RunInfoV2 --timestamp ' + str(args.timestamp) + ' --created-not-after ' + str(args.condition_not_after) + ' -d ${ALICEO2_CCDB_LOCALCACHE} ; '
TPCDigitask['cmd'] += '${O2_ROOT}/bin/o2-sim-digitizer-workflow ' + getDPL_global_options(bigshm=True) + ' -n ' + str(args.ns) + simsoption + ' --onlyDet TPC --TPCuseCCDB --interactionRate ' + str(INTRATE) + ' --tpc-lanes ' + str(NWORKERS_TF)

---

aod_df_id = '{0:03}'.format(tf)

import os
aod_creator = os.getenv("JALIEN_USER")
if aod_creator is None:
   # we use JAliEn to find out the user and capture the output into a variable through redirect_stdout
   import io
   from contextlib import redirect_stdout
   f = io.StringIO()
   with redirect_stdout(f):
      if JAlien(['whoami']) == 0:
         aod_creator = f.getvalue().strip()
         print (f"Determined GRID username {aod_creator}")

   # this option may not be available everywhere
   created_by_option = option_if_available('o2-aod-producer-workflow', '--created-by', envfile=async_envfile)
   if created_by_option != '':
      created_by_option += ' ' + aod_creator

---

### FV0
addQCPerTF(taskName='FV0DigitsQC',
           needs=[getDigiTaskName("FV0")],
           readerCommand='o2-fv0-digit-reader-workflow --fv0-digit-infile fv0digits.root',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/fv0-digits.json')

### FDD
addQCPerTF(taskName='FDDRecPointsQC',
           needs=[FDDRECOtask['name']],
           readerCommand='o2-fdd-recpoints-reader-workflow --fdd-recpoints-infile o2reco_fdd.root',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/fdd-recpoints.json')

---

f'--store-ctp-lumi {CTPSCALER}',
      '--disable-write-ini',
      putConfigValues(listOfMainKeys=['EMCSimParam','FV0DigParam','FT0DigParam'], localCF={"DigiParams.seed" : str(TFSEED)}),
      ('--combine-devices','')[args.no_combine_dpl_devices],
      ('',' --disable-mc')[args.no_mc_labels], 
      QEDdigiargs,
      '--forceSelectedDets'], configname = 'ft0fv0emcctp_digi'
   
   workflow['stages'].append(FT0FV0EMCCTPDIGItask)
   det_to_digitask["FT0"]=FT0FV0EMCCTPDIGItask
   det_to_digitask["FV0"]=FT0FV0EMCCTPDIGItask
   det_to_digitask["EMC"]=FT0FV0EMCCTPDIGItask
   det_to_digitask["CTP"]=FT0FV0EMCCTPDIGItask

---

module_name = "o2dpg_analysis_test_workflow"
spec = importlib.util.spec_from_file_location(module_name, join(O2DPG_ROOT, "MC", "analysis_testing", f"{module_name}.py"))
o2dpg_analysis_test_workflow = importlib.util.module_from_spec(spec)
sys.modules[module_name] = o2dpg_analysis_test_workflow
spec.loader.exec_module(o2dpg_analysis_test_workflow)

from o2dpg_analysis_test_workflow import add_analysis_tasks, add_analysis_qc_upload_tasks

# retrieve an external configuration if provided
# loads the workflow specification
def load_external_config(configfile):
    fp = open(configfile)
    config = json.load(fp)
    return config

---

#<------------------ TPC - time-series objects
# initial implementation sourced from comments in https://its.cern.ch/jira/browse/O2-4612
# TODO: this must be made configurable based on which detectors are actually present
tpctsneeds = [ TPCRECOtask['name'],
               ITSTPCMATCHtask['name'],
               TOFTPCMATCHERtask['name'],
               PVFINDERtask['name']
             ]
TPCTStask = createTask(name='tpctimeseries_'+str(tf), needs=tpctsneeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='2000', cpu='1')
TPCTStask['cmd'] = 'o2-global-track-cluster-reader --disable-mc --cluster-types "FT0,TOF,TPC" --track-types "ITS,TPC,ITS-TPC,ITS-TPC-TOF,ITS-TPC-TRD-TOF"'
TPCTStask['cmd'] += ' --primary-vertices '
TPCTStask['cmd'] += ' | o2-tpc-time-series-workflow --enable-unbinned-root-output --sample-unbinned-tsallis --sampling-factor 0.01 '
TPCTStask['cmd'] += putConfigValues() + ' ' + getDPL_global_options(bigshm=True)

---

# -----------
# reco
# -----------
tpcreconeeds=[FT0FV0EMCCTPDIGItask['name']]
tpcclusterneed=[TPCDigitask['name'], FT0FV0EMCCTPDIGItask['name']]
if not args.combine_tpc_clusterization:
  # TPC clusterization is handled in multiple (sector) steps to ensure compliance with memory constraints or to enable parallel processing per sector from an external source (currently not supported within the cluster algorithm).
  tpcclustertasks=[]
  sectorpertask=18
  for s in range(0,35,sectorpertask):
    taskname = 'tpcclusterpart' + str(int(s/sectorpertask)) + '_' + str(tf)
    tpcclustertasks.append(taskname)
    tpcclussect = createTask(name=taskname, needs=tpcclusterneed, tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu='2', mem='8000')
    digitmergerstr = '${O2_ROOT}/bin/o2-tpc-chunkeddigit-merger --tpc-sectors ' + str(s)+'-'+str(s+sectorpertask-1) + ' --tpc-lanes ' + str(NWORKERS_TF) + ' | '

---

### EMCAL
if EMC_is_active:
    addQCPerTF(taskName='emcRecoQC',
               needs=[EMCRECOtask['name']],
               readerCommand='o2-emcal-cell-reader-workflow --infile emccells.root',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/emc-reco-tasks.json')
    if CTP_is_active:
        addQCPerTF(taskName='emcBCQC',
                   needs=[EMCRECOtask['name'], getDigiTaskName("CTP")],
                   readerCommand='o2-emcal-cell-reader-workflow --infile emccells.root | o2-ctp-digit-reader --inputfile ctpdigits.root --disable-mc',
                   configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/emc-bc-task.json')
### FT0
addQCPerTF(taskName='RecPointsQC',
           needs=[FT0RECOtask['name']],
           readerCommand='o2-ft0-recpoints-reader-workflow --infile o2reco_ft0.root',

---

DOCUMENT:
    TPCTStask['cmd'] += putConfigValues() + ' ' + getDPL_global_options(bigshm=True)
    workflow['stages'].append(TPCTStask)

---

# ----------- START WORKFLOW CONSTRUCTION -----------------------------

# set the start time of the run (if no timestamp is given)
if args.sor == -1:
   args.sor = retrieve_sor(args.run)
   assert args.sor != 0

if args.timestamp == -1:
   args.timestamp = args.sor

NTIMEFRAMES = int(args.tf)
NWORKERS = args.n_workers
MODULES = "--skipModules ZDC" if not isActive("ZDC") else ""
SIMENGINE = args.e
BFIELD = args.field
RNDSEED = args.seed  # usually this should be the job ID, but if none is provided, the current time is used for initialization
random.seed(RNDSEED)
print("Using initial seed:", RNDSEED)
SIMSEED = random.randint(1, 900000000 - NTIMEFRAMES - 1)  # the maximum seed for PYTHIA is 900 million for some reason

# ---- initialize global (physics variables) for signal parts ----
ECMS = float(args.eCM)
EBEAMA = float(args.eA)
EBEAMB = float(args.eB)
NSIGEVENTS = args.ns
GENERATOR = args.gen
if GENERATOR == '':
   print('o2dpg_sim_workflow: Error! generator name not provided')
   exit(1)

---

scdcalib_track_sources = dpl_option_from_config(anchorConfig,
                                                'o2-tpc-scdcalib-interpolation-workflow',
                                                'tracking-sources',
                                                default_value='ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,FDD,HMP,FV0,TRD,MCH,CTP')

scdcalib_track_extraction = dpl_option_from_config(anchorConfig,
                                                   'o2-tpc-scdcalib-interpolation-workflow',
                                                   'tracking-sources-map-extraction',
                                                   default_value='ITS-TPC')

---

# generate the signal configuration
SGN_CONFIG_task=createTask(name='gensgnconf_'+str(tf), tf=tf, cwd=timeframeworkdir)
SGN_CONFIG_task['cmd'] = 'echo "placeholder / dummy task"'
if GENERATOR == 'pythia8':
    # check if there is an external config
    externalPythia8Config = simInitialConfigKeys.get("GeneratorPythia8", {}).get("config", None)
    if externalPythia8Config:
        # ensure the provided path is absolute
        if not isabs(externalPythia8Config):
            print ('Error: Argument to GeneratorPythia8.config must be an absolute path')
            exit (1)
        # copy the external configuration file to the local directory
        SGN_CONFIG_task['cmd'] = 'cp ' + externalPythia8Config + ' pythia8.cfg'
    else:
        SGN_CONFIG_task['cmd'] = '${O2DPG_ROOT}/MC/config/common/pythia8/utils/mkpy8cfg.py \
                                  --output=pythia8.cfg'

---

getDPL_global_options(bigshm=True),
    svfinder_threads,
    putConfigValues(['svertexer', 'TPCCorrMap'], {"NameConf.mDirMatLUT" : ".."} | tpcLocalCFreco),
    tpc_corr_scaling_options,
    tpc_corr_options_mc,
    '--vertexing-sources ' + svfinder_sources,
    ('--combine-source-devices','')[args.no_combine_dpl_devices],
    ('',' --disable-strangeness-tracker')[args.no_strangeness_tracking],
    ('',' --disable-mc')[args.no_mc_labels and not args.no_strangeness_tracking] # strangeness tracking may require MC labels
   ])
   workflow['stages'].append(SVFINDERtask)

---

configFilePathOnDisk = remove_json_prefix(configFilePath)
   # we verify if the configFilePath is present in the current software. If not, we exit gracefully
   task['cmd'] = ' if [ -f ' + configFilePathOnDisk + ' ]; then { '
    # The actual QC command
    # the --local-batch argument ensures that QC Tasks store their results in a file and merge with any existing objects
   task['cmd'] += f'{readerCommand} | o2-qc --config {configFilePath}' + \
                 f' --local-batch ../{qcdir}/{objectsFile}' + \
                 f' --override-values "qc.config.database.host={args.qcdbHost};qc.config.Activity.number={args.run};qc.config.Activity.type=PHYSICS;qc.config.Activity.periodName={args.productionTag};qc.config.Activity.beamType={args.col};qc.config.Activity.start={args.timestamp};qc.config.conditionDB.url={args.conditionDB}"' + \
                 ' ' + getDPL_global_options(ccdbbackend=False)

---

# TODO:
# - retrieve the final list of configKey values from the anchorConfig

import sys
import importlib.util
import argparse
from os import environ, mkdir
from os.path import join, dirname, isdir, isabs, isfile
import random
import json
import itertools
import math
import requests, re
from functools import lru_cache

pandas_available = True
try:
    import pandas as pd
except (ImportError, ValueError):  # ARM architecture has issues with pandas and numpy
    pandas_available = False

sys.path.append(join(dirname(__file__), '.', 'o2dpg_workflow_utils'))

---

parser.add_argument('--embedding', action='store_true', help='Option to embed signal into background')
parser.add_argument('--embeddPattern', help='Method for injecting signal into background', default='@0:e1')
parser.add_argument('-nb', help='Number of background events per timeframe', default=20)
parser.add_argument('-genBkg', help='Generator for background embedding', default='') #pythia8, not recommended: pythia8hi, pythia8pp
parser.add_argument('-procBkg', help='Process type: inel, ..., leave empty for Pythia8 PbPb', default='heavy_ion')
parser.add_argument('-iniBkg', help='Path to initialization parameters file for background generator (full path required)', default='${O2DPG_ROOT}/MC/config/common/ini/basic.ini')
parser.add_argument('-confKeyBkg', help='Configuration key values for background embedding, for example: "GeneratorPythia8.config=pythia8bkg.cfg"', default='')
parser.add_argument('-colBkg', help='Collision system for background embedding', default='PbPb')

---

DOCUMENT:
    addQCPerTF(taskName='trdTrackingQC',
                needs=[TRDTRACKINGtask2['name']],
                readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TRD,TPC-TRD" --cluster-types none',
                configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/trd-tracking-task.json')

     ### TOF
     addQCPerTF(taskName='tofDigitsQC',
                needs=[getDigiTaskName("TOF")],
                readerCommand='${O2_ROOT}/bin/o2-tof-reco-workflow --delay-1st-tf 3 --input-type digits --output-type none',
                configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/tofdigits.json',
                objectsFile='tofDigitsQC.root')

---

# if TPC residuals extraction is required, we must combine per-timeframe trees
if includeTPCResiduals:
   tpcResidMergingNeeds = ['scdaggreg_' + str(tf) for tf in range(1, NTIMEFRAMES + 1)]
   TPCResid_merge_task = createTask(name='tpcresidmerge', needs = tpcResidMergingNeeds, lab=["CALIB"], mem='2000', cpu='1')
   TPCResid_merge_task['cmd'] = ' set -e ; [ -f tpcresidmerge_input.txt ] && rm tpcresidmerge_input.txt; '
   TPCResid_merge_task['cmd'] += ' for i in `seq 1 ' + str(NTIMEFRAMES) + '`; do find tf${i} -name "o2tpc_residuals_*.root" >> tpcresidmerge_input.txt; done; '
   TPCResid_merge_task['cmd'] += '${O2DPG_ROOT}/UTILS/root_merger.py -o o2tpc_residuals.root -i $(grep -v \"^$\" tpcresidmerge_input.txt | paste -sd, -)'
   workflow['stages'].append(TPCResid_merge_task)


# adapt for alternative (RECO) software setups
adjust_RECO_environment(workflow, args.alternative_reco_software)

dump_workflow(workflow['stages'], args.o, meta=vars(args))

---

DOCUMENT:
    sys.path.append(join(dirname(__file__), '.', 'o2dpg_workflow_utils'))

from o2dpg_workflow_utils import createTask, createGlobalInitTask, dump_workflow, adjust_RECO_environment, isActive, activate_detector, deactivate_detector, compute_n_workers, merge_dicts
from o2dpg_qc_finalization_workflow import include_all_QC_finalization
from o2dpg_sim_config import create_sim_config, create_geant_config, constructConfigKeyArg, option_if_available, overwrite_config
from o2dpg_dpl_config_tools import parse_command_string, modify_dpl_command, dpl_option_from_config, TaskFinalizer

# for JAliEn interactions
from alienpy.alien import JAlien

parser = argparse.ArgumentParser(description='Generate an ALICE (Run3) MC simulation workflow')

---

ELSE: # here we create individual digitizers
    if usebkgcache:
        tneeds += [ BKG_HITDOWNLOADER_TASKS[det]['name'] ]
    t = createTask(name=name, needs=tneeds, tf=tf, cwd=timeframeworkdir, lab=["DIGI","SMALLDIGI"], cpu='1')
    t['cmd'] = ('','ln -nfs ../bkg_Hits' + str(det) + '.root . ;')[doembedding]
    t['cmd'] += commondigicmd + ' --onlyDet ' + str(det)
    t['cmd'] += ('',' --disable-mc')[args.no_mc_labels]
    if det == 'TOF':
        t['cmd'] += ' --ccdb-tof-sa'
    workflow['stages'].append(t)
    return t

det_to_digitask={}

if not args.no_combine_smaller_digi:
    det_to_digitask['ALLSMALLER']=createRestDigiTask("restdigi_"+str(tf))

for det in smallsensorlist:
    name=str(det).lower() + "digi_" + str(tf)
    t = det_to_digitask['ALLSMALLER'] if not args.no_combine_smaller_digi else createRestDigiTask(name, det)
    det_to_digitask[det]=t

---

# power features (for playing) --> not included in the help message
#  help='Treat smaller sensors in a single digitization')
parser.add_argument('--pregenCollContext', action='store_true', help=argparse.SUPPRESS) # currently the default setting, providing this or not makes no difference; retained for backward compatibility
parser.add_argument('--no-combine-smaller-digi', action='store_true', help=argparse.SUPPRESS)
parser.add_argument('--no-combine-dpl-devices', action='store_true', help=argparse.SUPPRESS)
parser.add_argument('--no-mc-labels', action='store_true', default=False, help=argparse.SUPPRESS)
parser.add_argument('--no-tpc-digitchunking', action='store_true', help=argparse.SUPPRESS)
parser.add_argument('--no-strangeness-tracking', action='store_true', default=False, help="Disable strangeness tracking")
parser.add_argument('--combine-tpc-clusterization', action='store_true', help=argparse.SUPPRESS) #<--- beneficial for small productions (pp, low interaction rate, few events)

---

# Step 1: header and link files
BKG_HEADER_task = createTask(name='bkgdownloadheader', cpu='0', lab=['BKGCACHE'])
BKG_HEADER_task['cmd'] = 'alien.py cp ' + args.use_bkg_from + 'bkg_MCHeader.root .'
BKG_HEADER_task['cmd'] += ';alien.py cp ' + args.use_bkg_from + 'bkg_geometry.root .'
BKG_HEADER_task['cmd'] += ';alien.py cp ' + args.use_bkg_from + 'bkg_grp.root .'
workflow['stages'].append(BKG_HEADER_task)

# A list of smaller sensors (used to construct digitization tasks in a parametrized manner)
smallsensorlist = [ "ITS", "TOF", "FDD", "MCH", "MID", "MFT", "HMP", "PHS", "CPV", "ZDC" ]
# A list of detectors that serve as input for the trigger processor CTP; these must be processed together at the moment
ctp_trigger_inputlist = [ "FT0", "FV0", "EMC" ]

---

# manage distortions and scaling with MC maps
# it is assumed that the lumi within the maps is recorded in the FT0 (pp) scalers
# for PbPb interactions, the conversion factor from ZDC to FT0 (pp) must be considered in the scalers
if tpcDistortionType == 2 and CTPSCALER <= 0:
    print('Warning: lumi scaling is needed, but no ctp scaler value is set. The full map will be applied without adjustment.')
    tpcDistortionType=1
lumiInstFactor=1
if COLTYPE == 'PbPb':
    lumiInstFactor=2.414
if tpcDistortionType == 2:
    tpcLocalCF['TPCCorrMap.lumiInst'] = str(CTPSCALER * lumiInstFactor)

---

DOCUMENT:
    trddigineeds = [ContextTask['name']]
    if usebkgcache:
        trddigineeds.append(BKG_HITDOWNLOADER_TASKS['TRD']['name'])
    TRDDigitask = createTask(name='trddigi_' + str(tf), needs=trddigineeds, tf=tf, cwd=timeframeworkdir, lab=["DIGI"], cpu=NWORKERS_TF, mem='8000')
    TRDDigitask['cmd'] = ('','ln -nfs ../bkg_HitsTRD.root . ;')[doembedding]
    TRDDigitask['cmd'] += '${O2_ROOT}/bin/o2-sim-digitizer-workflow ' + getDPL_global_options() + ' -n ' + str(args.ns) + simsoption         \
                          + ' --onlyDet TRD --interactionRate ' + str(INTRATE) + ' --incontext ' + str(CONTEXTFILE) + ' --disable-write-ini' \
                          + putConfigValues(localCF={"TRDSimParams.digithreads" : NWORKERS_TF, "DigiParams.seed" : str(TFSEED)}) + " --forceSelectedDets"
    TRDDigitask['cmd'] += ('',' --disable-mc')[args.no_mc_labels]
    workflow['stages'].append(TRDDigitask)

---

--eA='+str(EBEAMABKG)+'                                     \
--eB='+str(EBEAMBBKG)+'                                     \
--process='+str(PROCESSBKG)
# if we set pythia8 here, we must also update the configuration
# TODO: we require a proper config container/manager to integrate these local configurations with external ones, etc.
args.confKeyBkg = 'GeneratorPythia8.config=pythia8bkg.cfg;' + args.confKeyBkg

---

DOCUMENT:
    workflow['stages'].append(BKGtask)

        # check if we should upload background events
        if args.upload_bkg_to!=None:
            BKGuploadtask=createTask(name='bkgupload', needs=[BKGtask['name']], cpu='0')
            BKGuploadtask['cmd']='alien.py mkdir ' + args.upload_bkg_to + ';'
            BKGuploadtask['cmd']+='alien.py cp -f bkg* ' + args.upload_bkg_to + ';'
            workflow['stages'].append(BKGuploadtask)

    else:
        # here we utilize existing background events from ALIEN

        # when employing background caches, we have several smaller tasks
        # this division is sensible as they are required at different stages:
        # 1: download bkg_MCHeader.root, grp, and geometry
        # 2: download individual bkg_Hit files
        # 3: download bkg_Kinematics
        # (A potential issue with individual copying could be higher error rates, but
        #  we can introduce a "retry" function in the copy process)

---

#<--------- TRD global tracking 
# FIXME This is currently a workaround to avoid a race condition with trdcalibratedtracklets.root
TRDTRACKINGtask2 = createTask(name='trdreco2_'+str(tf), needs=[TRDTRACKINGtask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu='1', mem='2000')
trd_track_sources = dpl_option_from_config(anchorConfig, 'o2-trd-global-tracking', 'track-sources', default_value='TPC,ITS-TPC')
TRDTRACKINGtask2['cmd'] = task_finalizer([
      '${O2_ROOT}/bin/o2-trd-global-tracking',
      getDPL_global_options(bigshm=True), 
      ('',' --disable-mc')[args.no_mc_labels],
      putConfigValues(['ITSClustererParam',
                       'ITSCATrackerParam',
                       'trackTuneParams',
                       'GPU_rec_tpc',
                       'TPCGasParam',
                       'TPCCorrMap'], {"NameConf.mDirMatLUT" : ".."} | tpcLocalCFreco),
      '--track-sources ' + trd_track_sources,
      tpc_corr_scaling_options,
])

---

# Quality Control (QC) related arguments
parser.add_argument('--include-qc', '--include-full-qc', action='store_true', help='enables QC in the workflow, encompassing both per-tf processing and finalization')
parser.add_argument('--include-local-qc', action='store_true', help='enables the per-tf QC, while omitting the finalization (e.g., to facilitate subjob merging first)')

# O2 Analysis related arguments
parser.add_argument('--include-analysis', '--include-an', '--analysis',
                    action='store_true', help='a flag to incorporate O2 analysis into the workflow')

# MFT Reconstruction Configuration
parser.add_argument('--mft-reco-full', action='store_true', help='enables full MFT reconstruction instead of the simplified misaligned version')
parser.add_argument('--mft-assessment-full', action='store_true', help='enables a thorough assessment of MFT reconstruction')

---

# particularly in the epemgen.f file
QEDXSecExpected = {'PbPb': 35237.5, 'OO': 3.17289, 'NeNe': 7.74633} # the anticipated QED cross section value as generated by TEPEMGEN
Zsys = {'PbPb': 82, 'OO': 8, 'NeNe': 10} # the atomic number of the colliding species
PreCollContextTask = createTask(name='precollcontext', needs=precollneeds, cpu='1')

---

configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mft-tracks.json')
addQCPerTF(taskName='mftMCTracksQC',
           needs=[MFTRECOtask['name']],
           readerCommand='o2-global-track-cluster-reader --track-types MFT --cluster-types MFT',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mft-tracks-mc.json')

---

# depending on whether TRD and FT0 are available
if isActive('FT0') and isActive('TRD'):
    addQCPerTF(taskName='tofft0PIDQC',
               needs=[TOFTPCMATCHERtask['name'], FT0RECOtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC,ITS-TPC-TRD,ITS-TPC-TRD-TOF,TPC-TRD,TPC-TRD-TOF" --cluster-types FT0',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/pidft0tof.json')
elif isActive('FT0'):
    addQCPerTF(taskName='tofft0PIDQC',
               needs=[TOFTPCMATCHERtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC" --cluster-types FT0',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/pidft0tofNoTRD.json')
elif isActive('TRD'):
    addQCPerTF(taskName='tofPIDQC',
               needs=[TOFTPCMATCHERtask['name']])

---

#<--------- ZDC reconstruction workflow
ZDCRECOtask = createTask(name='zdcreco_'+str(tf), needs=[getDigiTaskName("ZDC")], tf=tf, cwd=timeframeworkdir, lab=["RECO", "ZDC"])
ZDCRECOtask['cmd'] = task_finalizer(
   ['${O2_ROOT}/bin/o2-zdc-digits-reco', 
    getDPL_global_options(), 
    putConfigValues(), 
    ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(ZDCRECOtask)

## forward matching
#<--------- MCH-MID forward matching
MCHMIDMATCHtask = createTask(name='mchmidMatch_'+str(tf), needs=[MCHRECOtask['name'], MIDRECOtask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
MCHMIDMATCHtask['cmd'] = task_finalizer(
   ['${O2_ROOT}/bin/o2-muon-tracks-matcher-workflow', 
    getDPL_global_options(ccdbbackend=False),
    putConfigValues(),
    ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(MCHMIDMATCHtask)

---

doembedding=True if args.embedding=='True' or args.embedding==True else False

# If not set previously, set beam energy B equal to A
if EBEAMB < 0 and ECMS < 0:
   EBEAMB=EBEAMA
   print('o2dpg_sim_workflow: Beam energy in B set to match that in A')
   if PDGA != PDGB:
      print('o2dpg_sim_workflow: Caution! Beam energies set differently for particles in beams A and B!')

if ECMS > 0:
   if PDGA != PDGB:
      print('o2dpg_sim_workflow: Caution! CM energy set for different particle beams!')

if ECMS < 0 and EBEAMA < 0 and EBEAMB < 0:
   print('o2dpg_sim_workflow: Error! Neither CM nor Beam energy is set!!!')
   exit(1)

# Determine interaction rate
INTRATE=int(args.interactionRate)
if INTRATE <= 0:
   print('o2dpg_sim_workflow: Error! Interaction rate must be > 0 !!!')
   exit(1)
BCPATTERN=args.bcPatternFile

# ----- global background specific stuff -------
COLTYPEBKG=args.colBkg
havePbPb = (COLTYPE == 'PbPb' or (doembedding and COLTYPEBKG == "PbPb"))

workflow={}
workflow['stages'] = []

---

parser.add_argument('-gen',help='Choose the generator: pythia8 or extgen', default='')
parser.add_argument('-proc',help='Select the process type: inel, dirgamma, jets, ccbar, etc.', default='none')
parser.add_argument('-trigger',help='Event selection criteria: particle or external', default='')
parser.add_argument('-ini',help='Provide the full path to the generator initialization parameters file, for example: ${O2DPG_ROOT}/MC/config/PWGHF/ini/GeneratorHF.ini', default='')
parser.add_argument('-confKey',help='Set the configuration key values for o2sim, generator, or trigger, for example: "GeneratorPythia8.config=pythia8.cfg;A.x=y"', default='')
parser.add_argument('--readoutDets',help='Specify the detectors for readout using a comma separated string (hit creation only, no material budget modification)', default='all')
parser.add_argument('--make-evtpool', help='Generate workflow for event pool creation.', action='store_true')

---

# These are single-threaded digitizers
def createRestDigiTask(name, det='ALLSMALLER'):
    tneeds = [ContextTask['name']]
    if includeQED:
        tneeds += [QED_task['name']]
    commondigicmd = '${O2_ROOT}/bin/o2-sim-digitizer-workflow ' + getDPL_global_options() + ' -n ' + str(args.ns) + simsoption \
                    + ' --interactionRate ' + str(INTRATE) + '  --incontext ' + str(CONTEXTFILE) + ' --disable-write-ini'      \
                    + putConfigValues(["MFTAlpideParam", "ITSAlpideParam", "ITSDigitizerParam"],
                                         localCF={"DigiParams.seed" : str(TFSEED), "MCHDigitizer.seed" : str(TFSEED)}) + QEDdigiargs

---

' ' + getDPL_global_options(ccdbbackend=False)
       task['cmd'] += ' ;} else { echo "Task ' + taskName + ' not performed as the config file was not found"; } fi'

---

# Background PYTHIA Setup
BKG_CONFIG_task=createTask(name='genbkgconf')
BKG_CONFIG_task['cmd'] = 'echo "placeholder / dummy task"'
if GENBKG == 'pythia8':
    print('Background generator seed: ', SIMSEED)
    BKG_CONFIG_task['cmd'] = '${O2DPG_ROOT}/MC/config/common/pythia8/utils/mkpy8cfg.py \
                                   --output=pythia8bkg.cfg                                     \
                                   --seed='+str(SIMSEED)+'                                     \
                                   --idA='+str(PDGABKG)+'                                      \
                                   --idB='+str(PDGBBKG)+'                                      \
                                   --eCM='+str(ECMSBKG)+'                                      \
                                   --eA='+str(EBEAMABKG)+'                                     \

---

parser.add_argument('-colBkg', help='specifies the background collision system for embedding', default='PbPb')
parser.add_argument('-confKeyQED', help='config key for parameters affecting the QED background simulator', default='')

---

# using the configuration, we will generate a task_finalizer functor
task_finalizer = TaskFinalizer(anchorConfig, logger="o2dpg_config_replacements.log")

# save this configuration
config_key_param_path = args.dump_config
with open(config_key_param_path, "w") as f:
   print(f"INFO: Additional config key parameters have been written to JSON {config_key_param_path}")
   json.dump(anchorConfig, f, indent=2)

---

generationtimeout = -1 # potential timeout for event pool creation
if args.make_evtpool:
    JOBTTL=environ.get('JOBTTL', None)
    if JOBTTL != None:
        generationtimeout = 0.95*int(JOBTTL) # for GRID jobs, set timeout automatically
SGNGENtask['cmd'] +=('','timeout ' + str(generationtimeout) + ' ')[args.make_evtpool and generationtimeout>0] \
                     + '${O2_ROOT}/bin/o2-sim --noGeant -j 1 --field ccdb --vertexMode ' + vtxmode_sgngen  \
                     + ' --run ' + str(args.run) + ' ' + str(CONFKEY) + str(TRIGGER)                  \
                     + ' -g ' + str(GENERATOR) + ' ' + str(INIFILE) + ' -o genevents ' + embeddinto   \
                     + ('', ' --timestamp ' + str(args.timestamp))[args.timestamp!=-1]                \
                     + ' --seed ' + str(TFSEED) + ' -n ' + str(NSIGEVENTS)                            \
                     + ' --fromCollContext collisioncontext.root:' + signalprefix

---

# validate and purify config-key values (separate and isolate diamond vertex parameters into finalDiamondDict)
def extractVertexArgs(configKeyValuesStr, finalDiamondDict):
  # split configKeyValuesStr by ;
  tokens = configKeyValuesStr.split(';')
  for t in tokens:
    if "Diamond" in t:
      left, right = t.split("=")
      value = finalDiamondDict.get(left, None)
      if value is None:
        finalDiamondDict[left] = right
      else:
        # this has been encountered previously, ensure consistent right side value, or terminate
        if value != right:
          print("Inconsistent repetition in Diamond values; Aborting")
          sys.exit(1)

vertexDict = {}
extractVertexArgs(args.confKey, vertexDict)
extractVertexArgs(args.confKeyBkg, vertexDict)
CONFKEYMV = ""
# construct a new vertex-only config-key string
for e in vertexDict:
  if len(CONFKEYMV) > 0:
    CONFKEYMV += ';'
  CONFKEYMV += str(e) + '=' + str(vertexDict[e])

print ("Diamond is " + CONFKEYMV)

---

def getDigiTaskName(det):
    t = det_to_digitask.get(det)
    if t is None:
        return "undefined"
    return t['name']

---

job_merging = False
if includeFullQC:
   workflow['stages'].extend(include_all_QC_finalization(ntimeframes=NTIMEFRAMES, standalone=False, run=args.run, productionTag=args.productionTag, conditionDB=args.conditionDB, qcdbHost=args.qcdbHost, beamType=args.col))

---

DOCUMENT:
    anchorConfig = {}
anchorConfig_generic = { "ConfigParams": create_sim_config(args) }
if args.anchor_config != '':
   print ("** Using external configuration **")
   anchorConfig = load_external_config(args.anchor_config)
   # incorporate keys from the generic configuration into the anchorConfig if they are not present in the external configuration
   # (this is helpful for digitization parameters and other settings that are typically not included in asynchronous reconstruction)
   for key in anchorConfig_generic["ConfigParams"]:
      if key not in anchorConfig["ConfigParams"]:
         print (f"Transferring key {key} from generic configuration to final configuration")
         anchorConfig["ConfigParams"][key] = anchorConfig_generic["ConfigParams"][key]

---

PRECOLLCONTEXTTASK['CMD']='${O2_ROOT}/bin/o2-steer-colcontexttool -i ' + interactionspecification                      \
                           + ' --show-context'                                                                                  \
                           + ' --timeframeID ' + str(int(args.production_offset)*NTIMEFRAMES)                                  \
                           + ' --orbitsPerTF ' + str(orbitsPerTF)                                                              \
                           + ' --orbits ' + str(NTIMEFRAMES * (orbitsPerTF))                                                   \
                           + ' --seed ' + str(RNDSEED)                                                                         \
                           + ' --noEmptyTF --first-orbit ' + str(args.first_orbit)                                            \

---

# Configure the TPC correction scaling settings for reconstruction; these settings are derived from the anchoring setup.
# Key points from Ruben:
# - lumi-type == 0 indicates that no corrections are scaled with any luminescence measure, rather than no corrections at all.
# - The "no corrections" mode is set by the TPCCorrMap.lumiMean configurable being negative, in which case all other correction options are disregarded.
# - However, if the MC simulation included distortions, then the reconstruction should use --lumy-type 1 (i.e., scaling with CTP luminescence) even if the corresponding anchor run reconstruction used --lumy-type 2 (i.e., scaling according to the non-existent TPC IDC).

---

# convert to set/hashmap
activeDetectors = { det:1 for det in activeDetectors.split(',') }
for detector in activeDetectors:
    activate_detector(detector)

if not args.with_ZDC:
   # deactivate ZDC to ensure consistent use of isActive
   deactivate_detector('ZDC')
   if 'ZDC' in activeDetectors:
       del activeDetectors['ZDC']

def addWhenActive(detID, needslist, appendstring):
   if isActive(detID):
      needslist.append(appendstring)

def retrieve_sor(run_number):
    """
    Retrieves the start of run (sor)
    from the RCT/Info/RunInformation table via a simple http request.
    In case of issues, 0 will be returned. The advantage of this simple http request
    is that it does not require initializing a Ccdb object.
    """

    url="http://alice-ccdb.cern.ch/browse/RCT/Info/RunInformation/"+str(run_number)
    ansobject=requests.get(url)
    tokens=ansobject.text.split("\n")

---

# This task establishes the foundational configuration for all digitizers. All digitization configuration parameters must be specified here.
# The goal of this concise task is to produce the digitization INI file that other tasks can utilize.
contextneeds = [LinkGRPFileTask['name'], SGNtask['name']]
if includeQED:
    contextneeds.append(QED_task['name'])
ContextTask = createTask(name='digicontext_' + str(tf), needs=contextneeds, tf=tf, cwd=timeframeworkdir, lab=["DIGI"], cpu='1')
# This is solely for generating the digitizer INI file
ContextTask['cmd'] = '${O2_ROOT}/bin/o2-sim-digitizer-workflow --only-context --interactionRate ' + str(INTRATE)                               \
                    + ' ' + getDPL_global_options(ccdbbackend=False) + ' -n ' + str(args.ns) + simsoption                                     \
                    + ' --seed ' + str(TFSEED)                                                                                                \

---

#<--------- FDD reconstruction workflow
FDDRECOtask = createTask(name='fddreco_'+str(tf), needs=[getDigiTaskName("FDD")], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1500')
FDDRECOtask['cmd'] = task_finalizer(['${O2_ROOT}/bin/o2-fdd-reco-workflow', 
                                     getDPL_global_options(ccdbbackend=False), 
                                     putConfigValues(),
                                     ('',' --disable-mc')[args.no_mc_labels]])
workflow['stages'].append(FDDRECOtask)

---

# Parameters for GeneratorFromO2Kine are only required prior to transport
   CONFKEY = re.sub(r'GeneratorFromO2Kine.*?;', '', CONFKEY)

---

# TPC configuration options
parser.add_argument('--tpc-distortion-type', default=0, type=int, help='Enable distortions in the TPC simulation (0=no distortions, 1=distortions without scaling, 2=distortions with CTP scaling)')
parser.add_argument('--tpc-corrmap-lumi-mode', default=2, type=int, help='Select TPC corrections mode (0=linear, 1=derivative, 2=derivative for special MC maps)')
parser.add_argument('--ctp-scaler', default=0, type=float, help='CTP raw scaler value for distortion simulation')

# Global Forward Reconstruction Settings
parser.add_argument('--fwdmatching-assessment-full', action='store_true', help='enables comprehensive evaluation of global forward reconstruction')
parser.add_argument('--fwdmatching-4-param', action='store_true', help='excludes q/pt from the matching parameters')
parser.add_argument('--fwdmatching-cut-4-param', action='store_true', help='apply selection cuts on position and angular parameters')

---

DOCUMENT:
    addQCPerTF(taskName='tofPIDQC',
               needs=[TOFTPCMATCHERtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC,ITS-TPC-TRD,ITS-TPC-TRD-TOF,TPC-TRD,TPC-TRD-TOF" --cluster-types none',
              configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/pidtof.json')
     else:
       addQCPerTF(taskName='tofPIDQC',
               needs=[TOFTPCMATCHERtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "ITS-TPC-TOF,TPC-TOF,TPC" --cluster-types none',
              configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/pidtofNoTRD.json')

---

#
# A script that generates a consistent MC->RECO->AOD workflow
# Its goal is to manage different MC configurations
# It generates a workflow.json file, which must be executed by running
#   ${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json
#
# Execution examples:
#  - pp PYTHIA jets, 2 events, triggered by high pT decay photons in all barrel calorimeters acceptance, eCMS at 13 TeV
#     ./o2dpg_sim_workflow.py -e TGeant3 -ns 2 -j 8 -tf 1 -mod "--skipModules ZDC" -col pp -eCM 13000 \
#                             -proc "jets" -ptHatBin 3 \
#                             -trigger "external" -ini "\$O2DPG_ROOT/MC/config/PWGGAJE/ini/trigger_decay_gamma_allcalo_TrigPt3_5.ini"
#
#  - pp PYTHIA ccbar events embedded in a heavy-ion environment, 2 PYTHIA events in 1 background event, beams energy 2.510
#     ./o2dpg_sim_workflow.py -e TGeant3 -nb 1 -ns 2 -j 8 -tf 1 -mod "--skipModules ZDC" \

---

# ===| TPC Digitization Section |===
CTPSCALER = args.ctp_scaler
tpcDistortionType = args.tpc_distortion_type
print(f"TPC distortion simulation type: {tpcDistortionType}, CTP scaler: {CTPSCALER}")
tpcdigineeds = [ContextTask['name'], LinkGRPFileTask['name']]
if usebkgcache:
   tpcdigineeds += [BKG_HITDOWNLOADER_TASKS['TPC']['name']]

tpcLocalCF = {"DigiParams.maxOrbitsToDigitize" : str(orbitsPerTF), "DigiParams.seed" : str(TFSEED)}

# enforce TPC common mode correction in all scenarios to prevent issues with CMk values in the CCDB
tpcLocalCF['TPCEleParam.DigiMode'] = str(2) # 2 = o2::tpc::DigitzationMode::ZeroSuppressionCMCorr from TPCBase/ParameterElectronics.h

---

parser.add_argument('-mod', help='Active modules (deprecated)', default='--skipModules ZDC')
parser.add_argument('--with-ZDC', action='store_true', help='Activate ZDC in the workflow')
parser.add_argument('-seed', help='random seed number', default=None)
parser.add_argument('-o', help='output workflow file', default='workflow.json')
parser.add_argument('--noIPC', help='disable shared memory in DPL')

---

+ ' --extract-per-timeframe tf:sgn'                                                            \
                            + ' --with-vertices ' + vtxmode_precoll                                                        \
                            + ' --maxCollsPerTF ' + str(args.ns)                                                           \
                            + ' --orbits-early ' + str(args.orbits_early)

---

DOCUMENT:
    INIFILE=''
if args.ini != '':
   INIFILE=' --configFile ' + args.ini
PROCESS=args.proc
TRIGGER=''
if args.trigger != '':
   TRIGGER=' -t ' + args.trigger

## Pt Hat productions
WEIGHTPOW=float(args.weightPow)
PTHATMIN=float(args.ptHatMin)
PTHATMAX=float(args.ptHatMax)

colsys = {'pp':[2212,2212], 'pPb':[2212,1000822080], 'Pbp':[1000822080,2212], 'PbPb':[1000822080,1000822080], 'pO':[2212,1000080160], 'Op':[1000080160,2212], 'HeO':[1000020040,1000080160], 'OHe':[1000080160,1000020040], 'OO':[1000080160,1000080160], 'NeNe':[1000100200,1000100200]}
# translate here collision type to PDG of allowed particles
COLTYPE=args.col
if COLTYPE in colsys.keys():
   PDGA=colsys[COLTYPE][0]
   PDGB=colsys[COLTYPE][1]
else:
   print('o2dpg_sim_workflow: Error! Unknown collision system %s' % COLTYPE)
   exit(1)

doembedding=True if args.embedding=='True' or args.embedding==True else False

---

DOCUMENT:
    bkgsimneeds = [BKG_CONFIG_task['name'], GRP_TASK['name'], PreCollContextTask['name']]
    BKGtask = createTask(name='bkgsim', lab=["GEANT"], needs=bkgsimneeds, cpu=NWORKERS)
    BKGtask['cmd'] = '${O2_ROOT}/bin/o2-sim -e ' + SIMENGINE + ' -j ' + str(NWORKERS) + ' -n ' + str(NBKGEVENTS) \
                     + ' -g ' + str(GENBKG) + ' ' + str(MODULES) + ' -o bkg ' + str(INIBKG) \
                     + ' --field ccdb ' + str(CONFKEYBKG) \
                     + ('', ' --timestamp ' + str(args.timestamp))[args.timestamp != -1] + ' --run ' + str(args.run) \
                     + ' --vertexMode kCCDB' \
                     + ' --fromCollContext collisioncontext.root:bkg'

    if not isActive('all'):
        BKGtask['cmd'] += ' --readoutDetectors ' + " ".join(activeDetectors)

---

### TPC
addQCPerTF(taskName='tpcStandardQC',
           needs=[TPCRECOtask['name']],
           readerCommand='o2-tpc-file-reader --tpc-track-reader "--infile tpctracks.root" --tpc-native-cluster-reader "--infile tpc-native-clusters.root" --input-type clusters,tracks',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/tpc-qc-standard-direct.json')

### TRD
addQCPerTF(taskName='trdDigitsQC',
           needs=[TRDDigitask['name']],
           readerCommand='o2-trd-trap-sim',
           configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/trd-standalone-task.json')

---

['--track-sources ' + trd_track_sources,
  tpc_corr_scaling_options, 
  tpc_corr_options_mc])
workflow['stages'].append(TRDTRACKINGtask2)

---

# PDG translation for background
if COLTYPEBKG in colsys.keys():
   PDGABKG = colsys[COLTYPEBKG][0]
   PDGBBKG = colsys[COLTYPEBKG][1]
else:
   print('o2dpg_sim_workflow: Error! Unknown background collision system %s' % COLTYPEBKG)
   exit(1)

PROCESSBKG = args.procBkg
ECMSBKG = float(args.eCM)
EBEAMABKG = float(args.eA)
EBEAMBBKG = float(args.eB)

if COLTYPEBKG == 'PbPb':
   if ECMSBKG < 0:    # set 5.02 TeV as default for Pb-Pb
      print('o2dpg_sim_workflow: Set BKG CM Energy to PbPb case 5.02 TeV')
      ECMSBKG = 5020.0
   if GENBKG == 'pythia8' and PROCESSBKG != 'heavy_ion':
      PROCESSBKG = 'heavy_ion'
      print('o2dpg_sim_workflow: Process type not applicable for Pythia8 PbPb')

---

#<--------- ITS-TPC track matching task 
   ITSTPCMATCHtask=createTask(name='itstpcMatch_'+str(tf), needs=[TPCRECOtask['name'], ITSRECOtask['name'], FT0RECOtask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='8000', relative_cpu=3/8)
   ITSTPCMATCHtask["cmd"] = task_finalizer([
     '${O2_ROOT}/bin/o2-tpcits-match-workflow',
     getDPL_global_options(bigshm=True),
     ' --tpc-track-reader tpctracks.root',
     '--tpc-native-cluster-reader \"--infile tpc-native-clusters.root\"',
     '--use-ft0',
     putConfigValues(['MFTClustererParam', 
                      'ITSCATrackerParam', 
                      'tpcitsMatch', 
                      'TPCGasParam', 
                      'TPCCorrMap', 
                      'ITSClustererParam', 
                      'GPU_rec_tpc', 
                      'trackTuneParams', 
                      'ft0tag'], 
                      {"NameConf.mDirMatLUT" : ".."} | tpcLocalCFreco),
     tpc_corr_scaling_options,

---

#<--------- HMP forward matching
hmpmatchneeds = [HMPRECOtask['name'], ITSTPCMATCHtask['name'], TOFTPCMATCHERtask['name'], TRDTRACKINGtask2['name']]
hmp_match_sources = dpl_option_from_config(anchorConfig, 'o2-hmpid-matcher-workflow', 'track-sources', default_value='ITS-TPC,ITS-TPC-TRD,TPC-TRD')
HMPMATCHtask = createTask(name='hmpmatch_'+str(tf), needs=hmpmatchneeds, tf=tf, cwd=timeframeworkdir, lab=["RECO"], mem='1000')
HMPMATCHtask['cmd'] = task_finalizer(
   ['${O2_ROOT}/bin/o2-hmpid-matcher-workflow',
    '--track-sources ' + hmp_match_sources,
     getDPL_global_options(), 
     putConfigValues()
   ])
workflow['stages'].append(HMPMATCHtask)

---

### MCH + MID
if both 'MCH' and 'MID' are active:
    addQCPerTF(taskName='MCHMIDTracksTaskQC',
               needs=[MCHMIDMATCHtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "MCH,MID,MCH-MID" --cluster-types "MCH,MID"',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mchmid-tracks-task.json')
  
### MCH && MID && MFT || MCH && MFT
if 'MCH', 'MID', and 'MFT' are all active:
    addQCPerTF(taskName='MUONTracksMFTTaskQC',
               needs=[MFTMCHMATCHtask['name'], MCHMIDMATCHtask['name']],
               readerCommand='o2-global-track-cluster-reader --track-types "MFT,MCH,MID,MCH-MID,MFT-MCH,MFT-MCH-MID" --cluster-types "MCH,MID,MFT"',
               configFilePath='json://${O2DPG_ROOT}/MC/config/QC/json/mftmchmid-tracks-task.json')
elif 'MCH' and 'MFT' are active:
    addQCPerTF(taskName='MCHMFTTaskQC',

---

# add embedIntoFile only if embeddPattern includes a '@'
embeddinto = "--embedIntoFile ../bkg_MCHeader.root" if (doembedding and "@" in args.embeddPattern) else ""
if doembedding:
    if not usebkgcache:
        signalneeds.append(BKGtask['name'])
    else:
        signalneeds.append(BKG_HEADER_task['name'])

# (separate) event generation task
sep_event_mode = args.event_gen_mode == 'separated'
sgngenneeds = signalneeds
# for HepMC, we need special handling to ensure different timeframes read distinct events from this file
if GENERATOR == "hepmc" and tf > 1:
    sgngenneeds += signalneeds + ['sgngen_' + str(tf-1)]  # we serialize event generation
SGNGENtask = createTask(name='sgngen_' + str(tf), needs=sgngenneeds, tf=tf, cwd='tf' + str(tf), lab=["GEN"],
                        cpu=8 if args.make_evtpool else 1, mem=1000)

---

#<------------- secondary vertexer
svfinder_threads = ' --threads 1 '
svfinder_cpu = 1
if COLTYPE == "PbPb" or (doembedding and COLTYPEBKG == "PbPb"):
    svfinder_threads = ' --threads 8 '
    svfinder_cpu = 8

svfinder_sources = dpl_option_from_config(anchorConfig,
                                          'o2-primary-vertexing-workflow',
                                          'vertex-track-matching-sources',
                                          default_value='ITS-TPC,TPC-TRD,ITS-TPC-TRD,TPC-TOF,ITS-TPC-TOF,TPC-TRD-TOF,ITS-TPC-TRD-TOF,MFT-MCH,MCH-MID,ITS,MFT,TPC,TOF,FT0,MID,EMC,PHS,CPV,ZDC,FDD,HMP,FV0,TRD,MCH,CTP')
SVFINDERtask = createTask(name='svfinder_'+str(tf), needs=[PVFINDERtask['name'], FT0FV0EMCCTPDIGItask['name']], tf=tf, cwd=timeframeworkdir, lab=["RECO"], cpu=svfinder_cpu, mem='5000')
SVFINDERtask['cmd'] = task_finalizer(
[ '${O2_ROOT}/bin/o2-secondary-vertexing-workflow', 
  getDPL_global_options(bigshm=True),
  svfinder_threads,

---

QED_task['cmd'] = 'o2-sim -e TGeant3 --field ccdb -j ' + str('1') + ' -o qed'                                               \
                  + ' -n ' + str(NEventsQED) + ' -m PIPE ITS MFT FT0 FV0 FDD '                                              \
                  + ('', ' --timestamp ' + str(args.timestamp))[args.timestamp != -1] + ' --run ' + str(args.run)            \
                  + ' --seed ' + str(TFSEED)                                                                                   \
                  + ' -g extgen '                                                                                               \
                  + QEDCONFKEY

QED_task['cmd'] += '; RC=$?; QEDXSecCheck=`grep xSectionQED qedgenparam.ini | sed \'s/xSectionQED=//\'`'
QED_task['cmd'] += '; echo "CheckXSection ' + str(QEDXSecExpected[COLTYPE]) + ' = $QEDXSecCheck"; [[ ${RC} == 0 ]]'
# TODO: dynamically propagate the Xsection ratio

---

if includeAnalysis:
  # incorporate analyses and possibly the final QC upload tasks
  add_analysis_tasks(workflow["stages"], needs=[AOD_merge_task["name"]], is_mc=True, collision_system=COLTYPE)
  if QUALITYCONTROL_ROOT:
     add_analysis_qc_upload_tasks(workflow["stages"], args.productionTag, args.run, "passMC")
else:
   wfneeds=['sgngen_' + str(tf) for tf in range(1, NTIMEFRAMES + 1)]
   tfpool=['tf' + str(tf) + '/genevents_Kine.root' for tf in range(1, NTIMEFRAMES + 1)]
   POOL_merge_task = createTask(name='poolmerge', needs=wfneeds, lab=["POOL"], mem='2000', cpu='1')
   POOL_merge_task['cmd'] = '${O2DPG_ROOT}/UTILS/root_merger.py -o evtpool.root -i ' + ','.join(tfpool)
   # also generate the stat file with the event count

---

DOCUMENT:
    ln -nsf ../bkg_geometry.root bkg_geometry.root;
    ln -nsf ../bkg_geometry-aligned.root bkg_geometry-aligned.root;
    ln -nsf ../bkg_geometry-aligned.root o2sim_geometry-aligned.root;
    ln -nsf ../bkg_MCHeader.root bkg_MCHeader.root;
    ln -nsf ../bkg_grp.root bkg_grp.root;
    ln -nsf ../bkg_grpecs.root bkg_grpecs.root
    '''
    else:
      LinkGRPFileTask=createTask(name='linkGRP_'+str(tf), needs=[SGNtask['name']], tf=tf, cwd=timeframeworkdir, cpu='0', mem='0')
      LinkGRPFileTask['cmd']='ln -nsf ' + signalprefix + '_grp.root o2sim_grp.root ; ln -nsf ' + signalprefix + '_geometry.root o2sim_geometry.root; ln -nsf ' + signalprefix + '_geometry-aligned.root o2sim_geometry-aligned.root'
    workflow['stages'].append(LinkGRPFileTask)

---

DOCUMENT:
    #     ./o2dpg_sim_workflow.py -e TGeant3 -nb 1 -ns 2 -j 8 -tf 1 -mod "--skipModules ZDC"  \
#                             -col pp -eA 2.510 -proc "ccbar"  --embedding
#

    PARAPHRASED DOCUMENT:
    #     ./o2dpg_sim_workflow.py -e TGeant3 -nb 1 -ns 2 -j 8 -tf 1 -mod "--skipModules ZDC"  \
#                             -col pp -eA 2.510 -proc "ccbar"  --embedding
#