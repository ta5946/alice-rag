## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/MC/utils/o2dpg_sim_metrics.py

**Start chunk id:** 06c4d5cd0b92e15310a843b8d6ec256aeb4b51794597ba168a4c2d3a1c176591

## Content

plot_histo_and_pie(categories, resources_per_category[METRIC_NAME_PSS], "category", "$\sum_{i\in\{\mathrm{tasks}\}_\mathrm{category}} \mathrm{PSS}_i\,\,[MB]$", join(out_dir, f"pss_categories.png"), color_map=cmap, title="PSS")

---

DOCUMENT:
    def history(args):
  """
  Entrypoint for history

  Based on specific features (such as centre-of-mass energy or event count), extract various feature values and compare the resources.
  """
  """
  Generate multiple plots for the resource history, along with bar and pie charts for summaries.
  """
  resources = extract_resources(args.pipelines)

  out_dir = args.output
  if not out_dir.exists():
    out_dir.mkdir()

  # visualize the history of all resources
  plot_resource_history(resources, out_dir, args.filter_task, args.suffix, args.names)

  # utilize a consistent color map
  cmap = matplotlib.cm.get_cmap("coolwarm")

  for res in resources:
    name = res.name

    # store in a sub-directory for each analyzed pipeline
    out_dir = out_dir / f"{name}_dir"
    if not out_dir.exists():
      out_dir.mkdir()

    PARAPHRASED DOCUMENT:

---

plot_comparison_parser = sub_parsers.add_parser("compare", help="Compare resources from pipeline_metric file")
plot_comparison_parser.set_defaults(func=compare)
plot_comparison_parser.add_argument("-p", "--pipelines", nargs="*", help="pipeline_metric files generated by o2_dpg_workflow_runner", required=True)
plot_comparison_parser.add_argument("--output", help="output directory for results", default="resource_comparison")
plot_comparison_parser.add_argument("--names", nargs="*", help="assign a custom name to each pipeline")
plot_comparison_parser.add_argument("--feature", help="select the feature to investigate", required=True, choices=FEATURES)

---

# this can be used as an identifier for concatenated dataframes, for example
self.dict_for_df["id"] = [self.timestamp] * length

def convert_columns_to_float_if_possible():
    """
    ensure that numerical values are cast to float where applicable

    In the pipeline_metric, some values might still be in string format
    """
    for rows in self.dict_for_df.values():
      for i, value in enumerate(rows):
        # if we can cast one, we assume we can cast all
        # otherwise, we end up with a mixed list of strings and numbers
        rows[i] = convert_to_float_if_possible(value)

def clean_cpu():
    """
    Correct negative CPU values by setting them to 0
    """
    if METRIC_NAME_CPU not in self.dict_for_df:
      return

    cpu_list = self.dict_for_df[METRIC_NAME_CPU]
    for i, value in enumerate(cpu_list):
      # if negative, set to 0; additionally, divide by 100 as the value represents a percentage
      cpu_list[i] = max(0, value) / 100

---

```python
def convert_to_float_if_possible(value):
  """
  attempt to convert any value to a float
  """
  if isinstance(value, bool):
    # do not cast booleans
    return value
  try:
    return float(value)
  except (TypeError, ValueError):
    pass
  return value


class Resources:
  """
  A wrapper class for managing resources

  this class holds resources in a pandas dataframe and includes additional relevant information
  """

  def __init__(self, pipeline_path=None):
    # this dictionary will be dynamically extended. However, we will manually add one more key, namely the timeframe.
    self.dict_for_df = {"timeframe": [], "category": []}
    self.meta = None
    self.df = None
    self.number_of_timeframes = None
    self.name = None
    # use this as an identifier in the dataframe later
    self.timestamp = int(time_ns() / 1000)

    if pipeline_path:
      self.extract_from_pipeline(pipeline_path)
      self.pipeline_file = pipeline_path
```

---

ax.set_xlabel("tasks", fontsize=40)
ax.set_ylabel(y_label, fontsize=40)
ax.legend(loc="best", fontsize=40)

ax.tick_params(labelsize=40)
ax.tick_params(axis="x", rotation=90)
if title:
    # add user-defined title if provided
    fig.suptitle(title, fontsize=60)
# adjust, save and close
save_figure(fig, save_path)

---

# retrieve distinct task names
task_names = df["name"].unique()
# obtain unique feature values as strings
feature_values = [str(v) for v in df[feature].unique()]
# organize values by task
task_values = {v: [] for v in feature_values}

fig, ax = plt.subplots(figsize=(40, 30))
# iterate through various markers
markers = ["o", "v", "P"]

for i, feat in enumerate(feature_values):
  for task in task_names:
    df_filt = df.query(f"{feature} == {feat} and name == \'{task}\'")
    if df_filt.empty:
      val_append = None
    else:
      # find the maximum value
      val_append = max(df_filt[metric].values)
    task_values[feat].append(val_append)
  label = f"{feature}: {feat}"
  if add_to_legend:
    label = f"{label}, {add_to_legend}"
  ax.plot(task_names, task_values[feat], label=label, lw=0, ms=30, marker=markers[i%len(markers)])

---

DOCUMENT:
    if len(json_pipelines) > 1:
    for av, mi, ma, y_label, me in zip(averages, mins, maxs, y_labels, metrics):
      # this function overlays minima, maxima, and averages
      fig, ax = create_default_figure()
      plot_data(names, av, "pipeline names", y_label, ax, label="average", marker="o", ms=30, linewidth=0)
      plot_data(names, mi, "pipeline names", y_label, ax, label="min", marker="v", ms=30, linewidth=0)
      plot_data(names, ma, "pipeline names", y_label, ax, label="max", marker="P", ms=30, linewidth=0)
      adjust_x_ticks(ax, rotation=90)
      add_legend(ax, loc="best", fontsize=30)
      save_plot(fig, join(out_dir, f"{me}_min_max_average{suffix}.png"))


def plot_resource_history_stacked(res, out_dir, per_what, task_filter=None):
  """
  Plotting resource history

  Include min, max, and average plots, especially useful for analyzing changes in workflow resource requirements.
  """

---

# table name for resources per CPU
tab_name = f"{args.table_base}_workflows_{metric_name}_per_cpu"
# normalize resources to number of CPUs
iterations = [it / n_cpu for it in iterations_y[metric_id]]
# assemble string for InfluxDB and write to file
db_string = f"{tab_name}{tags} minimum={min(iterations)},maximum={max(iterations)},average={sum(iterations) / len(iterations)}"
f.write(f"{db_string}\n")

return 0


def pandas_to_json(args):
  """
  Convert a pipeline_metric file to pandas DataFrame and dump to JSON

  This can be useful for later inspection
  """
  resources_single = extract_resources(args.pipelines)
  resources = resources_single[0]
  for m in resources_single[1:]:
    resources += m
  resources.df.to_json(args.output, indent=2)
  return 0


def main():

  parser = argparse.ArgumentParser(description="Evaluate metrics of O2 simulation workflow")
  sub_parsers = parser.add_subparsers(dest="command")

---

for each jp_i, ranging through json_pipelines:

    name = labels[jp_i]
    n_cpu = jp.meta["cpu_limit"]
    iterations, iterations_y = resources_per_iteration(jp, metrics, task_filter)

    names.append(f"{jp_i}_{name}")

    ls = linestyles[jp_i%len(linestyles)]

    for index, it_y in enumerate(iterations_y):
      if index == 2:
        # for CPU efficiency, we need to scale to the CPU limit; multiply by 100 to express it in percentage
        it_y = [it / n_cpu * 100 for it in it_y]

      average = np.mean(it_y)
      averages[index].append(average)
      mins[index].append(min(it_y))
      maxs[index].append(max(it_y))

      make_plot(iterations, it_y, "sampling iterations", y_labels[index], axes[index], label=f"{name} (Avg: {average:.2f})", ls=ls, linewidth=3)

  for fig, ax, me in zip(figures, axes, metrics):
    ax.legend(loc="best", fontsize=30)
    save_figure(fig, join(out_dir, f"{me}_vs_iterations{suffix}.png"))

---

def line_to_dict(l):
  """
  convert a single line read from a file into JSON format and return as a dictionary
  """
  l = l.strip().split()
  # the first two columns are the date and time from the Python logger
  # NOTE replace "," with "." for milliseconds. This seems valid in Python 3.11 but not in Python 3.9
  date_time = " ".join(l[:2]).replace(",", ".")
  seconds_since_epoch = datetime.fromisoformat(date_time).timestamp()
  # this is to remove the time and other logger fields
  l = " ".join(l[3:])
  # make it JSON readable
  l = l.replace("'", '"')
  l = l.replace("None", "null")
  l = l.replace("False", "false")
  l = l.replace("True", "true")

  try:
    d = json.loads(l)
    d[METRIC_NAME_TIME] = seconds_since_epoch
    return d
  except json.decoder.JSONDecodeError as e:
    # we just ignore this case
    # for example, there might be lines like ***MEMORY LIMIT PASSED !!***
    pass
  return None

---

def calculate_resources_per_category(res):
  """
  Aggregate the peak resource demands of each task within their respective category
  """
  df = res.df[["name", "category", "timeframe"] + METRICS]
  # identify the categories
  categories = [cat for cat in df["category"].unique() if cat is not None]
  resources_per_category = {metric: [0] * len(categories) for metric in METRICS}
  for i, cat in enumerate(categories):
    # filter for the specified category
    df_category = df.query(f"category == '{cat}'")
    task_names = df_category["name"].unique()
    for tn in task_names:
      # filter for the specific task and extract the maximum resource value
      df_name = df_category.query(f"name == '{tn}'")
      for key, current_res in resources_per_category.items():
        # add the extracted maximum value to the corresponding category
        current_res[i] += max(df_name[key].values)

  return categories, resources_per_category

---

self.df = pd.DataFrame(self.dict_for_df)
    self.dict_for_df = None

  def extract_number_of_timeframes(self):
    """
    Wrapper to extract the number of timeframes
    """
    self.number_of_timeframes = max(self.df["timeframe"].values)

  def add_iteration(self, iteration):
    """
    Add one iteration to the dictionary

    Everything on the fly
    and
    determine the timeframe and parent category as well
    """
    for key, value in iteration.items():
      if key == "name":
        try:
          name_split = value.split("_")
          tf_i = int(name_split[-1])
          # we only want to have the name without the timeframe suffix
          value = "_".join(name_split[:-1])
        except ValueError:
          tf_i = 0

        self.dict_for_df["timeframe"].append(tf_i)

        cat = get_parent_category(value)
        self.dict_for_df["category"].append(cat)

---

if norm:
    total = sum(y)
    if total > 0:
      y = [i / total for i in y]

  colors = None
  if cmap:
    # generate colors for better visualization
    step = 1. / len(y)
    colors = [cmap(i * step) for i, _ in enumerate(y)]

  bars = ax.bar(x, y, color=colors, **kwargs)
  if annotate and len(annotate) ==  len(x):
    # add annotations to the bar chart based on given annotations
    for bar, an in zip(bars, annotate):
      height = bar.get_height()
      ax.annotate(f"Avg.: {an:.2f}", xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3), textcoords="offset points", ha='center', va='bottom', rotation=90, fontsize=20)

  ax.set_xticks(range(len(x)))
  ax.set_xticklabels(x)
  ax.tick_params("both", labelsize=30)
  ax.tick_params("x", rotation=90)
  ax.set_xlabel(xlabel, fontsize=30)
  ax.set_ylabel(ylabel, fontsize=30)

  if title:
    figure.suptitle(title, fontsize=40)

  return figure, ax

---

DOCUMENT:
    stat_parser = sub_parsers.add_parser("stat", help="Display a basic summary of resource usage")
    stat_parser.set_defaults(func=stat)
    stat_parser.add_argument("-p", "--pipelines", nargs="*", help="pipeline_metric files from o2_dpg_workflow_runner", required=True)

    plot_parser = sub_parsers.add_parser("history", help="Generate plots from extracted metrics JSON file(s)")
    plot_parser.set_defaults(func=history)
    plot_parser.add_argument("-p", "--pipelines", nargs="*", help="pipeline_metric files from o2_dpg_workflow_runner", required=True)
    plot_parser.add_argument("--output", help="output directory", default="resource_history")
    plot_parser.add_argument("--filter-task", dest="filter_task", help="regex pattern to filter tasks in pipeline iterations")
    plot_parser.add_argument("--suffix", help="append a suffix to the end of the output file names")
    plot_parser.add_argument("--names", nargs="*", help="assign a custom name to each pipeline")

---

# per task within digi category
task_names, resources_per_task = get_resources_per_task_within_category(res, "digi")
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_TIME]["max"], "task", "$\mathrm{walltime}\,\,[s]$", join(out_dir, f"walltimes_tasks_digi.png"), cmap=cmap, title="TIME (digi)")
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_CPU]["max"], "task", "$\max\left(\#\mathrm{CPU}\\right)$", join(out_dir, f"cpu_tasks_digi.png"), cmap=cmap, title="CPU (digi)", annotate=resources_per_task[METRIC_NAME_CPU]["mean"])
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_USS]["max"], "task", "$\max\left(\mathrm{USS}\,\,[MB]\\right)$", join(out_dir, f"uss_tasks_digi.png"), cmap=cmap, title="USS (digi)", annotate=resources_per_task[METRIC_NAME_USS]["mean"])

---

DOCUMENT:
    def make_db_string(names, values, metric_name, sub_key=None):
    # this is the final table name for resources accumulated in categories
    table_suffix = metric_name if sub_key is None else f"{metric_name}_{sub_key}"
    tab_name = f"{args.table_base}_workflows_{table_suffix}"
    # start building the string for the influx file to be uploaded
    db_string = f"{tab_name}{tags}"
    # accumulate the total resources for this metric
    total = 0
    # resource measurements go into the fields and are separated from the tags by a space
    fields = []
    values_to_extract = values[metric_name]
    if sub_key:
      values_to_extract = values_to_extract[sub_key]
    for name, val in zip(names, values_to_extract):
      if sub_key is not None:
        val = val
      fields.append(f"{name}={val}")
      total += val
    # join fields by comma...
    fields = ",".join(fields)
    # ...add to the string and write to file
    db_string += f" {fields},total={total}"

---

DOCUMENT:
    return categories, resources_per_category


def get_resources_per_task_within_category(res, category=None):
    """
    Select one category and retrieve resources from there.
    """
    df = res.df
    if category:
        df = res.df.query(f"category == '{category}'")[["name"] + METRICS]
    task_names = df["name"].unique()
    # the first entry is the maximum, the second the average
    resources_max_mean = {"max": [0] * len(task_names), "mean": [0] * len(task_names)}
    resources_per_task = {metric: deepcopy(resources_max_mean) for metric in METRICS}
    for i, tn in enumerate(task_names):
        # filter by the specific task name and extract the maximum from it
        df_name = df.query(f"name == '{tn}'")
        for key, current_res in resources_per_task.items():
            # add the extracted value to this category
            values = df_name[key].values
            if len(values):
                current_res["max"][i] = max(df_name[key].values)
                current_res["mean"][i] = np.mean(df_name[key].values)

---

# stack on top
      bottom = [b + y for b, y in zip(bottom, it_y)]

    axes[metric_index].legend(loc='lower left', bbox_to_anchor=(0., 1.02, 1., .102), ncols=5, mode="expand", borderaxespad=0., fontsize=30, title=per_what, title_fontsize=40)
    axes[metric_index].set_xticklabels([it if not ((it - 1) % modulo) else None for it in iterations])
    figure.suptitle(y_labels[metric_index], fontsize=50)
    save_figure(figures[metric_index], join(out_dir, f"{metrics[metric_index]}_{per_what}_history_stacked.png"))

---

pandas_json_parser = sub_parsers.add_parser("pandas-json", help="read pipeline_metric file, convert to pandas and write to JSON")
pandas_json_parser.set_defaults(func=pandas_to_json)
pandas_json_parser.add_argument("-p", "--pipelines", nargs="*", help="pipeline file to be converted", required=True)
pandas_json_parser.add_argument("-o", "--output", help="custom output filename", default="df.json")


args = parser.parse_args()
args.func(args)

if __name__ == "__main__":
  sys.exit(main())

---

def influx(args):
  """
  Entry point for influx

  Create a text file for upload to InfluxDB
  """
  # gather the tags provided by the user
  tags = {}
  if args.tags:
    pairs = args.tags.split(";")
    for p in pairs:
      key_val = p.split("=")
      if len(key_val) != 2:
        print(f"WARNING: Invalid key-value pair {p}, skipped")
        continue
      tags[key_val[0]] = key_val[1]

  # initialize the pipeline
  resources = Resources(args.pipeline)
  n_cpu = resources.meta["cpu_limit"]

  # include the number of timeframes in the tags
  tags["ntfs"] = resources.number_of_timeframes
  tags = ",".join([f"{k}={v}" for k, v in tags.items()])
  if tags:
    # prepend a comma
    tags = "," + tags

  # retrieve the history of metrics of interest
  _, iterations_y = resources_per_iteration(resources, METRICS)

---

# Some characteristics of Monte Carlo runs, which can be obtained from the metadata
# These are useful when comparing plots from multiple pipelines based on these characteristics
# For now, let's limit to these arguments from o2dpg_sim_workflow.py
FEATURES = ["col", "eCM", "gen", "ns", "nb", "j", "cpu_limit", "mem_limit"]

# Basic categories to extract metrics from
CATEGORIES_RAW = ["sim", "digi", "reco", "pvfinder", "svfinder", "tpccluster", "match", "aod"]
CATEGORIES_REG = [re.compile(c, flags=re.IGNORECASE) for c in CATEGORIES_RAW]
CATEGORIES_EXCLUDE = ["", "QC", "", "", "", "QC", "QC", ""]

---

# Optional arguments:
#   -h, --help            show this help message and exit
#   -p [PIPELINES ...], --pipelines [PIPELINES ...]
#                         pipeline_metric files from o2_dpg_workflow_runner
#   --output OUTPUT       output_directory
#   --names [NAMES ...]   assign a custom name to each pipeline
#   --feature {col,eCM,gen,ns,nb,j,cpu_limit,mem_limit}
#                         feature to be investigated

# Generate a file for upload to InfluxDB containing various metrics akin to those produced by history
# usage: o2dpg_sim_metrics_df.py influx [-h] -p PIPELINE [--table-base TABLE_BASE] [--output OUTPUT] [--tags TAGS]

---

plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_PSS]["max"], "task", "$\max\left(\mathrm{PSS}\,\,[MB]\\right)$", join(out_dir, f"pss_tasks_digi.png"), color_map=cmap, title="PSS (digi)", annotate=resources_per_task[METRIC_NAME_PSS]["mean"])

---

#!/usr/bin/env python3

import sys
from os.path import join, exists, basename
from os import makedirs
from copy import deepcopy
import argparse
import re
from datetime import datetime
from time import time_ns
import matplotlib.pyplot as plt
import matplotlib
import json
import numpy as np
import pandas as pd

###############################################################################
#                                                                                #
# Script to examine resource consumption (CPU, memory, and time) for simulation workflows #
#                                                                                #
###############################################################################
# Plot history and resource demands for various simulation workflow categories (simulation, digitization, reconstruction): subcommand history
# usage: o2dpg_sim_metrics_df.py history [-h] -p [PIPELINES ...] [--output OUTPUT] [--filter-task FILTER_TASK] [--suffix SUFFIX]

---

# optional arguments:
#   -h, --help            show this help message and exit
#   -p PIPELINE, --pipeline PIPELINE
#                         a single pipeline_metric file from o2_dpg_workflow_runner to prepare for InfluxDB
#   --table-base TABLE_BASE
#                         base name for the InfluxDB table
#   --output OUTPUT, -o OUTPUT
#                         name of the output file
#   --tags TAGS           key-value pairs separated by ";", for example: alidist=1234567;o2=7654321;tag=someTag

METRIC_NAME_CPU = "cpu"
METRIC_NAME_USS = "uss"
METRIC_NAME_PSS = "pss"
METRIC_NAME_TIME = "time"

# metrics extracted by o2_dpg_workflow_runner and logged in pipeline_metric*.log
METRICS = [METRIC_NAME_CPU, METRIC_NAME_USS, METRIC_NAME_PSS, METRIC_NAME_TIME]

---

DOCUMENT:
    cat = get_parent_category(value)
    self.dict_for_df["category"].append(cat)

    if key not in self.dict_for_df:
        # dynamically extend the dictionary
        self.dict_for_df[key] = []
    # add the value
    self.dict_for_df[key].append(value)

  def extract_from_pipeline(self, pipeline_path):
    """
    read a pipeline_metric file and populate a dataframe with the data
    """
    if not exists(pipeline_path):
      print(f"ERROR: pipeline_metrics file not found at {pipeline_path}")
      return False

    self.name = basename(pipeline_path)

    with open(pipeline_path, "r") as f:
      for l in f:
        d = line_to_dict(l)
        if not d:
          continue

---

def calculate_time_difference(self):
    """
    Convert absolute timestamps to relative differences
    """
    timestamps = self.dict_for_df[METRIC_NAME_TIME]
    task_identifiers = self.dict_for_df["name"]
    timeframes = self.dict_for_df["timeframe"]
    # obtain the start times for each individual task
    initial_times = {}
    for index, (timestamp, task_id, timeframe) in enumerate(zip(timestamps, task_identifiers, timeframes)):
      timeframe = int(timeframe)
      # calculate the time difference relative to the minimum
      if task_id not in initial_times:
        initial_times[task_id] = []
      if len(initial_times[task_id]) < timeframe:
        initial_times[task_id].extend([None] * (timeframe - len(initial_times[task_id]) + 1))
      if initial_times[task_id][timeframe] is None:
        initial_times[task_id][timeframe] = timestamp
      timestamps[index] = timestamp - initial_times[task_id][timeframe]

  def transform_to_dataframe(self):
    """
    Function to convert the dictionary into a DataFrame
    """
    if not self.dict_for_df:
      return

    self.df = pd.DataFrame(self.dict_for_df)
    self.dict_for_df = None

---

# per task within reco category
task_names, resources_per_task = get_resources_per_task_within_category(res, "reco")
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_TIME]["max"], "task", "$\mathrm{walltime}\,\,[s]$", join(out_dir, f"walltimes_tasks_reco.png"), cmap=cmap, title="TIME (reco)")
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_CPU]["max"], "task", "$\max\left(\#\mathrm{CPU}\\right)$", join(out_dir, f"cpu_tasks_reco.png"), cmap=cmap, title="CPU (reco)", annotate=resources_per_task[METRIC_NAME_CPU]["mean"])
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_USS]["max"], "task", "$\max\left(\mathrm{USS}\,\,[MB]\\right)$", join(out_dir, f"uss_tasks_reco.png"), cmap=cmap, title="USS (reco)", annotate=resources_per_task[METRIC_NAME_USS]["mean"])

---

if title:
    figure.suptitle(title, fontsize=40)

return figure, ax


def make_plot(x, y, xlabel, ylabel, ax=None, **kwargs):
  """
  Create a plot

  parameters:
    x, y: iterables
      values for the x- and y-axes
    xlabel, ylabel: str
      labels for the x- and y-axes
    ax: matplotlib.pyplot.Axes (optional)
      axes to plot on
    cmap: matplotlib.colors.Colormap
      color the segments based on their size
    norm: bool
      whether to normalize to the histogram's total sum
    title:
      title for the figure
  """

  figure, ax = make_default_figure(ax)

  if not x or not y:
    print("No data available for plotting...")
    return figure, ax

  ax.plot(x, y, **kwargs)
  ax.tick_params("both", labelsize=30)
  ax.tick_params("x", rotation=45)
  ax.set_xlabel(xlabel, fontsize=30)
  ax.set_ylabel(ylabel, fontsize=30)

  return figure, ax


def make_pie(labels, y, ax=None, cmap=None, title=None, **kwargs):
  """
  Generate a pie chart

---

# per single task
task_names, resources_per_task = get_resources_per_task_within_category(res)
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_TIME]["max"], "task", "$\mathrm{walltime}\,\,[s]$", join(out_dir, f"walltimes_tasks.png"), cmap=cmap, title="TIME")
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_CPU]["max"], "task", "$\max\left(\#\mathrm{CPU}\right)$", join(out_dir, f"cpu_tasks.png"), cmap=cmap, title="CPU", annotate=resources_per_task[METRIC_NAME_CPU]["mean"])
plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_USS]["max"], "task", "$\max\left(\mathrm{USS}\,\,[MB]\right)$", join(out_dir, f"uss_tasks.png"), cmap=cmap, title="USS", annotate=resources_per_task[METRIC_NAME_USS]["mean"])

---

# the metrics we aim to extract
metrics = (METRIC_NAME_PSS, METRIC_NAME_USS, METRIC_NAME_CPU)
# corresponding y-axis labels
y_labels = ("PSS [MB]", "USS [MB]", "CPU efficiency [%]")
figures = []
axes = []
for _ in metrics:
    # gathering the figures and axes for plotting
    figure, ax = make_default_figure()
    figures.append(figure)
    axes.append(ax)

# names for the legends
names = []

# collect to plot them together in another overlay plot
averages = [[] for _ in metrics]
mins = [[] for _ in metrics]
maxs = [[] [[] for _ in metrics]

# to distinguish between resources from different pipelines visually
linestyles = ["solid", "dashed", "dashdot"]
labels = labels if labels and len(labels) == len(json_pipelines) else [jp.name for jp in json_pipelines]

---

influx_parser = sub_parsers.add_parser("influx", help="Convert data into a format suitable for InfluxDB")
influx_parser.set_defaults(func=influx)
influx_parser.add_argument("-p", "--pipeline", help="specify exactly one pipeline_metric file from o2_dpg_workflow_runner for InfluxDB preparation", required=True)
influx_parser.add_argument("--table-base", dest="table_base", help="set the base name for the InfluxDB table", default="O2DPG_MC")
influx_parser.add_argument("--output", "-o", help="define the output file name", default="metrics_influxDB.dat")
influx_parser.add_argument("--tags", help="provide key-value pairs separated by \";\", for example: alidist=1234567;o2=7654321;tag=someTag")

---

# ...append to the string and write to file
db_string += f" {fields},total={total}"
return db_string

---

# per category
categories, resources_per_category = get_resources_per_category(res)
plot_histo_and_pie(categories, resources_per_category[METRIC_NAME_TIME], "category", "$\sum_{i\in\{\mathrm{tasks}\}_\mathrm{category}} \mathrm{walltime}_i\,\,[s]$", join(out_dir, f"walltimes_categories.png"), cmap=cmap, title="Wall Time")
plot_histo_and_pie(categories, resources_per_category[METRIC_NAME_CPU], "category", "$\sum_{i\in\{\mathrm{tasks}\}_\mathrm{category}} \#\mathrm{CPU}_i$", join(out_dir, f"cpu_categories.png"), cmap=cmap, title="CPU Usage")
plot_histo_and_pie(categories, resources_per_category[METRIC_NAME_USS], "category", "$\sum_{i\in\{\mathrm{tasks}\}_\mathrm{category}} \mathrm{USS}_i /\,\,[MB]$", join(out_dir, f"uss_categories.png"), cmap=cmap, title="USS")

---

DOCUMENT:
    categories, values_categories = get_resources_per_category(resources)
    tasks, values_tasks = get_resources_per_task_within_category(resources)
    with open(args.output, "w") as f:
        for metric_id, metric_name in enumerate(METRICS):
            # write for categories
            db_string = make_db_string(categories, values_categories, metric_name)
            f.write(f"{db_string}\n")
            # write for single tasks
            db_string = make_db_string(tasks, values_tasks, metric_name, "max")
            f.write(f"{db_string}\n")
            db_string = make_db_string(tasks, values_tasks, metric_name, "mean")
            f.write(f"{db_string}\n")

            if metric_name == METRIC_NAME_TIME:
                # skip the following for time; using min, max and average does not make sense here
                continue

---

DOCUMENT:
    for metric_index, _ in enumerate(metrics):
     # checkpoints to be added
    last_appearance = [""] * len(iterations)
    # add current to stack
    bottom = [0] * len(iterations)
    per_what_values = list(iterations_y.keys())
    per_what_values.sort()
    for hatch_index, per_what_value in enumerate(per_what_values):
      it_y = iterations_y[per_what_value][metric_index]
      if metric_index == 2:
        # for CPU efficiency, we need to scale to the CPU limit; multiply by 100 to express it as a percentage
        it_y = [it / n_cpu * 100 for it in it_y]
      # determine where the last appearance was to attach it to the legend label
      last_appearance = iterations[get_last_appearance(it_y)]
      make_histo([i for i, _ in enumerate(it_y)], it_y, "sampling iterations", y_labels[metric_index], axes[metric_index], label=f"{per_what_value} (last appeared at {last_appearance})", bottom=bottom, sort=False, norm=False, hatch=hatches[hatch_index%len(hatches)])

---

DOCUMENT:
    return 0


def compare(args):
  """
  Entrypoint for comparison

  Depending on a specific feature (e.g., centre-of-mass energy or number of events), extract all distinct feature values
  and compare the resources.
  """
  # accumulate all resources
  resources_single = extract_resources(args.pipelines)
  resources = resources_single[0]
  for m in resources_single[1:]:
    resources += m

  # proceed with the dataframe, skim it to the necessary data
  df_full = resources.df[["name", "timeframe", "col", args.feature] + METRICS]

  def plot_resources_versus_tasks(df, metric, feature, y_label, save_path, title=None, add_to_legend=None, select=None):
    """
    Plot resources against tasks
    """
    if select:
      # filter based on the query if any
      df = df.query(select)

---

DOCUMENT:
    if "iter" in d:
          # This is an iteration, add it to the dictionary
          self.add_iteration(d)
          continue
        if not self.meta:
          # At this point, the only other line in the pipeline_metric is the meta information, so when we reach here, it indicates meta information
          self.meta = {}
          # remove the time from the meta information, as it's only relevant for iterations and would overwrite those values
          del d[METRIC_NAME_TIME]
          for key, value in d.items():
            self.meta[key] = convert_to_float_if_possible(value)

    if not self.check():
      return False

    self.add_meta()
    self.convert_columns_to_float_if_possible()
    self.clean_cpu()
    self.compute_time_delta()
    self.put_in_df()
    self.extract_number_of_timeframes()


def make_default_figure(ax=None, **fig_args):
  """Create a default figure with one axis

    """

---

DOCUMENT:
    def __add__(self, other):
    """
    Enables the addition of Resource objects
    """
    res = Resources()
    res.df = pd.concat([self.df, other.df], ignore_index=True)
    res.number_of_timeframes = self.number_of_timeframes + other.number_of_timeframes
    return res

  def verify(self):
    """
    Ensures the dictionary is complete for dataframe insertion
    """
    length = None
    for key, rows in self.dict_for_df.items():
      if length is None:
        length = len(rows)
        continue
      if length != len(rows):
        print(f"Key {key} has a different number of rows ({len(rows)}) compared to the expected ({length})")
        return False
    return True

  def include_metadata(self):
    """
    Adds rows for metadata information
    """
    length = len(self.dict_for_df[list(self.dict_for_df.keys())[0]])
    for key, value in self.meta.items():
      self.dict_for_df[key] = [value] * length

---

DOCUMENT:
    def resources_per_iteration(resources, fields, task_filter=None, per_what=None):
  """
  Extract specified fields from the pipeline based on a potential regex filter.
  """
  df = resources.df
  if task_filter:
    # filter on task names (which can include "|" for "or")
    df = df[df["name"].str.contains(task_filter)]

  iterations = df["iter"].unique()
  start = int(min(iterations))
  end = int(max(iterations))

  # each sub-list provides the corresponding resource value per iteration
  # iterations in pipeline_metric begin at 1
  values = [[0] * (end - start + 1) for _ in fields]

  # ensure fields is a list (e.g., in case it is a tuple)
  fields = list(fields)
  # columns to be selected
  columns = fields.copy()

  if per_what:
    what_values = df[per_what].dropna().unique()
    columns.append(per_what)
    values = {tn: deepcopy(values) for tn in what_values}

---

if not exists(args.output):
  makedirs(args.output)
plot_resources_versus_tasks(df_full, METRIC_NAME_CPU, args.feature, "# CPU", join(args.output, f"{args.feature}_cpu.png"), "system: pp", select="col == 'pp'")
plot_resources_versus_tasks(df_full, METRIC_NAME_USS, args.feature, "USS [GB]", join(args.output, f"{args.feature}_uss.png"), "system: pp", select="col == 'pp'")
plot_resources_versus_tasks(df_full, METRIC_NAME_PSS, args.feature, "PSS [GB]", join(args.output, f"{args.feature}_pss.png"), "system: pp", select="col == 'pp'")
plot_resources_versus_tasks(df_full, METRIC_NAME_TIME, args.feature, "time [s]", join(args.output, f"{args.feature}_time.png"), "system: pp", select="col == 'pp'")


def influx(args):
  """
  Entry point for influx

  """

---

if title:
    figure.suptitle(title, fontsize=40)

return figure, ax


def plot_histo_and_pie(x, y, xlabel, ylabel, path, annotate=None, **kwargs):
  """
  Create 3 subplots:
  1. absolute values
  2. relative values
  3. pie chart of relative values

  parameters:
    x, y: iterables
      values for x- and y-axis
    xlabel, ylabel: str
      labels for x- and y-axis
    path: str
      location to save the figure
    kwargs: dict
      title: str
        title for the figure
      scale: float
        scaling factor before plotting
  """
  figure, axes = plt.subplots(1, 2, figsize=(40, 20))

  if not x or not y:
    print("No data available for plotting...")
    return

  title = kwargs.pop("title", None)
  scale = kwargs.pop("scale", 1.)
  y = [i * scale for i in y]
  make_histo(x, y, xlabel, ylabel, axes[0], norm=False, annotate=annotate, **kwargs)
  make_pie(x, y, axes[1], **kwargs)
  if title:
    figure.suptitle(title, fontsize=60)
  save_figure(figure, path)

---

DOCUMENT:
    return task_names, resources_per_task


def extract_resources(pipelines):
    """
    A convenience function for extracting resources
    """
    # Gather all metrics we obtained, with the goal of obtaining the median from all iterations
    return [Resources(p) for p in pipelines]


def print_statistics(resource_object):
  """
  Outputs resource statistics for a dataframe of pipeline resources
  """
  print ("<--- Summary of extracted resources from file ", resource_object.pipeline_file)
  dframe = resource_object.df
  meta = resource_object.meta

  # estimate the runtime based on the maximum iteration
  max_iter = dframe['iter'].max()
  print ("Iterations: ", max_iter)
  # each iteration is estimated to take 5 seconds in the pipeline runner -- this should be made more dynamic and adaptive
  print ("Estimated runtime (s): ", max_iter * 5)

---

# generate stacked bar charts across iterations
# based on task
plot_resource_history_stacked(res, out_dir, per_what="name", task_filter=args.filter_task)
# based on timeframe
plot_resource_history_stacked(res, out_dir, per_what="timeframe", task_filter=args.filter_task)
# based on category
plot_resource_history_stacked(res, out_dir, per_what="category", task_filter=args.filter_task)

# the subsequent bar charts depict the peak resource demands for each task throughout all iterations

---

# Optional arguments:
#   -h, --help            display help message and exit
#   -p [PIPELINES ...], --pipelines [PIPELINES ...]
#                         pipeline_metric files from o2_dpg_workflow_runner
#   --output OUTPUT       specify output_directory
#   --filter-task FILTER_TASK
#                         regex to filter pipeline iterations by certain task names
#   --suffix SUFFIX       append a suffix to the end of output file names

# Compare simulation workflow resource usage for varying parameters such as center-of-mass energy, number of events, etc.: subcommand history
# usage: o2dpg_sim_metrics_df.py compare [-h] -p [PIPELINES ...] [--output OUTPUT] [--names [NAMES ...]] --feature {col,eCM,gen,ns,nb,j,cpu_limit,mem_limit}

---

for iteration in iterations:
    list_index = iteration - start
    df_skim = df.query(f"iter == {iteration}")[columns]
    if df_skim.empty:
      continue
    for index, field in enumerate(fields):
      if per_what:
        for _, row in df_skim.iterrows():
          per_what_value = row[per_what]
          if not per_what_value:
            continue
          values[per_what_value][index][list_index] += row[field]
        continue
      values[index][list_index] = sum(df_skim[field].values)

  return list(range(start, end + 1)), values


def plot_resource_history(json_pipelines, out_dir, task_filter=None, suffix="", labels=None):
  """
  Plotting the history of resources

  Include min, max, and average values, especially helpful for examining changes in the resources required by the workflow.
  """
  suffix = f"_{suffix}" if suffix else ""

---

plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_PSS]["max"], "task", "$\max\left(\mathrm{PSS}\,\,[MB]\\right)$", join(out_dir, f"pss_tasks.png"), cmap=cmap, title="PSS", annotate=resources_per_task[METRIC_NAME_PSS]["mean"])

---

def get_matching_category(proposed):
  """
  Associate a primary category with a suggested sub-category
  """
  cat = [cr for cr, creg, ce in zip(CATEGORIES_RAW, CATEGORIES_REG, CATEGORIES_EXCLUDE) if creg.search(proposed) and (not ce or ce not in proposed)]
  if not cat:
    return None
  if len(cat) != 1:
    print(f"ERROR: Multiple categories found")
    return None
  return cat[0]

---

# the metrics we aim to extract
metrics = (METRIC_NAME_PSS, METRIC_NAME_USS, METRIC_NAME_CPU)
# corresponding y-axis labels
y_labels = ("PSS [MB]", "USS [MB]", "CPU efficiency [%]")
figures = []
axes = []
for _ in metrics:
    # gathering figures and axes for plotting
    figure, ax = make_default_figure(figsize=(60, 20))
    figures.append(figure)
    axes.append(ax)

n_cpu = res.meta["cpu_limit"]
iterations, iterations_y = resources_per_iteration(res, metrics, task_filter, per_what=per_what)

# print every modulo iteration on the x-axis for better readability
modulo = 10**(max(0, len(str(len(iterations))) - 2))
# enhance bar visibility with hatches
hatches = ["/", "|", "-", "+", "*", "x"]

def find_last_non_zero(it_y):
    """
    helper function to locate the last non-zero value and return its index
    """
    for index, y in reversed(list(enumerate(it_y))):
        if y:
            return index
    return 0

---

plot_histo_and_pie(task_names, resources_per_task[METRIC_NAME_PSS]["max"], "task", "$\max\left(\mathrm{PSS}\,\,[MB]\\right)$", join(out_dir, f"pss_tasks_reco.png"), cmap=cmap, title="Peak Resident Set Size (reco)", annotate=resources_per_task[METRIC_NAME_PSS]["mean"])

---

```python
args:
x, y: iterables
  x- and y-axis values
xlabel, ylabel: str
  labels for the x- and y-axis
ax: matplotlib.pyplot.Axes (optional)
  the axes on which to plot the histogram
cmap: matplotlib colormap
  color the histogram pieces based on their size
norm: bool
  whether to normalize the histogram to its total sum
title: str
  title for the figure
  """  

  figure, ax = make_default_figure(ax)

  if not x or not y:
    print("No data for plotting...")
    return figure, ax

  # reorder x-tick labels based on ascending y-values
  if sort:
    y = y.copy()
    if annotate and len(annotate) == len(y):
      annotate = [i for _, i in sorted(zip(y, annotate))]
    x = [i for _, i in sorted(zip(y, x))]
    y.sort()

  if norm:
    total = sum(y)
    if total > 0:
      y = [i / total for i in y]
```

---

DOCUMENT:
        def create_default_figure(ax=None, **fig_args):
  """Create a default figure with one axes

  args:
    ax: matplorlib.pyplot.Axes (optional)
  """
  if ax is None:
    fig_args["figsize"] = fig_args.get("figsize", (20, 20))
    return plt.subplots(**fig_args)
  else:
    return ax.get_figure(), ax


def save_plot(figure, file_path):
  """
  Encapsulate the final steps of plot creation, including tight layout, saving, and closing

  args:
    figure: matplotlib.pyplot.Figure
      the figure to be saved
    file_path: str
      the location for saving
  """
  figure.tight_layout()
  figure.savefig(file_path, bbox_inches="tight")
  plt.close(figure)


def generate_histogram(data_x, data_y, x_label, y_label, ax=None, color_map=None, normalize=True, plot_title=None, sort_data=True, annotate_values=None, **extra_kwargs):
  """
  Generate a histogram

---

#(a) PSS memory
  summed_pss_per_iter = dframe.groupby("iter")['pss'].sum()
  mean_pss = summed_pss_per_iter.mean()
  max_pss = summed_pss_per_iter.max()
  print ("Mean-PSS (MB): ", mean_pss)
  print ("Max-PSS (MB): ", max_pss)

  #(b) CPU consumption
  summed_cpu_per_iter = dframe.groupby("iter")['cpu'].sum()
  mean_cpu = summed_cpu_per_iter.mean()
  max_cpu = summed_cpu_per_iter.max()
  print ("Mean-CPU (cores): ", mean_cpu)
  print ("Max-CPU (cores): ", max_cpu)
  print ("CPU-efficiency: ", mean_cpu / meta["cpu_limit"])
  print ("---> ")

def stat(args):
  """
  Providing basic global statistics of resource usage
  """
  resources = extract_resources(args.pipelines)
  # iterate over all resource objects and generate individual statistics
  for res in resources:
    print_statistics(res)


def history(args):
  """
  Entrypoint for resource history
  """

---

def create_pie_chart(labels, y, ax=None, cmap=None, title=None, **kwargs):
  """
  Create a pie chart

  parameters:
    labels: iterable of str
      labels for each slice of the pie
    y: iterable
      sizes of each slice relative to others
    cmap: matplotlib colormap
      assign colors to slices based on their size
    title: str
      title for the chart
  """
  figure, ax = set_default_figure(ax)

  if not labels or not y:
    print("No data to plot...")
    return figure, ax

  y = y.copy()
  labels = [l for _, l in sorted(zip(y, labels))]
  y.sort()
  colors = None
  if cmap:
    step = 1. / len(y)
    colors = [cmap(i * step) for i, _ in enumerate(y)]
  explode = [0.05 for _ in y]
  ax.pie(y, explode=explode, labels=labels, autopct="%1.1f%%", startangle=90, textprops={"fontsize": 30}, colors=colors)
  ax.axis("equal")

  if title:
    figure.suptitle(title, fontsize=40)

  return figure, ax