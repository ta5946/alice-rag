## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/MC/doc/WorkflowRunner.md

**Start chunk id:** 220f8910e4c81d12e79c8f58b0d82f6295fada154d0f53a1bd5846b73566bbaf

## Content

WHILE A WORKFLOW CAN BE HAND-Written, it is more practical to generate it programmatically via scripts that are adaptable to configuration and options. An example of such a workflow, following the PWGHF embedding exercise, can be found here: [create_embedding_workflow](https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGHF/create_embedding_workflow.py).

This create script essentially mirrors the previous `dpg_sim.sh` process.

A special task named '__global_init_task__' can be set as the initial task in the workflow. The environment data from this task will be utilized by the runtime engine to pass global environment variables to all subsequent tasks within the workflow.

# Workflow Example:

A workflow that performs a standard background simulation, followed by two periods of signal MC, digitization, reconstruction, and AOD could be visualized as follows:

![workflowgraph](./workflow.gv.png)

## Example Usage

---

This is the documentation for the `o2_dpg_workflow_runner.py` tool.

**This document reflects preliminary ideas and is subject to change and adaptation.**

# Purpose

The tool is designed for executing O2 Data Processing Graph (DPG) workflows under resource constraints, potentially scheduling tasks in parallel. In essence, it can handle any directed acyclic graph (DAG) workflow, not just DPG ones. The focus is on **how** tasks are executed, rather than **what** is executed or how it is configured.

# More Detailed Description

The tool offers features typical of a data/task pipelining environment using a DAG approach. It distinguishes between workflow setup and execution, enabling optimization during runtime. While it draws inspiration from similar concepts in ALICE alibuild and the ALICE Data Processing Layer (DPL), there are notable differences.

---

The objectives of the tool include:

- automatic task parallelization (both within and across timeframes)
- scalability from running on nodes with few cores to large HPC cores (achieved through automatic parallelism of timeframes)
- capabilities for restarting tasks in case of failures
- skipping tasks that have already been completed when the input remains unchanged
- reprocessing only the affected stages when the input data differs
- automatic skipping of tasks that are deemed irrelevant for the current objective
- tracking of file provenance and cleanup of intermediate products
- the aspiration of automatically fusing or pipelining DPL workflows (e.g., from TPC digitization to TPC reconstruction) to eliminate the need for intermediate files stored on disc

# Workflow specification

The tool executes workflows defined in JSON format. The details of this format are still under development. Currently, it adheres to the following structure:

---

![workflowgraph](./workflow.gv.png)

## Example Usage

Create a simulation workflow (refer to the example in the graph), for instance using [create_embedding_workflow.py](https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGHF/create_embedding_workflow.py):
```
./create_embedding_workflow.py -e TGeant3 -nb 1 -ns 10 -j 8 -tf 2 
```

Execute the workflow in a specified file:
```
alienv enter O2/latest O2DPG/latest
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json
```

Preview the commands that would be executed:
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --dry-run
```

Run the workflow in a serialized mode (one task at a time):
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json -jmax 1
```

Generate a shell script to run the workflow in a serialized manner:
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --produce-script foo.sh
```

---

FURTHER KEYS ARE DEFINED AS FOLLOWS:
| field | description |
| ----- | ----------- |
| `resources` | estimated resource usage, expressed as 250 for 2.5 CPUs and in MB for maximum memory; used in scheduling; -1 indicates unknown or unspecified. |
| `timeframe` | timeframe index, or -1 if unrelated to any timeframe; may affect execution order (prefer finish timeframe). |
| `cwd` | the working directory for task execution. |
| `label` | a list of labels describing the stage; useful for stage-wise execution (e.g., 'all digitization', 'ITS tasks'). |
| `env` | local environment variables required by the task. |
| `semaphore` | (optional) Synchronizes tasks using a named semaphore, allowing exclusion of parallel tasks with the same semaphore name. |

---

Redo a specific task and all its related dependencies in the workflow (this is only applicable if this is not the initial run of the workflow)
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --rerun-from tpcdigi_1
```

Execute the workflow for tasks that match trdtrap (regular expressions are supported)
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --target-tasks trdtrap
```

Run all tasks marked as "RECO"
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --target-stages RECO
```

Rerun the workflow until AOD, excluding tasks that have already been completed (task skipping is the default behavior)
```
${O2DPG_ROOT}/MC/bin/o2_dpg_workflow_runner.py -f workflow.json --target-stages AOD
```

# To-Do / Desired Feature List

* manage environment and environment variables
* optimize task skipping directly within the runner rather than in the taskwrapper (for performance improvements)
* enhance rerun functionality to work with labels as well (--rerun-from RAW)

---

```
{
  "stages": [
    {
      "name": "task1",
      "cmd": "o2-sim-serial -n 1 -m PIPE ITS",
      "needs": [],
      "resources": {
        "cpu": -1,
        "mem": -1
      },
      "timeframe": 1,
      "labels": [ "MC" ],
      "cwd": "tf1"
    },
    {
      "name": "task2",
      "env": { "MY_ENV": "1" },
      "cmd": "o2-sim-digitizer-workflow",
      "needs": [ "task1" ],
      "resources": {
        "cpu": -1,
        "mem": -1,
      },
      "timeframe": 1,
      "labels": [ "DIGI", "ITS" ],
      "cwd": "tf1",
      "semaphore" : "sem1"
    }]
  "comments" : "A DPG MC workflow for production FOO"
}
```
In this workflow, two tasks, `task1` and `task2`, are defined. `task1` runs a basic MC transport simulation, while `task2` performs a digitization process. `task2` depends on the successful completion of `task1`, as indicated by the `needs` list.

```

---

* enable parallel task scheduling
* ensure resource awareness (e.g., prevent scheduling two memory-intensive tasks simultaneously)
* support scheduling a variety of tasks, including executables, bash scripts, ROOT macros, and DPL workflows.

Common workflows managed by this tool include intricate bash scripts with interconnected parts, alongside a combination of DPL workflows, transport simulations, quality assurance steps, file operations, and validation procedures.