## Metadata

**Document link:** https://github.com/AliceO2Group/simulation/blob/main/additional_resources/talks/O2_AnalysisTutorial_April2023/ALICE-Run3-MC-HowTo_Transcript.md

**Start chunk id:** 066287f563f19718b23af5264fcd6a252aeb7cfdb3fa367c574c189879e21feb

## Content

Sure, here is the paraphrased document:

First, it's important to know that users require a valid alien token to access calibration and condition objects from CCDB, as these objects are stored on the ALICE GRID and require authentication. Additionally, our Monte Carlo workflows are designed to run efficiently on an environment with eight CPU cores and at least 16 gigabytes of RAM, which mirrors the standard resources available on GRID compute nodes. This is the same setup you should use when running the Monte Carlo workflow on your local laptop.

---

By default, Geant4 is always enabled. To use Geant3, you would opt for the second example, but we aim to promote Geant4 in Run3, which is why it is the default choice. The third example might be useful for analyzing pure generator output; here, you simply call the generator part to produce 10 Pythia8 pp events without any further transport. The kinematics file will contain only the generated events. As mentioned earlier, or perhaps also noted, the --help command provides a list of main options and displays the default settings we are using.

---

Now let's delve into the workflow creation process with some essential basic features.
The workflow creation is managed by the Python script o2dpg_sim_workflow.py, included in O2DPG.
This script allows you to configure your Monte Carlo simulation based on key user parameters.
For instance, you would run this script with parameters like the collision system, event generator, number of time frames, events per frame, interaction rate, and more.

Additionally, there is an option to specify a run number. In this example, the script generates an ALICE Run3 Monte Carlo workflow for five time frames, each containing 2000 events, for 14 TeV proton-proton collisions.

---

Sure, let's move on to discuss an area that borders physics analysis in terms of detector simulation. My aim is to provide you with practical insights on how, as an analyst, you can execute Run3 detector simulations and integrate them into your workflow. While this might be more introductory in nature, I hope to give you a broad overview of the Run3 simulation environment and a foundational understanding of how to operate it.

---

All of this is quite standard, so I won't delve into the details too much. However, I want to highlight that in ALICE RUN3, the detector transport simulation in o2-sim has been enhanced to be a scalable, multi-core simulation with sub-event parallelism. This means we can utilize powerful servers and compute nodes to rapidly process individual large events or collisions, drastically reducing the time neededâ€”instead of waiting hours for one event to complete, we can get results in just a few minutes.

Another unrelated point about o2-sim is that it processes events or collisions independently, without considering any time frame. This timeframe concept is introduced much later during the digitization stage, when we generate the detector sensor data.

---

Certainly something helpful for debugging is to transform the entire process into a straightforward shell script. Rather than running the workflow in its graphical interface, you can convert the workflow description into a linear shell script and execute it directly. This approach is beneficial for debugging or other scenarios. Additionally, there are numerous other useful features available; you can check the help menu for more details or reach out to the developers via the Mattermost channel.

---

Sure, here's the paraphrased document:

Okay, let's discuss the basic concepts behind setting up and conducting Monte Carlo simulations in our system. Essentially, running a Monte Carlo job involves two main steps to separate the configuration logic from the execution logic. In the first step, we generate a detailed description of the Monte Carlo job using a JSON workflow file. In the second step, we execute this job with a dynamic scheduler. In more detail, the workflow creation phase forms a coherent, acyclic directed graph (pipeline) that integrates all the tasks to be run, described in a custom JSON format. This phase also sets up the workflow according to critical user parameters, such as the collision system to use, the generators to run, and the interaction rate.

---

This is indeed a complex system made up of numerous executables or tasks that need consistent application and propagation of settings and configurations to function effectively together. It can be quite challenging to manage on your own, so it's best to rely on a maintained setup. For the Monte Carlo pipelines on the GRID, this maintained setup is available in the O2DPG repository, but it's worth noting that the same repository now also supports configuring and maintaining the scripts for data taking on the EPN.

---

And you can find examples for all these cases under the provided links. Regarding Pythia8: Pythia8 holds a somewhat unique position among event generators because it is more integrally linked into O2 than other generators. It is thus advisable to use Pythia8 whenever possible. If Pythia8 is utilized, it can be fully customized through a specialized configuration file, like the one illustrated on the right. Additionally, you can pass specific Pythia8 parameters to the executable, as detailed in the second box on the slide.

To set up the configuration file for Pythia8, we supply a Python tool that simplifies the process by allowing you to generate it with minimal effort, based on a few parameters you input to the tool. This tool serves to make the setup of the Pythia8 configuration more convenient for you. Apart from Pythia8,

---

To start, you need to specify which generators you intend to use, the interaction rate within your detector, the number of timeframes to simulate, and the generators you want to run. The result of this setup is saved in a file named workflow.json, which you can review.

---

An essential output from the o2-sim program comes from the transport simulation, specifically the kinematics data. This is frequently the most relevant for physics analysis as it includes creation vertices, momenta, and other attributes of both primary and secondary particles generated during the simulation. It also provides details on the physics creation processes for each particle and their relationships, such as mother-daughter connections. The data is structured using our MCTrack class, akin to ROOT's TParticles class, but designed to be more efficient in terms of memory and disk usage. For each event, there is a single entry in a ROOT TTree, which contains a vector of these tracks. You can easily review this data using ROOT's JSRoot or TBrowser system, as shown on the right.

---

Certainly. There are crucial helper classes designed to access and navigate Monte Carlo kinematics, which are essential for managing the complexities of ROOT IO and repetitive tasks. Two primary utility classes are highlighted here. The first is the Monte Carlo kinematics reader (MCKinematicsReader), a tool for efficiently reading and retrieving tracks based on an event number or Monte Carlo label (MCLabel). The second is the MC track navigator (MCTrackNavigator), which facilitates navigation through the mother-child relationships among Monte Carlo tracks and allows for querying various physics properties of MCTracks. An example on the right demonstrates how to read all stored Monte Carlo tracks, loop through them, and determine their direct mothers or other properties.

---

The primary function of the o2-sim program, as previously mentioned, includes first the creation of the geometry. Second, it generates events to simulate initial particle collisions. Third, it simulates the interaction of particles with the detector material and tracks their movement within the setup until they either exit or stop. Lastly, it produces hits, which are essentially energy deposits that serve as input for the detector digitizers to generate the actual sensor output.

---

In particular, the aim is to familiarize ourselves with the fundamental use cases of the o2-sim executable, which is the core system for event generation and transport simulation. Additionally, we will briefly discuss basic event generation techniques and how to configure them. Finally, we will introduce the O2DPG repository, which is our official integrated Monte Carlo production pipeline, encompassing event generators, AOD production, and analysis quality control tasks.

This introductory overview is meant for analysts and serves as a foundation for more specialized content in other parts of the tutorial.

---

INSTRUCTIONS: For setting up the configuration file for Pythia8, you need to do it yourself. In contrast to the direct compilation of specific generators in the previous AliRoot system, O2 has a smaller number of such integrations. The primary goal is to decouple physics-specific generator code and configurations from the data-taking code, to avoid recompiling O2 each time a generator configuration is altered. Instead, we prefer to use external generators, which can be integrated via just-in-time ROOT macros. These macros implement a special TGenerator interface from the ROOT project, allowing generator setup at runtime in C++. This makes the generator setup more of a configuration issue, which can be passed to o2-sim. A minimal example of a TGenerator implementation is provided on the right-hand side, though it is not fully complete. You would need to code a more complete implementation.

---

Alright, this concludes my presentation. There are numerous additional keywords in the simulation that I won't be covering, but I hope all the information is available in the documentation at https://aliceo2group.github.io/simulation/. Please assist us in enhancing it by asking questions and making direct contributions.

---

C++ code in a macro file that defines your generator, which can then be passed to o2-sim as illustrated in the upper box. This approach, which I would like to emphasize, is actively used in production by various physics working groups within the O2DPG system. Numerous examples demonstrate how you can integrate typical AliRoot generators, such as those for hygiene or other purposes, into o2-sim using this method. Additionally, we provide support for triggering, where event filtering or triggering is flexibly handled, working similarly to the external generator examples shown previously. You can implement trigger logic in a macro, which is then passed to o2-sim for just-in-time compilation. There's also a good example of this in the SIM examples folder of AliceO2. Advanced triggers are available, enabling you to trigger not only on the

---

Sure. Let's discuss event generation, focusing on the fundamentals. o2-sim comes with several predefined generators, which you can activate using the -g option. Notably, we have a pre-configured Pythia8pp for proton-proton interactions and a pre-configured Pythia8hi for lead-lead collisions. Additionally, there are other options like a simple box generator, a generator that uses an external kinematics file, and the ability to interface with generators that produce standardized HepMC output. This is how you choose the generator you need.

---

Sure, the key slides highlight our contact details. Hereâ€™s how to reach us: bi-weekly WP12/WP13 meetings are the primary venue for connecting and asking questions, with meeting invitations available via a CERN e-group you can subscribe to. For communication, we prefer using dedicated Mattermost channels for both general simulation queries and O2DPG production pipeline specifics. Additionally, for feature requests or bug reports, please open JIRA tickets within the O2 project.

---

Next, even though it might be somewhat redundant, I still want to briefly recall the traditional computing workflow in high-energy physics and highlight the importance of simulation. This workflow starts with real particle collisions that trigger detector outputs. This data is then processed by reconstruction software to generate AODs or analysis object data files. These AODs are used for actual physics analysis to publish scientific papers. Simulation, on the other hand, allows us to replicate this entire process in a fully virtual environment, generating Monte Carlo events based on physics models. These events produce sensor data similar to what is collected in real experiments, enabling us to create AODs. We perform these simulations to explore various aspects such as detector system design, reconstruction algorithm calibration, and efficiency calculations.

---

Sure, let's shift our focus to the o2-sim executable, the particle detector simulator for ALICE RUN3. This tool utilizes the ALICE detector geometry and material descriptions within well-known particle transport simulation engines, such as Geant4 (our primary choice), Geant3, and FLUKA. A key advantage of our setup is the flexibility to use any of these engines interchangeably. This feature stands out in ALICE compared to other HEP approaches that predominantly use Geant4. The capability to conduct radiation studies with FLUKA is another significant benefit.

---

Sure, here is the paraphrased document:

To demonstrate how to use o2-sim, I'll illustrate a few examples, beginning with a simple one. You would call o2-im from the command line as shown, specifying the number of events in the generator. This example generates 10 default Pythia8 proton-proton events, transports them through the entire ALICE detector, and produces the hits and kinematics output.

For a slightly more complex scenario, you can generate 10 default Pythia8 pp events and transport them using eight Geant3 workers, excluding the ZDC detector. Additionally, you can use a different magnetic field strength than the standard one, such as 2 kilo gauss. It's evident that you can customize o2-sim by providing various command-line options.

---

Sure, let's discuss run numbers briefly. Indeed, you might have noticed that a run number is required during the configuration phase. Using a run number is essential because it helps us determine a timestamp necessary for fetching conditions data from our conditions database (CCDB). Run numbers should be utilized even for simulations that are not data-taking, and I would like to point out that there is a list of predefined run numbers documented in a specific TWIKI. In this TWIKI, you can find run numbers suitable for various types of simulations. For example, if you are performing heavy ion simulations with a magnetic field of -0.5 tesla, the table indicates that using run number 310000 should provide you with the appropriate condition objects in the CCDB.

---

Sure. While this might not be crucial, I still wanted to highlight it since it can be useful to check what's happening internally. The ALICE O2 simulation generates three log files with distinct functions. The event generation phase logs are recorded in the o2sim_serverlog file, which provides insights into the event generation stage. Additionally, the o2sim_workerlog0 file captures details from the Geant4 transportation stage, which is beneficial for understanding the simulation's internal processes.

---

Based on this file, the workflow execution phase, the second step in the process, manages running the system on a multicore machine, akin to a dynamic build tool. This executor initiates all tasks as soon as the output from the preceding stage is ready. We've designed this scheduler to focus on high parallelism and CPU efficiency, while also adhering to resource limitations on compute nodes to avoid overloading the system with too many tasks simultaneously, ensuring memory remains manageable. Essentially, this tool can schedule any directed acyclic graph and is not limited to Monte Carlo simulations, making it versatile for other applications.

---

Sure, let's take a brief look at the ALICE Run3 simulation framework on the next slide. This is a typical setup for HEP experiments. The core of the simulation includes event generation, Geant-based transport simulation, and detector-specific digitization algorithms that transform Geant hit outputs into the actual electronics response for each detector. As depicted, this process is encapsulated in two main components. Additionally, it's crucial to note that Monte Carlo workflows can also run through all reconstruction steps or quality control analysis, which are integral parts of the simulation ecosystem and the broader Monte Carlo pipeline. In our context, integrating and configuring all these components into a cohesive workflow is managed within the O2DPG repository. Finally, I will provide a quick reminder of the primary data products in the simulation pipeline.

---

As shown on the right, the kinematics data is typically pruned by default, meaning it includes only relevant particles for physics or reconstruction. However, you can request full data generation to capture all billions of secondary particles produced. Additionally, there is metadata available at the event level, though it is found in the MC header file rather than the kinematics root file. This metadata includes important parameters such as the collision impact parameter and other global properties like the collision vertex.

---

O2DPG supplies the definitive setup for official Monte Carlo productions for ALICE Run3, along with a runtime system to execute these jobs on our GRID computing platform. It consolidates all necessary processing tasks into a unified and consistent environment, ensuring a seamless pipeline from event generation through AOD production. Furthermore, O2DPG manages versioned code for PWG-specific generator configurations and includes tools to validate whether these configurations are effective. This validation process occurs during pull request reviews.

---

Sure, it's worth noting that o2-sim can function as an on-the-fly event generator for analysis. Essentially, it can act as a generator service that directly feeds its generated events into a DPL analysis setup without any intermediate storage. This feature is particularly useful for studies focusing on the analysis or processing of primaries only. This idea was previously discussed with David Chinelatto, who was instrumental in its development, and it is now implemented. It appears to be utilized by several PWGs, and it will be covered in tomorrow's PWG EM tutorial.

Now, I'm moving to a discussion about the global Monte Carlo pipeline and integrated workflows aimed at producing simulated AODs. This encompasses more than just the transport simulator and event generation phases, and it must include stages such as digitization and reconstruction tasks.

---

In addition to this, in terms of documentation, we have initiated a new project that mirrors the efforts of physics analysis documentation. There is also some older material available for reference. However, please note that this project is still in its initial phase. Therefore, we encourage you to provide feedback, ask questions, or even contribute, as your input would be greatly appreciated.

Furthermore, a brief reminder on the software environment needed for ALICE detector simulations: as previously discussed, for Run3, you will need the O2Sim package. You can either compile it yourself or use the precompiled version available via CVMFS. I believe this setup should encompass all necessary components for detector simulation.

---

Next, I'll provide a brief reminder of the primary data products in the simulation pipeline.
When you process it from left to right, the transport simulation generates the ALICE detector geometry,
kinematics files with track properties for both primary and secondary particles, and detector response files, which we refer to as hits. These hits are then used by the digitization algorithms to create digit sub-detector timeframes, similar to the raw detector output of the actual experiment. Following this, the standard reconstruction pipeline takes over, where reconstruction uses the digits to generate global tracks, primary vertices, energy reconstructions, and ultimately produces the AO2D.root file for analysis.

---

More sophisticated are deep triggers, which permit triggering not only on the vector or the collection of primary particles, but also on the status of the event generator within the underlying simulation. Although this is slightly more advanced, we provide a code example for this in AliceO2.

---

the stored kinematics, and then iterate through all the tracks to identify a direct mother or
the primary ancestor for each particle.

---

I would also like to emphasize some additional useful features of this Python executor. Firstly, it supports checkpointing and incremental building, allowing for staged simulations. For example, you can run the pipeline up to digitization in the first execution and then continue in the next run by processing through the AOD stage. The benefit here is that it checkpoints at each stage, ensuring that the subsequent stage resumes from where it left off, avoiding redundant digitization.

---

Sure, let's move on to the detailed description of the second step in our execution process, which is the actual Monte Carlo workflow execution stage. To recap, this stage involves the workflow executor, which is a Python script. This script accepts the workflow file created in the preceding step and runs it on the compute node. The primary arguments provided include the workflow filename and the target stage up to which the graph pipeline should be executed. For us, this usually means up to the AOD stage.

---

Separating the pipeline's configuration from its execution clarifies responsibilities: one can adjust the Monte Carlo (MC) configuration independently of the execution code. Additionally, the MC pipeline can be easily shared in JSON format, enabling execution without needing to run the configuration step.

It's worth noting that this method is similar to how ALICE DPL topologies or O2Physics analysis tasks are structured.

However, the O2DPG MC graph workflow operates in incremental stages, with intermediate results saved to disk. In contrast, a complete global DPL topology loads all stages into memory simultaneously. Incremental execution was selected to manage the high memory demands during the digitization and Geant simulation stages.