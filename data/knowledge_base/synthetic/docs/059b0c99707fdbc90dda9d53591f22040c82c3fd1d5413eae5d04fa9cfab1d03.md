## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/DATA/README.md

**Start chunk id:** 059b0c99707fdbc90dda9d53591f22040c82c3fd1d5413eae5d04fa9cfab1d03

## Content

DOCUMENT:
    SET NHBPERTF=256                                                      # Number of HBF per TF

    PARAPHRASED DOCUMENT:

---

For calibration workflows, the number of cores must be specified and the memory limit is derived from the number of cores (approximately 4 GB per core, with some margin for the system). If `SHMSIZE` is configured for the workflow, it must comply with this memory constraint; a good guideline is 50% of the available memory. If `SHMSIZE` is not specified, it defaults to 2 GB per core. Ensure you request a reasonable number of cores, as there are only 4 calibration nodes shared among all workflows.

For an example, see the calibration workflows [here](testing/examples).

*NOTE* For reference, when running a calibration workflow with the AliECS on the EPN, currently a node from the `calib` zone must be requested by setting `odc_resources` to `[ {"zone":"online", "n":10}, {"zone":"calib", "n":1 } ]` (adjust the `10` to match your required number of reconstruction nodes). This will be streamlined in the future, eliminating the need for this additional setting.

---

- During synchronous processing on the EPN farm (signaled by the `$EPNSYNCMODE=1` variable), the *parser* will automatically `module load` the modules listed in the *topology description*. If not running on the EPN farm, the user needs to manually load the appropriate O2 / QC version.
- The parser sets the env variable `$RECO_NUM_NODES_WORKFLOW`, which indicates the number of nodes the workflow will use when executing the workflow script. This information can be utilized to adjust process multiplicities.

---

# Configuring and selecting workflow in AliECS:
Three methods are available for configuring the *full topology* in AliECS; currently, only the manual XML option is implemented:
- **Version of workflow repository**: Under this configuration, AliECS sets the following parameters, which uniquely define a *full topology*. The *parser* subsequently generates the final DDS XML file based on these settings:
  - A **commit hash** indicating a specific state of the `O2DPG` repository (which can be a tag, and for production workflows, it must be a tag).
  - The **path to a description library file** (relative to the DATA folder within the `O2DPG` repository).
  - The **workflow name** within the *description library file*.

---

- `$INRAWCHANNAME`: Transmitted to the workflow, it specifies the raw FMQ channel name utilized for interaction with DataDistribution.
  - `$RECO_NUM_NODES_OVERRIDE`: Changes the number of nodes employed in the reconstruction process (leave blank or set to 0 to deactivate this override).
  - `$DDMODE`: Determines the operation mode of DataDistribution: **discard** (creates TFs but discards them), **disk** (creates TFs and saves them to disk), **processing** (creates TFs and runs the DPL workflow on the TF data), **processing-disk** (both stores TFs to disk and performs processing).
  - `$DDWORKFLOW`: (*alternative option*): Provides an explicit path to an XML file containing the partial workflow for DataDistribution.
  - `$WORKFLOWMODE`: Can be configured to print mode, in which case the parser will not generate the DDS topology output, but instead will produce a list of shell commands to start running the workflows locally.

---

# Topology Descriptions and Description Library Files:
An additional layer of abstraction above *workflows* are referred to as **topology descriptions**. The *parser* tool is capable of producing a *full topology* XML file from such a *description* using the `–dds` option of DPL and the `odc-topo-epn` tool. *Topology descriptions* are kept in **description library files** within the `DATA` directory of the `O2DPG` repository. Each *description library file* can include multiple *topology descriptions*, each identified by a **topology name**.

# Notes:
- The repository does not store *full topologies*, but they are generated dynamically. Users have the option to cache the resulting full topology XML files.
- Default settings, especially those set in the common environment files within the `common` folder, are optimized for laptop or desktop use.

---

- The workflow commands should include `--monitoring-backend influxdb-unix:///tmp/telegraf.sock --resources-monitoring 60` for DPL metrics.
- To enable the infologger, use `--infologger-severity $INFOLOGGER_SEVERITY`.
- Workflows must end with the `o2-dpl-run` command and include the `$GLOBALDPLOPT` environment variable as a command line argument.
- Source the following files to access common functions:
  ```
  source common/getCommonArgs.sh
  source common/gen_topo_helper_functions.sh
  ```
- Combine your workflow components in the `$WORKFLOW` variable, using `add_W` to add a workflow and `add_QC_from_consul` to incorporate a QC workflow with a JSON file from consul.
- Calibration workflows should avoid contaminating the production CCDB in the scenario where `if [[ $RUNTYPE == "SYNTHETIC" || "${GEN_TOPO_DEPLOYMENT_TYPE:-}" == "ALICE_STAGING" ]]; then` (bash script); for instance, upload to `ccdb-test.cern.ch`.

---

- The **workflow name** within the *description library file*.
- **detector list**: A list of multiple detectors separated by commas, involved in the run (global list, list for quality control, list for calibration, list for reconstruction, list for CTF, list for processing on the FLP), with a default value of `ALL` for all detectors.
- **workflow parameters**: A text field supplied to the workflow as an environment variable for additional options.
- **number of nodes override**: A setting that changes the number of nodes required in the workflow (intended to quickly adjust the EPN partition size). **NOTE: This setting is now mandatory and exclusively used to define the number of nodes. The number specified in the workflow description is disregarded.**
- **process multiplicity overrides**: Scaling factors for the process multiplicities of raw decoders, CTF encoders, and other processes.

---

- For the EPN to run, the *calib* input proxies of the aggregator nodes need to include the command line option `--network-interface ib0` (to ensure data transmission occurs via InfiniBand rather than Ethernet). It is important to note that this applies only to the aggregator node and not to the regular processing stages!

---

Loading module DataDistribution
Loading DataDistribution/v1.0.6-2
  Loading requirement: libInfoLogger/v2.1.1-5 Ppconsul/v0.2.2-5 utf8proc/v2.6.1-3 lzma/v5.2.3-6 Clang/v12.0.1-2 lz4/v1.9.3-9 arrow/v5.0.0-alice1-4 GSL/v1.16-8 libxml2/v2.9.3-8 ROOT/v6-24-02-12 FairRoot/v18.4.2-7 Vc/1.4.1-11 Monitoring/v3.8.7-4 Configuration/v2.6.2-4 Common-O2/v1.6.0-13 ms_gsl/3.1.0-5 GLFW/3.3.2-10 libuv/v1.40.0-10
    DebugGUI/v0.5.6-6 libjalienO2/0.1.3-5 FFTW3/v3.3.9-6 O2/nightly-20210831-0930-1
Loading module QualityControl
Loading QualityControl/v1.27.0-1
  Loading requirement: Control-OCCPlugin/v0.26.3-1 VecGeom/89a05d148cc708d4efc2e7b0eb6e2118d2610057-40
Adding reconstruction workflow ( 10 - 10 nodes): SHMSIZE=128000000000 testing/private/drohr/my-workflow.sh
Running DPL command SHMSIZE=128000000000 testing/private/drohr/my-workflow.sh | grep -v "^\[INFO" > /tmp/o2_workflowmfld0a0n/wf2.dds && [ `grep "^\[" /tmp/o2_workflowmfld0a0n/wf2.dds | wc -l` == 0 ]
Creating reconstruction collection...

---

# Descriptions of Topology:
A *topology description* includes:
- A list of modules necessary for both generating the DDS XML file using DPL's `--dds` option and for executing the workflow. This list can be a single module or a space-separated list enclosed in double-quotes. This list also specifies the O2 version. We offer the `O2PDPSuite` package, which aligns with the O2 version and includes versions of `DataDistribution`, `QualityControl`, and `ODC`. Therefore, by default, one should load `O2PDPSuite/[version]`.
- A list of workflows, specified as commands to generate XML files using the `–dds` option. These commands are run with the `O2DPG/DATA` path as the working directory. The environment options used to configure the workflow are added in standard shell syntax. Certain env options are set by the EPN and should not be overridden: `FILEWORKDIR`, `INRAWCHANNAME`, `CTF_DIR`.

---

# The parsing script:
The **parser** is a basic Python script designed to interpret a *topology description* and produce a complete DDS XML file representing the *full topology*. It accomplishes this by running all DPL workflows with the `--dds ${WORKFLOWMODE_FILE}` parameter and subsequently employing the `odc-topo-epn` tool to integrate the *partial topology* into the final *full topology*.
The *parser* operates based on certain command line options and environment variables (with the latter being passed to the workflows as well).
- The *parser* requires a DataDistribution topology file. Example files are included in the `tools/datadistribution_workflows` directory for scenarios such as discarding the TF, storing the TF to disk, forwarding the TF to DPL processing (essential for DPL workflows), and forwarding while simultaneously storing to disk.
- *Parser* command line options:
  - The script is intended to be run from the `DATA` directory of the `O2DPG` repository.
  - The typical invocation command is:

---

Creating reconstruction collection...
A new DDS topology has been successfully created and saved to the file "/home/drohr/gen_topo/test/output.xml"
The DDS topology named "topology" was successfully opened from the file "/home/drohr/gen_topo/test/output.xml"
Completed
[drohr@epn245 test]$ cat $HOME/gen_topo_output.xml
<?xml version="1.0" encoding="utf-8"?>
[...]
</topology>
```

---

DOCUMENT:
    /opt/alisw/el9/GenTopo/bin/gen_topo.sh > $HOME/gen_topo_output.xml
[drohr@epn245 test]$ ./run.sh
Loading ODC/0.36-1
  Loading requirement: BASE/1.0 GCC-Toolchain/v10.2.0-alice2-3 fmt/7.1.0-10 FairLogger/v1.9.1-7 zlib/v1.2.8-8 OpenSSL/v1.0.2o-9 libpng/v1.6.34-9 sqlite/v3.15.0-2 libffi/v3.2.1-2 FreeType/v2.10.1-8 Python/v3.6.10-12 Python-modules/1.0-16 boost/v1.75.0-13 ZeroMQ/v4.3.3-6 ofi/v1.7.1-8 asio/v1.19.1-2 asiofi/v0.5.1-2 DDS/3.5.16-5 FairMQ/v1.4.40-4
    protobuf/v3.14.0-9 c-ares/v1.17.1-5 re2/2019-09-01-11 grpc/v1.34.0-alice2-1
Using the topology named drohr-workflow from the library testing/private/drohr/workflows.desc
Found topology drohr-workflow - ['drohr-workflow:', 'O2PDPSuite', 'reco,10,10,SHMSIZE=128000000000 testing/private/drohr/my-workflow.sh']
Loading module DataDistribution
Loading DataDistribution/v1.0.6-2

---

When modifying your workflow, it is advisable to adhere to the style of the existing workflows. The [testing/examples/example-workflow.sh](testing/examples/example-workflow.sh) serves as a basic template, while a more intricate example can be found in [testing/detectors/TPC/tpc-workflow.sh](testing/detectors/TPC/tpc-workflow.sh). For a comprehensive example of a global workflow, refer to [production/full-system-test/dpl-workflow_local.sh](production/full-system-test/dpl-workflow_local.sh).

The `run.sh` script leverages the `parser` to generate the XML file, primarily by setting environment variables and invoking the `parser` with all options defined. Consequently, you can also directly use the `parser` to create the workflow as detailed [here](Creating-a-full-topology-DDS-XML-file-manually).

For a comparative view, see the following console output:
```
[drohr@head ~]$ ssh epn245
Activate the web console with: systemctl enable --now cockpit.socket

```

---

# Workflow requirements:
- Workflows must support three run modes, selected through the `WORKFLOWMODE` environment variable. The `dds` mode with its `${WORKFLOWMODE_FILE}` parameter is obligatory:
  - **run** (default): execute the workflow
  - **print**: display the final workflow command in the console
  - **dds**: generate a partial topology.
- Where applicable, workflows should utilize the configuration settings from the `common/setenv.sh` script rather than defining their own options. Required environment variables to adhere to are:
  - `SHMSIZE`
  - `SEVERITY` and `INFOLOGGER_SEVERITY`, which should be set to `warning`
  - `NORATELOG`, or fmq rate logging must be turned off
  - `GPUTYPE` (if the workflow supports GPUs)
  - `GLOBALDPLOPT`, which must be included in the workflow (appended to the final binary if merged with `|` syntax)
  - ... (to be continued).
- DPL metrics and InfoLogger (while not strictly required, their absence makes debugging challenging).

---

- For calib:
  - Number of physical cores to reserve on the node for the workflow.
  - Name of the calibration (used to configure DDS properties, which determine the connection of reconstruction workflows to specific calibration workflows).
    - ODC/DDS ensures enough nodes are allocated to provide sufficient CPU cores for the calibration workflows. The various calibration workflows might or might not run on the same node.

---

- Execute the parser with the following command:
```
./tools/parse production/production.desc synchronous-workflow /tmp/dds-topology.xml
```
- After running this, you can utilize `/tmp/dds-topology.xml` to initiate the workflow through DDS.

---

- **extra environment options**: A text field for the operator to input additional environment variables, which will be passed to the workflow.
  - **wipe workflow cache**: Typically, XML files are cached when generated from the same repository version, same workflow, and same O2 version. This option clears the cache for the current partition.
- **repository directory**: Similar to the previous case, but the repository path, rather than the commit hash, is specified, directing to a checked-out repository on the shared home folder in the EPN farm. The process remains the same, where the parser generates the full topology XML file from the specified workflow within the repository.

---

Running DPL command with settings EXTINPUT=1, SYNCMODE=1, NUMAGPUIDS=1, NUMAID=1, SHMSIZE=128000000000, EPNPIPELINES=1, SHMTHROW=0, SEVERITY=warning, and executing the script production/full-system-test/dpl-workflow_local.sh, then filtering out lines starting with "[INFO" with grep, redirecting the output to /tmp/o2_workflowkxkzei9w/wf3.dds, and ensuring no lines starting with "[" are present in the file.
Creating reconstruction collection...
A new DDS topology has been successfully created and saved to "/home/drohr/gen_topo/test/output.xml"
The DDS topology "topology" has been successfully opened from the file "/home/drohr/gen_topo/test/output.xml"
Process completed.

---

- Establish an empty directory in `$HOME` on the EPN, specifically in `$HOME/test`.
- Duplicate the topology generation template from `O2DPG/DATA/tools/epn/run.sh` into your folder.
  - Note: This template script includes all options that will be supplied via AliECS as environment variables automatically. Eventually, this file will no longer be necessary; instead, the XML file will be generated automatically from the AliECS GUI.
- Modify your local copy of the `run.sh` file. Here are the pertinent parameters for you:
  - Keep the `GEN_TOPO_HASH` set to 0, and use the commented section with `GEN_TOPO_HASH=1`, which will be activated once AliECS is updated.
  - Insert the path to the `DATA` directory of your `O2DPG` copy into `GEN_TOPO_SOURCE`, and place your newly created description library file and the workflow in that directory as `GEN_TOPO_LIBRARY_FILE` and `GEN_TOPO_WORKFLOW_NAME`.

---

- To set the number of reconstruction nodes, use `RECO_NUM_NODES_OVERRIDE`; otherwise, the default from your description library file will be applied (leave it empty or set to `=0`).
- `WORKFLOW_DETECTORS` and `WORKFLOW_PARAMETERS` are optional settings and not necessary for your current workflow; you can skip them for now.
- Ensure `DDMODE=processing` is included to execute the workflow.
- `NHBPERTF` will be automatically configured by AliECS, so there is no need to modify it.
- Change the output filename to a location in your `$HOME`; the default is `$HOME/gen_topo_output.xml`, which is the file you need to input into AliECS for topology.
- Execute `run.sh`.
- Upload the output file (default is `$HOME/gen_topo_output.xml`) as the EPN DDS topology in the AliECS GUI.

---

# Folder structure:
- **common** holds shared scripts accessible to all workflows, particularly including common environment variable scripts.
- **production** houses the production workflows for global runs, managed by PDP specialists.
- **tools** includes the **parser** script and supplementary tools.
- **testing** features scripts for tests or standalone runs maintained by detectors or individuals. It includes **examples** for illustrative workflows, **detectors** for standalone detector workflows, and **private** for user-specific workflows.

---

DOCUMENT:
    export DDMODE=processing                                             # DataDistribution mode - possible options: processing, disk, processing-disk, discard

# Utilize these configurations to access the Workflow Repository via a hash or tag
#export GEN_TOPO_HASH=1                                                # Use a git hash to fetch the O2DPG repository
#export GEN_TOPO_SOURCE=v0.5                                           # Specific git hash for the repository

# Use these settings to define a local path to the workflow repository in your home directory
export GEN_TOPO_HASH=0                                                # Define the path to the O2DPG repository
export GEN_TOPO_SOURCE=/home/drohr/O2DPG/DATA                         # Local path to the O2DPG repository

---

- Each "raw" proxy input must be given a unique name using the `--proxy-name [NAME]` option. The *reco* script has a default input raw proxy named `readout-proxy`.
- The channel-name for each input proxy should correspond to its name. Calibration input proxies should have `method=bind` for their channels, whereas output proxies should use `method=connect` and their channel name should match the input proxy it connects to.
- The `dataspec` for the proxies is configured similarly to the `readout-proxy`, and the specs must be identical for corresponding input and output proxies.
- The channels of input and output proxies (excluding the *reco* `readout-proxy`) should be configured without specifying an address.
- For output proxies, use the command line option `--proxy-channel-name [name]`, where `name` is the configured channel name.

---

This repository includes the PDP workflows for execution on the EPN (and will also support the FLP in the future), along with a parse script that converts description files into DDS XML files.
For a brief introduction and an example on how to create a workflow on the EPN, refer to [this section](#Quick-guide-to-create-and-deploy-detector-workflow).
Detailed options for the production workflow are outlined [here](production/README.md).

# Terminology:
- A **workflow** is defined as a single DPL workflow binary, or a combination of multiple workflow binaries using the `|` syntax, or a shell script that initiates such a workflow.
- A **full topology** is the final XML file submitted to DDS to initiate a processing chain for a single partition on the EPN.
- A **partial topology** is the XML file generated by DPL using the `--dds` option.

---

DOCUMENT:
    export GEN_TOPO_LIBRARY_FILE=production/production.desc              # File containing the topology description to load
export GEN_TOPO_WORKFLOW_NAME=synchronous-workflow                   # Name of the workflow defined in the topology description file
export WORKFLOW_DETECTORS=ALL                                        # Optional parameter for the workflow: List of detectors to perform reconstruction on (separated by commas)
export WORKFLOW_DETECTORS_QC=                                        # Optional parameter for the workflow: List of detectors to run quality control for
export WORKFLOW_DETECTORS_CALIB=                                     # Optional parameter for the workflow: List of detectors to run calibration for
export WORKFLOW_PARAMETERS=EVENT_DISPLAY,CTF,GPU                     # Additional parameters for the workflow
export RECO_NUM_NODES_OVERRIDE=0                                     # Override the number of EPN compute nodes to be used (default value is set in the description library file)

---

/opt/alisw/el9/GenTopo/bin/gen_topo.sh > $HOME/gen_topo_output.xml
[drohr@epn245 test]$ ./run.sh
Loading ODC/0.36-1
  Loading requirement: BASE/1.0 GCC-Toolchain/v10.2.0-alice2-3 fmt/7.1.0-10 FairLogger/v1.9.1-7 zlib/v1.2.8-8 OpenSSL/v1.0.2o-9 libpng/v1.6.34-9 sqlite/v3.15.0-2 libffi/v3.2.1-2 FreeType/v2.10.1-8 Python/v3.6.10-12 Python-modules/1.0-16 boost/v1.75.0-13 ZeroMQ/v4.3.3-6 ofi/v1.7.1-8 asio/v1.19.1-2 asiofi/v0.5.1-2 DDS/3.5.16-5 FairMQ/v1.4.40-4
    protobuf/v3.14.0-9 c-ares/v1.17.1-5 re2/2019-09-01-11 grpc/v1.34.0-alice2-1
Using a synchronous workflow from the library defined in production/production.desc

---

- **manually specified XML file**: In this mode, the `O2DPG` repository is completely omitted, and instead, the absolute path to a *full topology* XML file located in the EPN's shared home folder is provided. This XML file needs to be created manually, using the same methods that the *parser* typically employs (refer to the section on manually specified XML files for more details).

---

For reference, here is the creation of the XML for the full synchronous processing workflow:
```
[drohr@epn245 test]$ cat run.sh
#!/bin/bash

export DDMODE=processing                                             # DataDistribution mode - possible options include: processing, disk, processing-disk, or discard

# Use these settings to fetch the Workflow Repository using a hash or tag
#export GEN_TOPO_HASH=1                                              # Fetch O2DPG repository using a git hash
#export GEN_TOPO_SOURCE=v0.5                                         # Git hash to fetch

# Use these settings to specify a path to the workflow repository in your home directory
export GEN_TOPO_HASH=0                                               # Specify path to O2DPG repository
export GEN_TOPO_SOURCE=/home/drohr/O2DPG/DATA                        # Path to O2DPG repository
```

---

# Calibration Workflows Utilizing Aggregators

When calibration workflows employ an aggregator, the processing occurs on each EPN, with the results then transmitted to an aggregator node. Communication is facilitated via the `o2-dpl-raw-proxy` and the `o2-dpl-output-proxy`.

Setting up such a workflow requires adherence to these guidelines:
- Two distinct shell scripts are necessary: one for the "reco" process running on each EPN, and another for the calibration aggregator "calib" process on the calibration node. If the topology includes multiple aggregators, there will be one *reco* script and several *calib* scripts.
- In a calib aggregator workflow, the `o2-dpl-raw-proxy` MUST NOT include the `--inject-missing-data` command line argument! (This argument is used only for input proxies receiving data from DataDistribution!)
- The *reco* script should include an `o2-dpl-output-proxy` for sending output, while each calib script should incorporate an `o2-dpl-raw-proxy` for input.

---

- Each workflow incorporates the following parameters, which precede the workflow command with commas and no spaces, and the workflow command is enclosed in double-quotes:
- The zone where the workflow is to be executed (calib / reco)
- For reconstruction workflows:
  - The number of nodes on which to run this workflow
    - **NOTE: The setting for the number of nodes is now disregarded. Please use the node override in ECS instead!**
    - If a processor in the workflow needs to determine the node it is running on, it can utilize the `$DDS_COLLECTION_INDEX` environment variable.
  - The minimum number of nodes required for the workflow (in the event of node failure)
    - If there are multiple workflows in the topology description, the maximum number of nodes and the highest minimum number of nodes are utilized.
- For calibration workflows:
  - The number of physical cores to reserve on the node for running the workflow.

---

- Move the contents of `O2DPG/DATA/testing/examples`, including the description library file `workflows.desc` and the workflow script `example-workflow.sh`, to another location within the repository, typically under `testing/detectors/[DETECTOR]` or `testing/private/[USERNAME]`.
- Modify the workflow script as needed, and update or rename the workflow in the description library file.
  - Refer to [this section](#Topology-descriptions) for the library file syntax (if it isn’t clear), and ensure you do not overwrite the listed protected environment variables. The workflow script is a bash script that initiates a DPL workflow, which must include the `--dds ${WORKFLOWMODE_FILE}` parameter to generate a partial DDS topology.
  - Confirm that the workflow script meets the [requirements](#Workflow-requirements), especially with regard to respecting the required environment variables.
  - Utilize `O2PDPSuite` for module loading to ensure the latest installed version, or specify a version by using `O2PDPSuite/[version]`.

---

# Creating a complete topology DDS XML file manually via the parser:
- **NOTE** This information is for reference or use on a private PC. For XML creation on the EPN, see [here](#Quick-guide-to-create-and-deploy-detector-workflow).
- Access the `O2DPG` repository, modify the workflows and topology description in the `DATA` directory to meet your requirements.
- Open a terminal and navigate to the `DATA` directory within `O2DataProcessing`.
- Ensure that `odc-topo-epn` is included in your path (e.g., `module load ODC` / `alienv enter ODC/latest`).
- Set the necessary environment variables, such as:
```
FILEWORKDIR=/home/epn/odc/files EPNSYNCMODE=1 DDWORKFLOW=tools/datadistribution_workflows/dd-processing.xml INRAWCHANNAME=tf-builder-pipe-0 WORKFLOW_DETECTORS=TPC,ITS,TRD,TOF,FT0
```
- If you are not on the EPN farm and have not configured `EPNSYNCMODE=1`: Load the necessary modules for O2 / QC (`alienv load O2PDPSuite/latest`).
- Execute the parser, for example:
```

---

DOCUMENT:
    define NHBPERTF as 256                                              # Number of HBF per TF

    PARAPHRASED DOCUMENT:

---

- Workflow scripts must include support for the `WORKFLOWMODE=print` option; when used, they will output the command needed to start the workflow without actually executing it.
- The parser also accommodates `WORKFLOWMODE=print`, generating the command line in the output file. If the topology involves multiple commands, it will provide all necessary command lines.
- The `run.sh` script, designed to mimic the AliECS GUI, also supports `WORKFLOWMODE=print`. To run it locally on your home computer, ensure you set `GEN_TOPO_RUN_HOME=1`.

---

Using topology synchronous-workflow as specified in library production/production.desc
Detected topology synchronous-workflow - ['synchronous-workflow:', 'O2PDPSuite', 'reco,128,128,EXTINPUT=1 SYNCMODE=1 NUMAGPUIDS=1 NUMAID=0 SHMSIZE=128000000000 EPNPIPELINES=1 SHMTHROW=0 SEVERITY=warning production/full-system-test/dpl-workflow_local.sh', 'reco,128,128,EXTINPUT=1 SYNCMODE=1 NUMAGPUIDS=1 NUMAID=1 SHMSIZE=128000000000 EPNPIPELINES=1 SHMTHROW=0 SEVERITY=warning production/full-system-test/dpl-workflow_local.sh']
Loaded module DataDistribution
Loaded DataDistribution/v1.0.6-2
  Loaded dependencies: libInfoLogger/v2.1.1-5 Ppconsul/v0.2.2-5 utf8proc/v2.6.1-3 lzma/v5.2.3-6 Clang/v12.0.1-2 lz4/v1.9.3-9 arrow/v5.0.0-alice1-4 GSL/v1.16-8 libxml2/v2.9.3-8 ROOT/v6-24-02-12 FairRoot/v18.4.2-7 Vc/1.4.1-11 Monitoring/v3.8.7-4 Configuration/v2.6.2-4 Common-O2/v1.6.0-13 ms_gsl/3.1.0-5 GLFW/3.3.2-10 libuv/v1.40.0-10
    DebugGUI/v0.5.6-6 libjalienO2/0.1.3-5 FFTW3/v3.3.9-6 O2/nightly-20210831-0930-1

---

An example of the topology library file is as follows:
- topologies.desc
```
demo-full-topology: O2PDPSuite/nightly-20210801 reco,128,126,"SHMSIZE=320000000000 full-system-test/dpl-workflow.sh" calib,5,"SHMSIZE=2000000000 calibration/some-calib.sh" calib,20,"SHMSIZE=2000000000 calibration/other-calib.sh";
other-topology: O2PDPSuite/v1.0.0 reco,2,1,"tpc-test/tpc-standalone-test-1.sh"
```
- AliECS-config:
```
commit=xxxx|path=xxxx file=topologies.desc topology=demo-full-topology parameters="EVENT_DISPLAY" detectors="TPC,ITS" detectors_qc="TPC" [...]
```

---

[drohr@epn245 testing]$ cat private/drohr/workflows.desc
drohr-workflow: "O2PDPSuite" reco,10,10,"SHMSIZE=128000000000 testing/private/drohr/my-workflow.sh"
[drohr@epn245 testing]$ mkdir ~/test
[drohr@epn245 testing]$ cd ~/test
[drohr@epn245 test]$ cp ~/O2DPG/DATA/tools/epn/run.sh .
[drohr@epn245 test]$ vi run.sh
[drohr@epn245 test]$ cat run.sh
#!/bin/bash

---

- The syntax for the command is as follows:
```
[ENV_VARIABLES] ./tools/parse [DESCRIPTION_LIBRARY_FILE] [TOPOLOGY_NAME] [OUTPUT_NAME]
```
- An example of how to use this is:
```
DDWORKFLOW=tools/datadistribution_workflows/dd-processing.xml WORKFLOW_DETECTORS=TPC,ITS WORKFLOW_DETECTORS_QC=TPC WORKFLOW_DETECTORS_CALIB=ALL ./tools/parse topologies.desc demo-full-topology /tmp/output.xml
```
- The following environment variables control the operation of the *Parser*:
  - `$FILEWORKDIR`: This must be set and is utilized by the workflows to indicate the directory where all necessary files (like grp, geometry, dictionaries, etc.) are stored.
  - `$EPNSYNCMODE`: If this variable is set, the parser assumes it is running on the EPN for synchronous processing. In this case, it will automatically load the modules as specified in the topology description. Additionally, this variable is used by the workflows to activate features such as the InfoLogger and Metrics monitoring, and to retrieve QC JSONs from consul.

---

# Quick guide to create and deploy detector workflow:
- **Note**: While not all configuration features (see [here](#Configuring-and-selecting-workflow-in-AliECS)) are currently available in AliECS, this guide focuses on creating the XML file for DDS. This XML file must then be manually entered in the AliECS GUI as the topology. Although this manual entry method will persist, in the future, workflows will be configured directly in AliECS, with the XML generated on-the-fly.
- **Note**: The topology must be created on an EPN with the required O2 version installed, as specified by the topology. Any EPN should suffice, provided that the O2 version is the same across all nodes.
- Clone the [O2DPG](https://github.com/AliceO2Group/O2DPG) repository to your home folder on the EPN (`$HOME` in the following).

---

Last login: Wednesday, September 1, 2021, at 19:11:47 from 10.162.32.2
[drohr@epn245 ~]$ git clone https://github.com/AliceO2Group/O2DPG
Cloning the repository into 'O2DPG'...
remote: Enumerating objects: 182, done.
remote: Counting objects: 100% (182/182), done.
remote: Compressing objects: 100% (112/112), done.
remote: Total 182 (delta 64), reused 135 (delta 48), pack-reused 0
Receiving 182 objects: 100% (182/182), 36.42 KiB | 5.20 MiB/s, done.
Resolving deltas: 100% (64/64), done.
[drohr@epn245 ~]$ cd O2DPG/DATA/testing/
[drohr@epn245 testing]$ mkdir -p private/drohr
[drohr@epn245 testing]$ ls examples/
example-workflow.sh  workflows.desc       
[drohr@epn245 testing]$ cp examples/* private/drohr/
[drohr@epn245 testing]$ vi private/drohr/workflows.desc
[drohr@epn245 testing]$ mv private/drohr/example-workflow.sh private/drohr/my-workflow.sh
[drohr@epn245 testing]$ vi private/drohr/my-workflow.sh
[drohr@epn245 testing]$ cat private/drohr/workflows.desc

---

DOCUMENT:
    export GEN_TOPO_LIBRARY_FILE=testing/private/drohr/workflows.desc    # File containing the topology description library to be loaded
export GEN_TOPO_WORKFLOW_NAME=drohr-workflow                         # Name of the workflow within the topology description library
export WORKFLOW_DETECTORS=ALL                                        # Optional parameter for the workflow: Specify the detectors to perform reconstruction on (separated by commas)
export WORKFLOW_DETECTORS_QC=                                        # Optional parameter for the workflow: Specify the detectors to run quality control for
export WORKFLOW_DETECTORS_CALIB=                                     # Optional parameters for the workflow: Specify the detectors to perform calibration on
export WORKFLOW_PARAMETERS=                                          # Additional parameters for the workflow
export RECO_NUM_NODES_OVERRIDE=0                                     # Override the number of EPN compute nodes to be used (default value is set in the description library file)

---

- When a workflow employs an `o2-dpl-raw-proxy` to intake data from DataDistribution, it is necessary for that device to include the `--inject-missing-data` command-line option.

---

DOCUMENT:
    DebugGUI/v0.5.6-6 libjalienO2/0.1.3-5 FFTW3/v3.3.9-6 O2/nightly-20210831-0930-1
Loading module QualityControl
Loading QualityControl/v1.27.0-1
  Loading requirement: Control-OCCPlugin/v0.26.3-1 VecGeom/89a05d148cc708d4efc2e7b0eb6e2118d2610057-40
Adding reconstruction workflow with 128 nodes (range 128 - 128): EXTINPUT=1 SYNCMODE=1 NUMAGPUIDS=1 NUMAID=0 SHMSIZE=128000000000 EPNPIPELINES=1 SHMTHROW=0 SEVERITY=warning, running from production/full-system-test/dpl-workflow_local.sh
Running DPL command: EXTINPUT=1 SYNCMODE=1 NUMAGPUIDS=1 NUMAID=0 SHMSIZE=128000000000 EPNPIPELINES=1 SHMTHROW=0 SEVERITY=warning production/full-system-test/dpl-workflow_local.sh | grep -v "^\[INFO" > /tmp/o2_workflowkxkzei9w/wf2.dds && [ `grep "^\[" /tmp/o2_workflowkxkzei9w/wf2.dds | wc -l` == 0 ]
Adding reconstruction workflow with 128 nodes (range 128 - 128): EXTINPUT=1 SYNCMODE=1 NUMAGPUIDS=1 NUMAID=1 SHMSIZE=128000000000 EPNPIPELINES=1 SHMTHROW=0 SEVERITY=warning, running from production/full-system-test/dpl-workflow_local.sh