## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/MC/analysis_testing/o2dpg_analysis_test_config.py

**Start chunk id:** 28da1d3e7be6ab25ebd1707b16f95b039ce8dfd79c3a809a9753ee559b52fcd1

## Content

DOCUMENT:
    return ret


def main():
    """
    entry point for direct command line execution
    """
    parser = argparse.ArgumentParser(description='Check, validate or modify analysis configuration')
    sub_parsers = parser.add_subparsers(dest="command")

    config_parser = argparse.ArgumentParser(add_help=False)
    config_parser.add_argument("-c", "--config", help="input configuration file to use")

    # modify config
    modify_parser = sub_parsers.add_parser("modify", parents=[config_parser])
    modify_parser.add_argument("-o", "--output", default="analyses_config.json", help="output file name for new configuration")
    modify_parser.add_argument("--enable-tasks", dest="enable_tasks", nargs="*", help="names of analysis tasks to enable (if they are disabled)")
    modify_parser.add_argument("--disable-tasks", dest="disable_tasks", nargs="*", help="names of analysis tasks to disable (if they are enabled), takes precedence over --enable-tasks")
    modify_parser.set_defaults(func=modify)

---

```
return 0


def validate_output(args):
    """
    Post-execution validation

    * verify the presence of corresponding *.log_done files from the WF runner
    * ensure the exit code is correct in the *.log files
    * confirm that expected output files are present
    """

    if not args.config:
        # first check if a config is not explicitly provided, then use the directory containing the analyses to be checked
        args.config = args.directory

    analyses = get_config(args.config)

    # initialize the return code
    ret = 0
    # flag to include disabled analyses
    include_disabled = args.include_disabled

    for ana in analyses:
        analysis_name = ana["name"]

        if args.tasks:
            if analysis_name not in args.tasks:
                continue
            # explicitly specified tasks should always be considered
            include_disabled = True
```

---

analyses = get_config(args.config)

    for ana in analyses:
        if ana["name"] != args.task:
            continue
        if args.status:
            print_status(ana["enabled"])
        if args.applicable_to:
            if ana.get("valid_mc", False):
                print("mc")
            if ana.get("valid_data", False):
                print("data")

        return 0

    # analysis not found
    print(f"WARNING: Unknown task {args.task}")
    return 1


def list_analyses(args):
    """
    Examine analyses and display those that are en-/disabled
    """
    if not args.enabled and not args.disabled:
        args.enabled = True
        args.disabled = True

    analyses = get_config(args.config)

    for ana in analyses:
        if (args.enabled and ana["enabled"]) or (args.disabled and not ana["enabled"]):
            print(ana["name"])

    return 0

---

#!/usr/bin/env python3

import sys
import argparse
from os import environ
from os.path import join, exists, isdir
import json

# ensure O2DPG and O2 are properly set up
O2DPG_ROOT=environ.get('O2DPG_ROOT')

if O2DPG_ROOT is None:
    print('ERROR: This script requires O2DPG to be loaded')
    sys.exit(1)


def fetch_config(path=None):
    default_path = join(O2DPG_ROOT, "MC", "config", "analysis_testing", "json", "analyses_config.json")
    if not path:
        path = default_path
    else:
        if isdir(path):
            # assume the analyses_config.json is in this directory
            path = join(path, "analyses_config.json")

        if not exists(path):
            print(f"WARNING: Failed to find config for AnalysisQC at custom path {path}. Using default at {default_path}")
            path = default_path

    with open(path, "r") as f:
        return json.load(f)["analyses"]


def adjust(args):
    """
    modify the configuration and generate a new one
    """

---

# check properties of a task
validate_parser = sub_parsers.add_parser("validate-output", parents=[config_parser])
validate_parser.add_argument("-t", "--tasks", nargs="*", help="tasks to validate; if not specified, all tasks are validated")
validate_parser.add_argument("-d", "--directory", help="top directory (usually called \"Analysis\") where individual analysis directories are located", required=True)
validate_parser.add_argument("--include-disabled", action="store_true", help="include tasks that are typically turned off (not required if a specific task is specified with --task)")
validate_parser.set_defaults(func=validate_output)

# parse and run
args = parser.parse_args()
args.func(args)

if __name__ == "__main__":
    sys.exit(main())

---

# Display enabled or disabled tasks
show_parser = sub_parsers.add_parser("show-tasks", parents=[config_parser])
show_parser.add_argument("--enabled", action="store_true", help="display enabled tasks")
show_parser.add_argument("--disabled", action="store_true", help="display disabled tasks")
show_parser.set_defaults(func=show_tasks)

# Examine properties of a task
check_parser = sub_parsers.add_parser("check", parents=[config_parser])
check_parser.add_argument("-t", "--task", help="analysis task to examine", required=True)
check_parser.add_argument("--status", action="store_true", help="verify if task is enabled or disabled")
check_parser.add_argument("--applicable-to", dest="applicable_to", action="store_true", help="determine if valid for MC or data")
check_parser.set_defaults(func=check)

---

log_file = join(analysis_dir, f"Analysis_{analysis_name}.log")

if exists(log_file):
    exit_status = "0"
    with open(log_file, "r") as f:
        for line in f:
            if "TASK-EXIT-CODE:" in line:
                exit_status = line.strip().split()[1]
                if exit_status != "0":
                    print(f"Analysis {analysis_name} terminated with a non-zero exit code {exit_status}.")
                    ret = 1
                    break
    if exit_status != "0":
        continue

    # verify the existence of the *.log_done file
    log_done_file = join(analysis_dir, f"Analysis_{analysis_name}.log_done")
    if not exists(log_done_file):
        print(f"It seems that analysis {analysis_name} did not complete successfully, as {log_done_file} is missing.")
        ret = 1

return ret

---

if not ana["enabled"] and not include_disabled:
    # skip if disabled and not including disabled analyses
    continue

    analysis_dir = join(args.directory, analysis_name)

    if not exists(analysis_dir):
        print(f"The expected output directory {analysis_dir} for analysis {analysis_name} does not exist.")
        ret = 1
        continue

    if not ana["expected_output"]:
        # expected no output
        continue

    # verify the presence of expected outputs
    for expected_output in ana["expected_output"]:
        expected_output = join(analysis_dir, expected_output)
        if not exists(expected_output):
            print(f"Expected output {expected_output} for analysis {analysis_name} does not exist.")
            ret = 1

    logfile = join(analysis_dir, f"Analysis_{analysis_name}.log")

---

PARAPHRASED DOCUMENT:
    analyses = get_config(args.config)

    for ana in analyses:
        if args.disable_tasks and ana["name"] in args.disable_tasks:
            ana["enabled"] = False
            continue
        if args.enable_tasks and ana["name"] in args.enable_tasks:
            ana["enabled"] = True

    with open(args.output, "w") as f:
        json.dump({"analyses": analyses}, f, indent=2)

    return 0


def check(args):
    """
    verify a few conditions for a given task

    Outputs some details to stdout:
    1. --status ==> ENABLED or DISABLED
    2. --applicable-to ==> mc/data
    """

    def print_status(enabled):
        if enabled:
            print("ENABLED")
            return
        print("DISABLED")