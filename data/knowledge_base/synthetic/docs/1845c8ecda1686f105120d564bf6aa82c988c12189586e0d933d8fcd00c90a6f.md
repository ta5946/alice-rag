## Metadata

**Document link:** https://github.com/AliceO2Group/O2DPG/blob/master/UTILS/FileIOGraph/analyse_FileIO.py

**Start chunk id:** 1845c8ecda1686f105120d564bf6aa82c988c12189586e0d933d8fcd00c90a6f

## Content

if not file_matches:
    continue

if file_consumed_task.get(file_name) is None:
    file_consumed_task[file_name] = set()
if file_written_task.get(file_name) is None:
    file_written_task[file_name] = set()
    
for p in pids:
    if p in pid_to_O2DPGtask:
        task = pid_to_O2DPGtask[p]
        if mode == 'read':
            task_reads[task].add(file_name)
            file_consumed_task[file_name].add(task)

        if mode == 'write':
            task_writes[task].add(file_name)
            file_written_task[file_name].add(task)


# generates the graph for files and tasks
def draw_graph(graphviz_filename):
    if not havegraphviz:
        print('graphviz not installed, cannot draw workflow')
        return

---

# Save the dictionary to a JSON file
with open(json_file_name, 'w') as json_file:
    json.dump({ "file_report" : file_written_task_tr, "task_report" : tasks_output }, json_file, indent=2)

if args.graphviz:
  generate_graph(args.graphviz)

if args.output:
  create_json_report(args.output)

---

DOCUMENT:
    dot = Digraph(comment='O2DPG file - task network')
    
    ccdbfilter = re.compile('ccdb(.*)/snapshot.root')

    nametoindex={}
    index=0

    allfiles = set(file_written_task.keys()) | set(file_consumed_task.keys())
    normalfiles = [s for s in allfiles if not ccdbfilter.match(s)]
    ccdbfiles = [(s, ccdbfilter.match(s).group(1)) for s in allfiles if ccdbfilter.match(s)]

    with dot.subgraph(name='CCDB') as ccdbpartition:
        ccdbpartition.attr(color='blue')
        for f in ccdbfiles:
            nametoindex[f[0]] = index
            ccdbpartition.node(str(index), f[1], color='blue')
            index = index + 1

---

WITH dot.subgraph(name='normal') AS normalpartition:
    normalpartition.attr(color='black')
    FOR f IN normalfiles:
        nametoindex[f] = index
        normalpartition.node(str(index), f, color='red')
        index += 1
    FOR t IN O2DPGtask_to_pid:
        nametoindex[t] = index
        normalpartition.node(str(index), t, shape='box', color='green', style='filled')
        index += 1

    # edges (connections between files and tasks)
    FOR node IN file_consumed_task:
        # node is a file (source)
        sourceindex = nametoindex[node]
        FOR task IN file_consumed_task[node]:
            toindex = nametoindex[task]
            dot.edge(str(sourceindex), str(toindex))

---

PARAPHRASED DOCUMENT:
    parser = argparse.ArgumentParser(description='Generate O2DPG MC file dependency reports')

# specify the run number or use a default if not specified
parser.add_argument('--actionFile', type=str, help="O2DPG pipeline runner action file")
parser.add_argument('--monitorFile', type=str, help="monitoring file from the fanotify tool. See O2DPG/UTILS/FileIOGraph for more details.")
parser.add_argument('--basedir', type=str, help="O2DPG workflow directory")
parser.add_argument('--file-filters', nargs='+', default=[r'.*'], help="Regular expressions to select files (default: all files = '.*')")
parser.add_argument('--graphviz', type=str, help="Create a graphviz plot")
parser.add_argument('-o','--output', type=str, help="Output JSON report")

args = parser.parse_args()

# determine the necessary actions
# (a) - parse the action file to map O2DPG task names to PIDs
# -----> populates pid_to_O2DPGtask and O2DPGtask_to_pid

---

#!/usr/bin/env python3

# This script is written in Python and aims to analyze a "fanotify" file access report,
# enriched with task details from an O2DPG MC workflow.
# It generates:
# - a JSON report
# - optionally, a graphviz visualization illustrating file and task dependencies

import argparse
import re
import json

try:
    from graphviz import Digraph
    havegraphviz=True
except ImportError:
    havegraphviz=False

parser = argparse.ArgumentParser(description='Generate O2DPG MC file dependency reports')

---

DOCUMENT:
    pattern = re.compile(args.basedir + r'([^,]+),((?:read|write)),(.*)')
# ignoring certain file names
file_exclude_filter = re.compile(r'(.*)\.log(.*)|(ccdb/log)|(.*)dpl-config\.json')

# create user-defined file filters
file_filter_re = [ re.compile(l) for l in args.file_filters ]

with open(args.monitorFile, 'r') as file:
    for line in file:
        # attempt to match the pattern in each line
        match = pattern.match(line)
        if match:
            file_name = match.group(1)
            mode = match.group(2)
            pids = match.group(3).split(";")

            # apply file name exclusion filter
            if file_exclude_filter.match(file_name):
                continue

            # check if file matches any user-defined filter
            file_matches = False
            for r in file_filter_re:
                if r.match(file_name):
                    file_matches = True
                    break

---

# Define the pattern using regular expressions
pid_to_O2DPGtask = {}
O2DPGtask_to_pid = {}

pattern = re.compile(r'.*INFO Task (\d+).*:(\w+) finished with status 0')
# Open the action file and process each line
with open(args.actionFile, 'r') as file:
    for line in file:
        # Try to match the pattern in each line
        match = pattern.match(line)
        
        # If a match is found, extract the information
        if match:
            task_number = match.group(1)
            task_name = match.group(2)
            
            pid_to_O2DPGtask[task_number] = task_name
            O2DPGtask_to_pid[task_name] = task_number


# (b) - parse the monitor file to map files to processes and operations
# ---> fills the following structures:
task_reads = { tname : set() for tname in O2DPGtask_to_pid }
task_writes = { tname : set() for tname in O2DPGtask_to_pid }
file_written_task = {}
file_consumed_task = {}

---

# edges (arrows between files and tasks)
for node in file_written_task:
    # node is a file (target)
    toindex = nametoindex[node]
    for task in file_written_task[node]:
        sourceindex = nametoindex[task]
        dot.edge(str(sourceindex), str(toindex))

dot.render(graphviz_filename, format='pdf')
dot.render(graphviz_filename, format='gv')

def generate_json_report(json_file_name):
  # create a JSON report of file dependencies
  all_filenames = set(file_written_task.keys()) | set(file_consumed_task.keys())
  file_written_task_tr = [
   {
     "file" : k,
     "written_by" : list(file_written_task.get(k, [])),
     "read_by" : list(file_consumed_task.get(k, []))
   }
   for k in all_filenames
  ]
  
  tasks_output = [
   {
     "task" : t,
     "writes" : list(task_writes.get(t,[])),
     "reads" : list(task_reads.get(t,[]))
   }
   for t in O2DPGtask_to_pid
  ]