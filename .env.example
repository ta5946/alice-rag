# TODO create separate config.yml file

LANGCHAIN_TRACING_V2="false"
LANGCHAIN_PROJECT="alice-dev"
LANGCHAIN_API_KEY="your_langchain_api_key"

LANGFUSE_PUBLIC_KEY="pk-lf-f5c27df0-2d07-435f-88f4-0c03b365f499"
LANGFUSE_SECRET_KEY="your_langfuse_secret_key"
LANGFUSE_HOST="http://pc-alice-ph01:3000"

# HF_LLM_REPO="TheBloke/Mistral-7B-Instruct-v0.1-GGUF:Q4_K_M"
# HF_LLM_REPO="MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF:Q6_K"
HF_LLM_REPO="MaziyarPanahi/Qwen2.5-7B-Instruct-GGUF:Q6_K"
# HF_LLM_REPO="MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF:Q6_K"
# HF_LLM_REPO="MaziyarPanahi/gemma-3-12b-it-GGUF:Q3_K_M"

HF_EMBEDDINGS_REPO="BAAI/bge-base-en-v1.5"
# HF_EMBEDDINGS_REPO="BAAI/bge-m3"

HF_RERANKER_REPO="BAAI/bge-reranker-base"
# HF_RERANKER_REPO="BAAI/bge-reranker-v2-m3"

HF_CACHE_DIR="./models/huggingface"
LLAMA_CPP_CACHE_DIR="./models/llama.cpp"
N_GPU_LAYERS=50
CTX_LENGTH=16000 # in tokens, 0 means taking it from the model config

LLM_BASE_URL="http://pc-alice-ph01:8080/v1"
LLM_API_KEY="any"

CHROMA_DIR="./data/chroma"
CHROMA_COLLECTION_NAME="o2_docs"
CHROMA_CHUNK_SIZE=1000 # in characters, for text splitter
CHROMA_TOP_K=20 # retriever stage
CHROMA_TOP_N=5 # reranker stage
CHROMA_THRESHOLD=0.25

INDEXER_RESOURCE_FILE="./src/indexer/knowledge_base.yml"
INDEXER_HASHES_FILE="./data/hashes.json"
INDEXER_DATA_DIR="./data/indexed"
INDEXER_BATCH_SIZE=1000

MATTERMOST_URL="mattermost.web.cern.ch"
MATTERMOST_TOKEN="bot_mattermost_token"
MATTERMOST_PORT=443
