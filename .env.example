LANGCHAIN_TRACING_V2="true"
LANGCHAIN_PROJECT="alice-dev"
LANGCHAIN_API_KEY="your_langchain_api_key"

# HF_LLM_REPO="TheBloke/Mistral-7B-Instruct-v0.1-GGUF:Q4_K_M"
# HF_LLM_REPO="MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF:Q6_K"
HF_LLM_REPO="MaziyarPanahi/Qwen2.5-7B-Instruct-GGUF:Q6_K"
# HF_LLM_REPO="MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF:Q6_K"
# HF_LLM_REPO="MaziyarPanahi/gemma-3-12b-it-GGUF:Q3_K_M"

HF_EMBEDDINGS_REPO="BAAI/bge-base-en-v1.5"
# HF_EMBEDDINGS_REPO="BAAI/bge-m3"

HF_RERANKER_REPO="BAAI/bge-reranker-base"
# HF_RERANKER_REPO="BAAI/bge-reranker-v2-m3"

HF_CACHE_DIR="./models/huggingface"
LLAMA_CPP_CACHE_DIR="./models/llama.cpp"
N_GPU_LAYERS=50
CTX_LENGTH=16000 # 0 means taking it from the model config

LLM_BASE_URL="http://localhost:8080/v1"
LLM_API_KEY="any"

CHROMA_DIR="./indexer/chroma_store"
CHROMA_TOP_K=20 # retriever stage
CHROMA_TOP_N=5 # reranker stage
CHROMA_THRESHOLD=0.3
